{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rQc-wXjqrEuR"
   },
   "source": [
    "# Optimize Preprocessing\n",
    "\n",
    "When input data does not fit the model input tensor perfectly, additional operations/steps are needed to transform the data to the format expected by the model. This tutorial demonstrates how it could be performed with Preprocessing API. Preprocessing API is an easy-to-use instrument, that allows to integrate preprocessing steps into an execution graph and perform it on selected device, which can improve of device utilization. For more information about Preprocessing API, please, see this [overview](https://docs.openvino.ai/latest/openvino_docs_OV_UG_Preprocessing_Overview.html#) and [details](https://docs.openvino.ai/latest/openvino_docs_OV_UG_Preprocessing_Details.html)\n",
    "\n",
    "This tutorial include following steps:\n",
    "- Downloading the model\n",
    "- Setup preprocessing, loading the model and inference with original image\n",
    "- Fitting image to the model input type and inference with prepared image\n",
    "- Comparing results on one picture\n",
    "- Comparing performance of the inference with and without using of preprocessing API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "4cSNQWdbSyeo"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from openvino.runtime import Core\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "sys.path.append(\"../utils\")\n",
    "from notebook_utils import download_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup image and device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = \"../data/image/coco.jpg\"\n",
    "device = \"CPU\"\n",
    "# device = \"GPU\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading the model\n",
    "\n",
    "This tutorial uses the [caffe-googlenet-bn](https://github.com/lim0606/caffe-googlenet-bn). The caffe-googlenet-bn model is the second of the [Inception](https://github.com/tensorflow/tpu/tree/master/models/experimental/inception) family of models designed to perform image classification. Like other Inception models, caffe-googlenet-bn has been pre-trained on the [ImageNet](https://image-net.org/) data set. For more details about this family of models, see the [research paper](https://arxiv.org/abs/1512.00567).\n",
    "\n",
    "The following code downloads caffe-googlenet-bn and converts it to OpenVINO IR format `(ir_model/caffe-googlenet-bn.xml)` with  Model Optimizer tool. For more information about Model Optimizer, see the [Model Optimizer Developer Guide](https://docs.openvino.ai/latest/openvino_docs_MO_DG_Deep_Learning_Model_Optimizer_DevGuide.html). Downloading and converting steps will be skipped if this actions have already been executed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"caffe-googlenet-bn\"\n",
    "MODEL_DIR = Path(\"./model\").expanduser()\n",
    "ir_path = MODEL_DIR / \"ir_model\" / f\"{model_name}.xml\"\n",
    "\n",
    "# donwload model from origin source if it is not exists\n",
    "if Path(MODEL_DIR, f'{model_name}.prototxt').exists() and Path(MODEL_DIR, f'{model_name}.caffemodel').exists():\n",
    "    print(f\"Model {model_name} already donwloaded to {MODEL_DIR}\\n\")\n",
    "else:\n",
    "    prototxt_url = \"https://raw.githubusercontent.com/lim0606/caffe-googlenet-bn/d19caf526b7d8cad873ff91ba4cea602eadd58b3/deploy.prototxt\"\n",
    "    download_file(prototxt_url, filename=f\"{model_name}.prototxt\", directory=MODEL_DIR)\n",
    "    caffemodel_url = \"https://github.com/lim0606/caffe-googlenet-bn/raw/d19caf526b7d8cad873ff91ba4cea602eadd58b3/snapshots/googlenet_bn_stepsize_6400_iter_1200000.caffemodel\"\n",
    "    download_file(caffemodel_url, filename=f\"{model_name}.caffemodel\", directory=MODEL_DIR)\n",
    "\n",
    "prototxt_file = MODEL_DIR / f'{model_name}.prototxt'\n",
    "caffemodel_file = MODEL_DIR / f'{model_name}.caffemodel'\n",
    "\n",
    "# postpocessing\n",
    "text = prototxt_file.read_text()\n",
    "text = text.replace(\"dim: 10\", \"dim: 1\")\n",
    "text = text.replace(\"layers {\", \"layer {\")\n",
    "prototxt_file.write_text(text)\n",
    "\n",
    "# convert the model to OpenVINO format with Model Optimizer if IR is not exists\n",
    "if ir_path.exists():\n",
    "    print(f\"Model in OpenVINO format already exists: {ir_path}\")\n",
    "else: \n",
    "    mo_command = f\"\"\"mo\n",
    "                 --input_model={caffemodel_file}\n",
    "                 --input_proto={prototxt_file}\n",
    "                 --output_dir=\"{ir_path.parent}\"\n",
    "                 --mean_values=data[104.0,117.0,123.0]\n",
    "                 --output=prob\n",
    "                 \"\"\"\n",
    "    mo_command = \" \".join(mo_command.split())\n",
    "    print(\"Model Optimizer command to convert the model to OpenVINO:\")\n",
    "    display(Markdown(f\"`{mo_command}`\"))\n",
    "    ! $mo_command"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup preprocessing steps with Preprocessing API and perform inference\n",
    "\n",
    "Intuitively, preprocessing API consists of the following parts:\n",
    "- Tensor - declares user data format, like shape, layout, precision, color format from actual user’s data.\n",
    "- Steps - describes sequence of preprocessing steps which need to be applied to user data.\n",
    "- Model - specifies model data format. Usually, precision and shape are already known for model, only additional information, like layout can be specified.\n",
    "\n",
    "Graph modifications of a model shall be performed after the model is read from a drive and before it is loaded on the actual device.\n",
    "\n",
    "Pre-processing support following operations (please, see more details [here](https://docs.openvino.ai/latest/classov_1_1preprocess_1_1PreProcessSteps.html#doxid-classov-1-1preprocess-1-1-pre-process-steps-1aeacaf406d72a238e31a359798ebdb3b7))\n",
    "- Mean/Scale Normalization\n",
    "- Converting Precision\n",
    "- Converting layout (transposing)\n",
    "- Resizing Image\n",
    "- Color Conversion\n",
    "- Custom Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "core = Core()\n",
    "ppp_model = core.read_model(model=ir_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create PrePostProcessor Object\n",
    "\n",
    "The [PrePostProcessor()](https://docs.openvino.ai/latest/classov_1_1preprocess_1_1PrePostProcessor.html#doxid-classov-1-1preprocess-1-1-pre-post-processor) class allows specifying preprocessing and postprocessing steps for a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openvino.preprocess import PrePostProcessor\n",
    "\n",
    "ppp = PrePostProcessor(ppp_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Declare User’s Data Format\n",
    "\n",
    "To address particular input of a model/preprocessor, use the PrePostProcessor.input(input_name) method. If the model has only one input, then simple PrePostProcessor.input() will get a reference to pre-processing builder for this input (a tensor, the steps, a model). In general, when a model has multiple inputs/outputs, each one can be addressed by a tensor name or by it’s index.\n",
    "\n",
    "Below is all the specified input information:\n",
    "- Precision is U8 (unsigned 8-bit integer).\n",
    "- Data represents tensor with the {1,577,800,3} shape.\n",
    "- Layout is “NHWC”. It means: height=577, width=800, channels=3.\n",
    "- Color format is BGR.\n",
    "\n",
    "The height/width information is necessary for resize, and channels is needed for mean/scale normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openvino.runtime import Type, Layout\n",
    "from openvino.preprocess import ColorFormat\n",
    "\n",
    "# Read image to check the image format\n",
    "image = cv2.imread(image_path)\n",
    "plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB));\n",
    "print(f\"The shape of the image is {image.shape}\")\n",
    "print(f\"The data type of the image is {image.dtype}\")\n",
    "\n",
    "# setup formant of data\n",
    "ppp.input().tensor().set_element_type(Type.u8)\\\n",
    "                    .set_shape([1, 577, 800, 3])\\\n",
    "                    .set_layout(Layout('NHWC')) \\\n",
    "                    .set_color_format(ColorFormat.BGR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Declaring Model Layout\n",
    "\n",
    "Model input already has information about precision and shape. Preprocessing API is not intended to modify this. The only thing that may be specified is input data [layout](https://docs.openvino.ai/latest/openvino_docs_OV_UG_Layout_Overview.html#doxid-openvino-docs-o-v-u-g-layout-overview)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer_ir = next(iter(ppp_model.inputs))\n",
    "print(f\"The input shape of the model is {input_layer_ir.shape}\")\n",
    "\n",
    "ppp.input().model().set_layout(Layout('NCHW'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing Steps\n",
    "\n",
    "Now, the sequence of preprocessing steps can be defined.\n",
    "\n",
    "Perform the following:\n",
    "- Convert U8 to FP32 precision.\n",
    "- Resize to height/width of a model. Be aware that if a model accepts dynamic size e.g., {?, 3, ?, ?}, resize will not know how to resize the picture. Therefore, in this case, target height / width should be specified as PreProcessSteps.resize( ResizeAlgorithm, destination_height, destination_width). For more details, see also the [PreProcessSteps.resize()](https://docs.openvino.ai/latest/classov_1_1preprocess_1_1PreProcessSteps.html#doxid-classov-1-1preprocess-1-1-pre-process-steps-1a40dab78be1222fee505ed6a13400efe6).\n",
    "- Subtract mean from each channel.\n",
    "\n",
    "Also it could be specify color format with PrePostProcessor.convert_color() and scale with PrePostProcessor.scale().\n",
    "Specifitng of converting layout is not needed, such conversion will be added implicitly.\n",
    "\n",
    "Keep in mind that the last convert_layout step is commented out as it is not necessary to specify the last layout conversion. The PrePostProcessor will do such conversion automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openvino.preprocess import ResizeAlgorithm\n",
    "\n",
    "ppp.input().preprocess().convert_element_type(Type.f32) \\\n",
    "                        .resize(ResizeAlgorithm.RESIZE_LINEAR) \\\n",
    "                        .mean([104.0, 117.0, 123.0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Integrating Steps into a Model\n",
    "\n",
    "Once the preprocessing steps have been finished the model can be finally built. It is possible to display PrePostProcessor configuration for debugging purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Dump preprocessor: {ppp}')\n",
    "model_with_preprocess = ppp.build()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model and perform inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "compiled_model_with_preprocess = core.compile_model(model=ppp_model, device_name=device)\n",
    "\n",
    "ppp_output_layer = compiled_model_with_preprocess.output(0)\n",
    "\n",
    "image = cv2.imread(image_path)\n",
    "ppp_input_tensor = np.expand_dims(image, 0)\n",
    "\n",
    "results = compiled_model_with_preprocess(ppp_input_tensor)[ppp_output_layer][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit image manually and perform inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = core.read_model(model=ir_path)\n",
    "compiled_model = core.compile_model(model=model, device_name=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load image and fit it to model input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def manual_image_preprocessing(path_to_image, compiled_model):\n",
    "    input_layer_ir = next(iter(compiled_model.inputs))\n",
    "\n",
    "    # Read image in BGR format.\n",
    "    image = cv2.imread(path_to_image)\n",
    "\n",
    "    # N, C, H, W = batch size, number of channels, height, width.\n",
    "    N, C, H, W = input_layer_ir.shape\n",
    "\n",
    "    # Resize image to the input size expected by the model.\n",
    "    resized_image = cv2.resize(image, (W, H))\n",
    "\n",
    "    # change data type\n",
    "    dtype_changed_image = np.float32(resized_image)\n",
    "\n",
    "    # perform mean normalization\n",
    "    mean_values = np.array([104, 117, 123])\n",
    "    preprocessed_image = dtype_changed_image - mean_values\n",
    "\n",
    "    input_tensor = np.expand_dims(preprocessed_image.transpose(2, 0, 1), 0)\n",
    "\n",
    "    return input_tensor\n",
    "\n",
    "\n",
    "input_tensor = manual_image_preprocessing(image_path, compiled_model)\n",
    "print(f\"The shape of the image is {input_tensor.shape}\")\n",
    "print(f\"The data type of the image is {input_tensor.dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform inference "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_layer = compiled_model.output(0)\n",
    "\n",
    "result = compiled_model(input_tensor)[output_layer]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare results on one image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def results(input_tensor, compiled_model):\n",
    "    output_layer = compiled_model.output(0)\n",
    "\n",
    "    results = compiled_model(input_tensor)[output_layer][0]\n",
    "\n",
    "    top_indices = np.argsort(results)[-5:][::-1]\n",
    "    top_softmax = results[top_indices]\n",
    "\n",
    "    return top_indices, top_softmax\n",
    "\n",
    "\n",
    "# Convert the inference result to a class name.\n",
    "imagenet_classes = open(\"../data/datasets/imagenet/imagenet_2012.txt\").read().splitlines()\n",
    "imagenet_classes = ['background'] + imagenet_classes\n",
    "\n",
    "# get result for inference with preprocessing api\n",
    "top_indices, top_softmax = results(ppp_input_tensor, compiled_model_with_preprocess)\n",
    "\n",
    "print(\"Result of inference with preprocessing api:\")\n",
    "for index, softmax_probability in zip(top_indices, top_softmax):\n",
    "    print(f\"{imagenet_classes[index]}, {softmax_probability:.5f}\")\n",
    "\n",
    "print(\"\\n\")\n",
    "# get result for inference with the manual preparing of the image\n",
    "top_indices, top_softmax = results(input_tensor, compiled_model)\n",
    "\n",
    "print(\"Result of inference with manual image setup:\")\n",
    "for index, softmax_probability in zip(top_indices, top_softmax):\n",
    "    print(f\"{imagenet_classes[index]}, {softmax_probability:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check performance for inference with preprocessing api\n",
    "num_images = 1000\n",
    "\n",
    "start = time.perf_counter()\n",
    "\n",
    "for _ in range(num_images):\n",
    "    compiled_model_with_preprocess(ppp_input_tensor)\n",
    "\n",
    "end = time.perf_counter()\n",
    "time_ir = end - start\n",
    "\n",
    "print(\n",
    "    f\"IR model in OpenVINO Runtime/CPU with preprocessing API: {time_ir/num_images:.4f} \"\n",
    "    f\"seconds per image, FPS: {num_images/time_ir:.2f}\"\n",
    ")\n",
    "\n",
    "# check performance for inference with the manual preparing of the image\n",
    "start = time.perf_counter()\n",
    "\n",
    "for _ in range(num_images):\n",
    "    input_tensor = manual_image_preprocessing(image_path, compiled_model)\n",
    "    compiled_model([input_tensor])\n",
    "\n",
    "end = time.perf_counter()\n",
    "time_ir = end - start\n",
    "\n",
    "print(\n",
    "    f\"IR model in OpenVINO Runtime/{device}: {time_ir/num_images:.4f} \"\n",
    "    f\"seconds per image, FPS: {num_images/time_ir:.2f}\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "tutorial_tiny.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10 (tags/v3.8.10:3d8993a, May  3 2021, 11:48:03) [MSC v.1928 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "99b31a8f0484178f325321f977e8458680b0318d6e9b26bee95a1a71c664adb2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
