{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Super Resolution with OpenVINO\n",
    "Super Resolution is the process of enhancing the quality of an image by increasing the pixel count using deep learning. This notebook applies Single Image Super Resolution (SISR) to frames in a 360p (480Ã—360) video in 360p resolution. We use a model called [single-image-super-resolution-1032](https://github.com/openvinotoolkit/open_model_zoo/tree/develop/models/intel/single-image-super-resolution-1032) which is available from the Open Model Zoo. It is based on the research paper cited below. \n",
    "\n",
    "Y. Liu et al., [\"An Attention-Based Approach for Single Image Super Resolution,\"](https://arxiv.org/abs/1807.06779) 2018 24th International Conference on Pattern Recognition (ICPR), 2018, pp. 2777-2784, doi: 10.1109/ICPR.2018.8545760.\n",
    "\n",
    "**NOTE:** The Single Image Super Resolution (SISR) model used in this demo is not optimized for video. Results may vary depending on the video. We are looking for a more suitable Multi Image Super Resolution (MISR) model, so if you know of a great open source model, please let us know! You can start a [discussion](https://github.com/openvinotoolkit/openvino_notebooks/discussions) or create an [issue](https://github.com/openvinotoolkit/openvino_notebooks/issues) on GitHub. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Preparation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Imports"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import os\r\n",
    "import socket\r\n",
    "import time\r\n",
    "import urllib\r\n",
    "from pathlib import Path\r\n",
    "\r\n",
    "import cv2\r\n",
    "import numpy as np\r\n",
    "import urllib\r\n",
    "from IPython.display import (\r\n",
    "    HTML,\r\n",
    "    FileLink,\r\n",
    "    Pretty,\r\n",
    "    ProgressBar,\r\n",
    "    Video,\r\n",
    "    clear_output,\r\n",
    "    display,\r\n",
    ")\r\n",
    "from openvino.inference_engine import IECore\r\n",
    "from pytube import YouTube"
   ],
   "outputs": [],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Settings"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Device to use for inference. For example, \"CPU\", or \"GPU\"\r\n",
    "DEVICE = \"CPU\"\r\n",
    "# 1032: 4x superresolution, 1033: 3x superresolution\r\n",
    "MODEL_FILE = \"model/single-image-super-resolution-1032.xml\"\r\n",
    "model_name = os.path.basename(MODEL_FILE)\r\n",
    "model_xml_path = Path(MODEL_FILE).with_suffix(\".xml\")"
   ],
   "outputs": [],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Functions\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def write_text_on_image(image: np.ndarray, text: str) -> np.ndarray:\r\n",
    "    \"\"\"\r\n",
    "    Write the specified text in the top left corner of the image\r\n",
    "    as white text with a black border.\r\n",
    "\r\n",
    "    :param image: image as numpy arry with HWC shape, RGB or BGR\r\n",
    "    :param text: text to write\r\n",
    "    :return: image with written text, as numpy array\r\n",
    "    \"\"\"\r\n",
    "    font = cv2.FONT_HERSHEY_PLAIN\r\n",
    "    org = (20, 20)\r\n",
    "    font_scale = 4\r\n",
    "    font_color = (255, 255, 255)\r\n",
    "    line_type = 1\r\n",
    "    font_thickness = 2\r\n",
    "    text_color_bg = (0, 0, 0)\r\n",
    "    x, y = org\r\n",
    "\r\n",
    "    image = cv2.UMat(image)\r\n",
    "    (text_w, text_h), _ = cv2.getTextSize(\r\n",
    "        text, font, font_scale, font_thickness\r\n",
    "    )\r\n",
    "    result_im = cv2.rectangle(\r\n",
    "        image, org, (x + text_w, y + text_h), text_color_bg, -1\r\n",
    "    )\r\n",
    "\r\n",
    "    textim = cv2.putText(\r\n",
    "        result_im,\r\n",
    "        text,\r\n",
    "        (x, y + text_h + font_scale - 1),\r\n",
    "        font,\r\n",
    "        font_scale,\r\n",
    "        font_color,\r\n",
    "        font_thickness,\r\n",
    "        line_type,\r\n",
    "    )\r\n",
    "    return textim.get()\r\n",
    "\r\n",
    "\r\n",
    "def load_image(path: str) -> np.ndarray:\r\n",
    "    \"\"\"\r\n",
    "    Loads an image from `path` and returns it as BGR numpy array.\r\n",
    "\r\n",
    "    :param path: path to an image filename or url\r\n",
    "    :return: image as numpy array, with BGR channel order\r\n",
    "    \"\"\"\r\n",
    "    if path.startswith(\"http\"):\r\n",
    "        # Set User-Agent to Mozilla because some websites block requests\r\n",
    "        # with User-Agent Python\r\n",
    "        request = urllib.request.Request(\r\n",
    "            path, headers={\"User-Agent\": \"Mozilla/5.0\"}\r\n",
    "        )\r\n",
    "        response = urllib.request.urlopen(request)\r\n",
    "        array = np.asarray(bytearray(response.read()), dtype=\"uint8\")\r\n",
    "        image = cv2.imdecode(array, -1)  # Loads the image as BGR\r\n",
    "    else:\r\n",
    "        image = cv2.imread(path)\r\n",
    "    return image\r\n",
    "\r\n",
    "\r\n",
    "def convert_result_to_image(result) -> np.ndarray:\r\n",
    "    \"\"\"\r\n",
    "    Convert network result of floating point numbers to image with integer\r\n",
    "    values from 0-255. Values outside this range are clipped to 0 and 255.\r\n",
    "\r\n",
    "    :param result: a single superresolution network result in N,C,H,W shape\r\n",
    "    \"\"\"\r\n",
    "    result = result.squeeze(0).transpose(1, 2, 0)\r\n",
    "    result *= 255\r\n",
    "    result[result < 0] = 0\r\n",
    "    result[result > 255] = 255\r\n",
    "    result = result.astype(np.uint8)\r\n",
    "    return result"
   ],
   "outputs": [],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load the Superresolution Model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Load the model in Inference Engine with `ie.read_network` and load it to the specified device with `ie.load_network`"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "ie = IECore()\r\n",
    "net = ie.read_network(\r\n",
    "    str(model_xml_path), str(model_xml_path.with_suffix(\".bin\"))\r\n",
    ")\r\n",
    "exec_net = ie.load_network(network=net, device_name=DEVICE)"
   ],
   "outputs": [],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Get information about network inputs and outputs. The Super Resolution model expects two inputs: 1) the input image, 2) a bicubic interpolation of the input image to the target size 1920x1080. It returns the super resolution version of the image in 1920x1800. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Network inputs and outputs are dictionaries. Get the keys for the\r\n",
    "# dictionaries.\r\n",
    "original_image_key = list(exec_net.input_info)[0]\r\n",
    "bicubic_image_key = list(exec_net.input_info)[1]\r\n",
    "output_key = list(exec_net.outputs.keys())[0]\r\n",
    "\r\n",
    "# Get the expected input and target shape. `.dims[2:]` returns the height\r\n",
    "# and width. OpenCV's resize function expects the shape as (width, height),\r\n",
    "# so we reverse the shape with `[::-1]` and convert it to a tuple\r\n",
    "input_height, input_width = tuple(\r\n",
    "    exec_net.input_info[original_image_key].tensor_desc.dims[2:]\r\n",
    ")\r\n",
    "target_height, target_width = tuple(\r\n",
    "    exec_net.input_info[bicubic_image_key].tensor_desc.dims[2:]\r\n",
    ")\r\n",
    "\r\n",
    "upsample_factor = int(target_height / input_height)\r\n",
    "\r\n",
    "print(\r\n",
    "    f\"The network expects inputs with a width of {input_width}, \"\r\n",
    "    f\"height of {input_height}\"\r\n",
    ")\r\n",
    "print(\r\n",
    "    f\"The network returns images with a width of {target_width}, \"\r\n",
    "    f\"height of {target_height}\"\r\n",
    ")\r\n",
    "\r\n",
    "print(\r\n",
    "    f\"The image sides are upsampled by a factor {upsample_factor}. \"\r\n",
    "    f\"The new image is {upsample_factor**2} times as large as the \"\r\n",
    "    \"original image\"\r\n",
    ")"
   ],
   "outputs": [],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Superresolution on Video\n",
    "\n",
    "Download a YouTube\\* video with PyTube and enhance the video quality with superresolution. \n",
    "\n",
    "By default only the first 100 frames of the video are processed. Change NUM_FRAMES in the cell below to modify this. \n",
    "\n",
    "**Note:**\n",
    "- The resulting video does not contain audio.\n",
    "- The input video should be a landscape video and have an an input resultion of 360p (640x360) for the 1032 model, or 480p (720x480) for the 1033 model."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Settings"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "VIDEO_DIR = \"data\"\r\n",
    "# Number of frames to read from the input video. Set to 0 to read all frames.\r\n",
    "NUM_FRAMES = 100\r\n",
    "# The format for saving the result video's\r\n",
    "# vp09 is slow, but widely available. If you have FFMPEG installed, you can\r\n",
    "# change the FOURCC to `*\"THEO\"` to improve video writing speed\r\n",
    "FOURCC = cv2.VideoWriter_fourcc(*\"vp09\")"
   ],
   "outputs": [],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Download and Prepare Video"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Use pytube to download a video. It downloads to the videos subdirectory.\r\n",
    "# You can also place a local video there and comment out the following lines\r\n",
    "VIDEO_URL = \"https://www.youtube.com/watch?v=V8yS3WIkOrA\"\r\n",
    "yt = YouTube(VIDEO_URL)\r\n",
    "# Use `yt.streams` to see all available streams. See the PyTube documentation\r\n",
    "# https://python-pytube.readthedocs.io/en/latest/api.html for advanced\r\n",
    "# filtering options\r\n",
    "try:\r\n",
    "    os.makedirs(VIDEO_DIR, exist_ok=True)\r\n",
    "    stream = yt.streams.filter(resolution=\"360p\").first()\r\n",
    "    filename = Path(\r\n",
    "        stream.default_filename.encode(\"ascii\", \"ignore\").decode(\"ascii\")\r\n",
    "    ).stem\r\n",
    "    stream.download(VIDEO_DIR, filename=filename)\r\n",
    "    print(f\"Video {filename} downloaded to {VIDEO_DIR}\")\r\n",
    "\r\n",
    "    # Create Path objects for the input video and the resulting videos\r\n",
    "    video_path = Path(stream.get_file_path(filename, VIDEO_DIR))\r\n",
    "except (socket.timeout, TimeoutError, urllib.error.HTTPError):\r\n",
    "    # If PyTube fails, use a local video stored in the VIDEO_DIR directory\r\n",
    "    video_path = Path(rf\"{VIDEO_DIR}/CEO Pat Gelsinger on Leading Intel.mp4\")\r\n",
    "\r\n",
    "# Path names for the result videos\r\n",
    "superres_video_path = video_path.with_name(f\"{video_path.stem}_superres.mp4\")\r\n",
    "bicubic_video_path = video_path.with_name(f\"{video_path.stem}_bicubic.mp4\")\r\n",
    "comparison_video_path = video_path.with_name(\r\n",
    "    f\"{video_path.stem}_superres_comparison.mp4\"\r\n",
    ")\r\n"
   ],
   "outputs": [],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Open the video and get the dimensions and the FPS\n",
    "cap = cv2.VideoCapture(str(video_path))\n",
    "ret, image = cap.read()\n",
    "if not ret:\n",
    "    raise ValueError(f\"The video at '{video_path}' cannot be read.\")\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "original_frame_height, original_frame_width = image.shape[:2]\n",
    "\n",
    "cap.release()\n",
    "print(\n",
    "    f\"The input video has a frame width of {original_frame_width}, \"\n",
    "    f\"frame height of {original_frame_height} and runs at {fps:.2f} fps\"\n",
    ")"
   ],
   "outputs": [],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Create superresolution video, bicubic video and comparison video. The superresolution video contains the enhanced video, upsampled with superresolution, the bicubic video is the input video upsampled with bicubic interpolation, the combination video sets the bicubic video and the superresolution side by side."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "superres_video = cv2.VideoWriter(\n",
    "    str(superres_video_path),\n",
    "    FOURCC,\n",
    "    fps,\n",
    "    (target_width, target_height),\n",
    ")\n",
    "bicubic_video = cv2.VideoWriter(\n",
    "    str(bicubic_video_path),\n",
    "    FOURCC,\n",
    "    fps,\n",
    "    (target_width, target_height),\n",
    ")\n",
    "comparison_video = cv2.VideoWriter(\n",
    "    str(comparison_video_path),\n",
    "    FOURCC,\n",
    "    fps,\n",
    "    (target_width * 2, target_height),\n",
    ")"
   ],
   "outputs": [],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Do Inference\n",
    "\n",
    "Read video frames and enhance them with superresolution. Save the superresolution video, the bicubic video and the comparison video to file.\n",
    "\n",
    "The code in this cell reads the video frame by frame. Each frame is resized and reshaped to network input shape and upsampled with bicubic interpolation to target shape. Both the original and the bicubic image are propagated through the network. The network result is a numpy array with floating point values, with a shape of (1,3,1920,1080). This array is converted to an 8-bit image with shape (1080,1920,3) and written to `superres_video`. The bicubic image is written to `bicubic_video` for comparison. Lastly, the bicubic and result frames are combined side by side and written to `comparison_video`. A progress bar shows the progress of the process. Inference time is measured, as well as total time to process each frame, which includes inference time as well as the time it takes to process and write the video."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "start_time = time.perf_counter()\n",
    "frame_nr = 1\n",
    "total_inference_duration = 0\n",
    "total_frames = (\n",
    "    cap.get(cv2.CAP_PROP_FRAME_COUNT) if NUM_FRAMES == 0 else NUM_FRAMES\n",
    ")\n",
    "\n",
    "progress_bar = ProgressBar(total=total_frames)\n",
    "progress_bar.display()\n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture(str(video_path))\n",
    "try:\n",
    "    while cap.isOpened():\n",
    "        ret, image = cap.read()\n",
    "        if not ret:\n",
    "            cap.release()\n",
    "            break\n",
    "\n",
    "        if NUM_FRAMES > 0 and frame_nr == NUM_FRAMES:\n",
    "            break\n",
    "\n",
    "        # Resize the input image to network shape and convert from (H,W,C) to\n",
    "        # (N,C,H,W)\n",
    "        resized_image = cv2.resize(image, (input_width, input_height))\n",
    "        input_image_original = np.expand_dims(\n",
    "            resized_image.transpose(2, 0, 1), axis=0\n",
    "        )\n",
    "\n",
    "        # Resize and reshape the image to the target shape with bicubic\n",
    "        # interpolation\n",
    "        bicubic_image = cv2.resize(\n",
    "            image, (target_width, target_height), interpolation=cv2.INTER_CUBIC\n",
    "        )\n",
    "        input_image_bicubic = np.expand_dims(\n",
    "            bicubic_image.transpose(2, 0, 1), axis=0\n",
    "        )\n",
    "\n",
    "        # Do inference\n",
    "        inference_start_time = time.perf_counter()\n",
    "        result = exec_net.infer(\n",
    "            inputs={\n",
    "                original_image_key: input_image_original,\n",
    "                bicubic_image_key: input_image_bicubic,\n",
    "            }\n",
    "        )[output_key]\n",
    "        inference_stop_time = time.perf_counter()\n",
    "        inference_duration = inference_stop_time - inference_start_time\n",
    "        total_inference_duration += inference_duration\n",
    "\n",
    "        # Transform inference result into an image\n",
    "        result_frame = convert_result_to_image(result)\n",
    "\n",
    "        # Write resulting image and bicubic image to video\n",
    "        superres_video.write(result_frame)\n",
    "        bicubic_video.write(bicubic_image)\n",
    "        stacked_frame = np.hstack((bicubic_image, result_frame))\n",
    "        comparison_video.write(stacked_frame)\n",
    "\n",
    "        frame_nr = frame_nr + 1\n",
    "\n",
    "        # Update progress bar and status message\n",
    "        progress_bar.progress = frame_nr\n",
    "        progress_bar.update()\n",
    "        if frame_nr % 10 == 0:\n",
    "            clear_output(wait=True)\n",
    "            progress_bar.display()\n",
    "            display(\n",
    "                Pretty(\n",
    "                    f\"Processed frame {frame_nr}. Inference time: \"\n",
    "                    f\"{inference_duration:.2f} seconds \"\n",
    "                    f\"({1/inference_duration:.2f} FPS)\"\n",
    "                )\n",
    "            )\n",
    "\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"Processing interrupted.\")\n",
    "finally:\n",
    "    superres_video.release()\n",
    "    bicubic_video.release()\n",
    "    comparison_video.release()\n",
    "    end_time = time.perf_counter()\n",
    "    duration = end_time - start_time\n",
    "    print(f\"Video's saved to {comparison_video_path.parent} directory.\")\n",
    "    print(\n",
    "        f\"Processed {frame_nr} frames in {duration:.2f} seconds. Total FPS \"\n",
    "        f\"(including video processing): {frame_nr/duration:.2f}. \"\n",
    "        f\"Inference FPS: {frame_nr/total_inference_duration:.2f}.\"\n",
    "    )"
   ],
   "outputs": [],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Show side-by-side video of bicubic and superresolution version"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "if not comparison_video_path.exists():\n",
    "    raise ValueError(\"The comparison video does not exist.\")\n",
    "else:\n",
    "    video_link = FileLink(comparison_video_path)\n",
    "    display(\n",
    "        HTML(\n",
    "            f\"Showing side by side comparison. If you cannot see the video in \"\n",
    "            \"your browser, please click on the following link to download \"\n",
    "            f\"the video<br>{video_link._repr_html_()}\"\n",
    "        )\n",
    "    )\n",
    "    display(Video(comparison_video_path, width=800, embed=True))"
   ],
   "outputs": [],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openvino_env",
   "language": "python",
   "name": "openvino_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}