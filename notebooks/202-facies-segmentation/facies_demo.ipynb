{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Facies segmentation Python Demo\n",
    "\n",
    "This demo demonstrate how to run facies classification using OpenVINO&trade;\n",
    "\n",
    "This model came from seismic interpretation tasks. Fasies is the overall characteristics of a rock unit that reflect its origin and differentiate the unit from others around it.  Mineralogy and sedimentary source, fossil content, sedimentary structures and texture distinguish one facies from another. Data are presented in the 3D arrays."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo Output\n",
    "\n",
    "The application uses Jupyter notebook to display 3d itkwidget with resulting instance classification masks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How It Works\n",
    "Upon the start-up, the demo application loads a network and an given dataset file to the Inference Engine plugin. When inference is done, the application displays 3d itkwidget viewer with facies interpretation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation of dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup virtual-env\n",
    "\n",
    "Step 1: You can install the required packages with the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install prerequinces for the demo\n",
    "import sys\n",
    "!{sys.executable} -m pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "\n",
    "from tqdm import tqdm\n",
    "from itkwidgets import view\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download model:\n",
    "\n",
    "Step 1: Create model folder and download a model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! cd notebooks/202-facies-segmentation\n",
    "! mkdir model\n",
    "! wget -O model/facies-segmentation-deconvnet.bin https://www.dropbox.com/s/x0c7ao8kebxykj1/facies-segmentation-deconvnet.bin?dl=1 \n",
    "! wget -O model/facies-segmentation-deconvnet.xml https://www.dropbox.com/s/g288xdcd7xumqm7/facies-segmentation-deconvnet.xml?dl=1\n",
    "! wget -O model/facies-segmentation-deconvnet.mapping https://www.dropbox.com/s/a7kge25hfpjnhvf/facies-segmentation-deconvnet.mapping?dl=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download dataset:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is used from here: https://github.com/yalaudah/facies_classification_benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download dataset\n",
    "! mkdir data\n",
    "! wget -O data/test2_seismic.npy https://www.dropbox.com/s/sbj2atyukpjgssx/test2_seismic.npy?dl=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_config():\n",
    "    config = defaultdict(str)\n",
    "    config.update({\n",
    "             \"model\": 'model/facies-segmentation-deconvnet.xml',\n",
    "             \"data_path\": 'data/test2_seismic.npy',\n",
    "             \"name_classes\": ['upper_ns', 'middle_ns',\n",
    "                              'lower_ns', 'rijnland_chalk',\n",
    "                              'scruff', 'zechstein'],\n",
    "             \"edge_one\": (0, 30, 0),\n",
    "             \"edge_two\": (500, 199, 244),\n",
    "             \"device\":\"CPU\"})\n",
    "\n",
    "    return config    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(data, mu=0, std=1):\n",
    "    if not isinstance(data, np.ndarray):\n",
    "        data = np.array(data)\n",
    "    data = (data - data.flatten().mean())/data.flatten().std()\n",
    "    return data * std + mu\n",
    "\n",
    "def load_data(config):\n",
    "    data_format = config[\"data_path\"].split('.')[1]\n",
    "    assert not (config[\"data_path\"].split('.')[0] == '' or data_format == ''), \\\n",
    "        f'Invalid path to data file: {config[\"data_path\"]}'\n",
    "    if data_format == 'npy':\n",
    "        data = np.load(config[\"data_path\"])\n",
    "    elif data_format == 'dat':\n",
    "        data = np.fromfile(config[\"data_path\"])\n",
    "    elif data_format == 'segy':\n",
    "        import segyio\n",
    "        data = segyio.tools.cube(config[\"data_path\"])\n",
    "        data = np.moveaxis(data, -1, 0)\n",
    "        data = np.ascontiguousarray(data, 'float32')\n",
    "    else:\n",
    "        assert False, f'Unsupported data format: {data_format}'\n",
    "\n",
    "    data = normalize(data, mu=1e-8, std=0.2097654)\n",
    "    print(f\"[INFO] Dataset has been loaded, shape is {data.shape}\")\n",
    "    print(f\"[INFO] Dataset mean is {data.flatten().mean():.5f}, std {data.flatten().std():.5f}\")\n",
    "    \n",
    "    x_min =  min(config[\"edge_one\"][0], config[\"edge_two\"][0])\n",
    "    x_max =  max(config[\"edge_one\"][0], config[\"edge_two\"][0])\n",
    "    y_min =  min(config[\"edge_one\"][1], config[\"edge_two\"][1])\n",
    "    y_max =  max(config[\"edge_one\"][1], config[\"edge_two\"][1])\n",
    "    z_min =  min(config[\"edge_one\"][2], config[\"edge_two\"][2])\n",
    "    z_max =  max(config[\"edge_one\"][2], config[\"edge_two\"][2])\n",
    "    x_lim, y_lim, z_lim = data.shape\n",
    "    assert x_min >=0 and y_min>=0 and z_min >= 0\n",
    "    assert x_max < x_lim and y_max < y_lim and z_max < z_lim, \"Invalid edges\"\n",
    "    sub_data = data[x_min: x_max , y_min: y_max, z_min: z_max]\n",
    "    return sub_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_model(net, shape, axis=None):\n",
    "    if axis is None:\n",
    "        index_of_dim = np.argmin(shape)\n",
    "    else:\n",
    "        index_of_dim = axis\n",
    "    input_data_shape = list(shape)\n",
    "    del input_data_shape[index_of_dim]\n",
    "\n",
    "    input_net_info = net.input_info\n",
    "    input_name = next(iter(input_net_info))\n",
    "    input_net_shape = input_net_info[input_name].input_data.shape\n",
    "    \n",
    "    print(f\"[INFO] Infer should be on {input_data_shape} resolution\")\n",
    "    if input_data_shape != input_net_shape[-2:]:\n",
    "        net.reshape({input_name: [1, 1, *input_data_shape]})\n",
    "        print(f\"[INFO] Reshaping model to fit for slice shape: {input_data_shape}\")\n",
    "    else:\n",
    "        print(f\"[INFO] Use not reshaped model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_cube(exec_net, data, axis=None):\n",
    "    if axis is None:\n",
    "        index_of_dim = np.argmin(data.shape)\n",
    "    else:\n",
    "        index_of_dim = axis\n",
    "    predicted_cube = np.empty(data.shape)\n",
    "    size = data.shape[index_of_dim]\n",
    "    for slice_index in tqdm(range(size)):\n",
    "        if index_of_dim == 0:\n",
    "            inp = data[slice_index, :, :]\n",
    "            out = exec_net.infer(inputs={'input': inp})['output']\n",
    "            out = np.argmax(out, axis=1).squeeze()\n",
    "            predicted_cube[slice_index, :, :] = out\n",
    "        if index_of_dim == 1:\n",
    "            inp = data[:, slice_index, :]\n",
    "            out = exec_net.infer(inputs={'input': inp})['output']\n",
    "            out = np.argmax(out, axis=1).squeeze()\n",
    "            predicted_cube[:, slice_index, :] = out\n",
    "        if index_of_dim == 2:\n",
    "            inp = data[:, :, slice_index]\n",
    "            out = exec_net.infer(inputs={'input': inp})['output']\n",
    "            out = np.argmax(out, axis=1).squeeze()\n",
    "            predicted_cube[:, :, slice_index] = out\n",
    "    return predicted_cube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discrete_cmap(N, base_cmap=None):\n",
    "    \"\"\"Create an N-bin discrete colormap from the specified input map\"\"\"\n",
    "\n",
    "    # Note that if base_cmap is a string or None, you can simply do\n",
    "    #    return plt.cm.get_cmap(base_cmap, N)\n",
    "    # The following works for string, None, or a colormap instance:\n",
    "\n",
    "    base = plt.cm.get_cmap(base_cmap)\n",
    "    color_list = base(np.linspace(0, 1, N))\n",
    "    cmap_name = base.name + str(N)\n",
    "    return base.from_list(cmap_name, color_list, N)\n",
    "\n",
    "def show_legend(N, cmap_name):\n",
    "    base = plt.cm.get_cmap(cmap_name)\n",
    "    color_list = base(np.linspace(0, 1, N))\n",
    "    print(color_list)\n",
    "    \n",
    "def show_legend(labels, cmap):\n",
    "    N = len(labels)\n",
    "    fig = plt.figure(figsize=(12, 6))\n",
    "    ax1 = fig.add_axes([0.05, 0.80, 0.9, 0.15])\n",
    "    cb1 = mpl.colorbar.ColorbarBase(ax1, cmap=cmap,\n",
    "                                    ticks=np.arange(0, N, 1)/N + 1/(2*N),\n",
    "                                    orientation='horizontal')\n",
    "    cb1.ax.set_xticklabels(labels, fontsize = 20)\n",
    "    cb1.set_label('Legend', fontsize = 24)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get config and load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = get_config()\n",
    "data = load_data(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openvino_extensions import get_extensions_path\n",
    "from openvino.inference_engine import IECore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ie = IECore()\n",
    "ie.add_extension(get_extensions_path(), \"CPU\")\n",
    "net = ie.read_network(config[\"model\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reshape_model(net, data.shape, axis=1)\n",
    "exec_net = ie.load_network(network=net, device_name=config[\"device\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_data = infer_cube(exec_net, data, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the inference of the model is running. Slices along the axis 1 are fed to the input and the result is combined into an output cube (`predicted_data`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize original and predicted data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Prepare origidal data viewer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer_orig_data = view(data, shadow=False)\n",
    "count_of_greys = 100\n",
    "viewer_orig_data.cmap = np.array([[i/count_of_greys, i/count_of_greys, i/count_of_greys] for i\n",
    "                                  in range(count_of_greys)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Prepare predicted data viewer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = discrete_cmap(len(config[\"name_classes\"]), 'jet')\n",
    "show_legend(config[\"name_classes\"], cmap)\n",
    "viewer_interpret_data = view(predicted_data, shadow=False)\n",
    "viewer_interpret_data.cmap = cmap\n",
    "widgets.link((viewer_interpret_data, 'camera'), (viewer_orig_data, 'camera')) # link widget cameras\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Run render"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer_interpret_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer_orig_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can now see a visualization of the interpreted and raw seismic data. You can interactively use your mouse to rotate or zoom in and explore interpretated data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openvino_env",
   "language": "python",
   "name": "openvino_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
