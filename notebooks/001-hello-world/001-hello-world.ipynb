{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "291dc37b",
   "metadata": {},
   "source": [
    "# Hello Image Classification\n",
    "\n",
    "A very basic introduction to OpenVINO that shows how to perform inference with an image classification model.\n",
    "\n",
    "We use a pre-trained [MobileNetV3 model](https://docs.openvinotoolkit.org/latest/omz_models_model_mobilenet_v3_small_1_0_224_tf.html) from the [Open Model Zoo](https://github.com/openvinotoolkit/open_model_zoo/). See the [TensorFlow to OpenVINO](101-tensorflow-to-openvino) tutorial to learn more about how this OpenVINO IR model was created."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c8cbe5",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ee9436",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from openvino.inference_engine import IECore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e49ae7",
   "metadata": {},
   "source": [
    "## Load the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c4d6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ie = IECore()\n",
    "net = ie.read_network(\n",
    "    model=\"model/v3-small_224_1.0_float.xml\", weights=\"model/v3-small_224_1.0_float.bin\"\n",
    ")\n",
    "exec_net = ie.load_network(network=net, device_name=\"CPU\")\n",
    "\n",
    "input_key = next(iter(exec_net.input_info))\n",
    "output_key = next(iter(exec_net.outputs.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a19fc080",
   "metadata": {},
   "source": [
    "## Load an Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca45b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The MobileNet network expects images in RGB format\n",
    "image = cv2.cvtColor(cv2.imread(filename=\"data/coco.jpg\"), code=cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# resize to MobileNet image shape\n",
    "input_image = cv2.resize(src=image, dsize=(224, 224))\n",
    "\n",
    "# reshape to network input shape\n",
    "input_image = np.expand_dims(input_image.transpose(2, 0, 1), 0)\n",
    "plt.imshow(image);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be327b6",
   "metadata": {},
   "source": [
    "## Do Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed78a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = exec_net.infer(inputs={input_key: input_image})[output_key]\n",
    "result_index = np.argmax(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf29578c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the inference result to a class name.\n",
    "imagenet_classes = json.loads(open(\"utils/imagenet_class_index.json\").read())\n",
    "\n",
    "# The model description states that for this model, class 0 is background,\n",
    "# so we add 1 to the network output to get the class name\n",
    "imagenet_classes = {int(key) + 1: value for key, value in imagenet_classes.items()}\n",
    "imagenet_classes[result_index]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openvino_env",
   "language": "python",
   "name": "openvino_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
