{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "miniature-figure",
   "metadata": {},
   "source": [
    "# Hello World\n",
    "\n",
    "A very basic introduction to OpenVINO that shows how to do inference on a given IR model.\n",
    "\n",
    "We use a [MobileNetV3 model](https://docs.openvinotoolkit.org/latest/omz_models_model_mobilenet_v3_small_1_0_224_tf.html) from [Open Model Zoo](https://github.com/openvinotoolkit/open_model_zoo/). See the [Tensorflow to OpenVINO Notebook](101-tensorflow-to-openvino) for information on how this OpenVINO IR model was created.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "narrative-officer",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "european-delivery",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from openvino.inference_engine import IECore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spiritual-bouquet",
   "metadata": {},
   "source": [
    "## Load the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "statewide-growth",
   "metadata": {},
   "outputs": [],
   "source": [
    "ie = IECore()\n",
    "net = ie.read_network(\n",
    "    model=\"v3-small_224_1.0_float.xml\", weights=\"v3-small_224_1.0_float.bin\"\n",
    ")\n",
    "exec_net = ie.load_network(net, \"CPU\")\n",
    "\n",
    "input_key = list(exec_net.input_info)[0]\n",
    "output_key = list(exec_net.outputs.keys())[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "convertible-literacy",
   "metadata": {},
   "source": [
    "## Load an Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "simplified-accommodation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The MobileNet network expects images in RGB format\n",
    "image = cv2.cvtColor(cv2.imread(\"coco.jpg\"), cv2.COLOR_BGR2RGB)\n",
    "input_image = cv2.resize(image, (224, 224))  # resize to MobileNet image shape\n",
    "input_image = np.expand_dims(\n",
    "    input_image.transpose(2, 0, 1), 0\n",
    ")  # reshape to network input shape\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "warming-platinum",
   "metadata": {},
   "source": [
    "## Do Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "italic-comment",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = exec_net.infer(inputs={input_key: input_image})[output_key]\n",
    "result_index = np.argmax(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complicated-command",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the inference result to a class name.\n",
    "imagenet_classes = json.loads(open(\"imagenet_class_index.json\").read())\n",
    "# The model description states that for this model, class 0 is background,\n",
    "# so we add 1 to the network output to get the class name\n",
    "imagenet_classes = {\n",
    "    int(key) + 1: value for key, value in imagenet_classes.items()\n",
    "}\n",
    "imagenet_classes[result_index]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openvino_env",
   "language": "python",
   "name": "openvino_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
