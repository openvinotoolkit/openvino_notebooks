# Visual Question Answering and Image Captioning using BLIP and OpenVINO
[BLIP](https://arxiv.org/abs/2201.12086) is a pre-training framework for unified vision-language understanding and generation, which achieves state-of-the-art results on a wide range of vision-language tasks.
This tutorial considers ways to use BLIP for visual question answering and image captioning.

The complete pipeline of this demo is shown below:

## Image Captioning

<p align="center">
    <img src="https://user-images.githubusercontent.com/29454499/221865836-a56da06e-196d-449c-a5dc-4136da6ab5d5.png"/>
</p>

The following image shows an example of the input image and generated caption:

<p align="center">
    <img src="https://user-images.githubusercontent.com/29454499/221933471-5c06cc51-073c-48af-b514-bddce1a89aaa.png"/>
</p>

## Visual Question Answering

<p align="center">
    <img src="https://user-images.githubusercontent.com/29454499/221868167-d0081add-d9f3-4591-80e7-4753c88c1d0a.png"/>
</p>
The following image shows an example of the input image, question and answer generated by model

<p align="center">
    <img src="https://user-images.githubusercontent.com/29454499/221933762-4ff32ecb-5e5d-4484-80e1-e9396cb3c511.png"/>
</p>


## Notebook Contents

This folder contains two notebooks that show how to convert and optimize model with OpenVINO:

1. [Convert the BLIP model using OpenVINO](233-blip-convert.ipynb)
2. [Optimize the OpenVINO BLIP model using NNCF](233-blip-optimize.ipynb)

The first notebook consists of the following parts:

1. Instantiate a BLIP model.
2. Convert the BLIP model to OpenVINO IR.
3. Run visual question answering and image captioning with OpenVINO.

The second notebook consists of the following parts:

1. Download and preprocess dataset for quantization.
2. Quantize the converted vision and text encoder OpenVINO models from [notebook](233-blip-convert.ipynb) with NNCF.
3. Compress weights of the OpenVINO text decoder model from [notebook](233-blip-convert.ipynb) with NNCF.
4. Check the model result using the same input data from the [notebook](233-blip-convert.ipynb).
5. Compare model size of converted and optimized models.
6. Compare performance of converted and optimized models.

NNCF performs optimization within the OpenVINO IR. It is required to run the [first notebook](233-blip-convert.ipynb) before running the [second notebook](233-blip-optimize.ipynb).

## Installation Instructions

This is a self-contained example that relies solely on its own code.</br>
We recommend running the notebook in a virtual environment. You only need a Jupyter server to start.
For details, please refer to [Installation Guide](../../README.md).
