{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# License Plate Recognition with OpenVINO\n",
    "\n",
    "This notebook demonstrates license plate recognition with OpenVINO. We use the [License Plate Recognition Model](https://docs.openvino.ai/2020.2/_models_intel_license_plate_recognition_barrier_0001_description_license_plate_recognition_barrier_0001.html) from [Open Model Zoo](https://github.com/openvinotoolkit/open_model_zoo/). This model uses a small-footprint network trained end-to-end to recognize Chinese license plates in traffic.\n",
    "\n",
    "License plate recognition model helps you get the chinese license plate number precisely in no time. The input of the color license plate image can be any size. It will be resized and augmented before put into the model. After matching the result to correct character, we can get the license plate number. In the notebook we show how to create the following pipeline:\n",
    "\n",
    "![flowchart.png](https://user-images.githubusercontent.com/15709723/162659593-3f620d7a-44d2-4f49-a558-94c35a244a8e.png)\n",
    "\n",
    "> Note: Augmentation method on image is optional and it may lead to the wrong recognition result. Thus, we recommend you to use it under special conditions like image overexposure or too dark.\n",
    "\n",
    "Example image data comes from [CCPD (Chinese City Parking Dataset, ECCV)](https://github.com/detectRecog/CCPD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import cv2\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from openvino.runtime import Core"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Model\n",
    "\n",
    "### Download the Model\n",
    "\n",
    "We use `omz_downloader`, the tool from the `openvino-dev` package to download the selected model. It will be retrieved from the cache if the model is already downloaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# directory where model will be downloaded\n",
    "base_model_dir = \"model\"\n",
    "\n",
    "# model name as named in Open Model Zoo\n",
    "model_name = \"license-plate-recognition-barrier-0001\"\n",
    "\n",
    "# it will be retrieved from the cache if the model is already downloaded.\n",
    "download_command = (\n",
    "    f\"omz_downloader \"\n",
    "    f\"--name {model_name} \"\n",
    "    f\"--output_dir {base_model_dir} \"\n",
    "    f\"--cache_dir {base_model_dir}\"\n",
    ")\n",
    "\n",
    "# this code is provided for the first download of the model\n",
    "! $download_command"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Model\n",
    "\n",
    "First, we create an Inference Engine. Then we read the network architecture and model weights from the .bin and .xml files to compile for the desired device. You can choose manually CPU, GPU, MYRIAD etc.\n",
    "\n",
    "If you wnat OpenVINO to decide which hardware offers the best performance, you need to use `AUTO`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# \"FP16\", \"FP32\" or \"FP16-INT8\"\n",
    "precision = \"FP16\"\n",
    "# output path for the conversion\n",
    "converted_model_path = f\"model/intel/{model_name}/{precision}/{model_name}.xml\"\n",
    "\n",
    "# initialize inference engine\n",
    "ie_core = Core()\n",
    "# read the network and corresponding weights from file\n",
    "model = ie_core.read_model(model=converted_model_path)\n",
    "# compile the model for the CPU (you can choose manually CPU, GPU, MYRIAD etc.)\n",
    "# or let the engine choose the best available device (AUTO)\n",
    "compiled_model = ie_core.compile_model(model=model, device_name=\"CPU\")\n",
    "\n",
    "# get input and output nodes\n",
    "input_layer = next(iter(compiled_model.inputs))\n",
    "output_layer = next(iter(compiled_model.outputs))\n",
    "\n",
    "# get input size\n",
    "input_height, input_width = list(input_layer.shape)[2:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "## Inference\n",
    "\n",
    "### Using ImageLoader to Process Image\n",
    "\n",
    "\n",
    "#### Model Limitations:\n",
    "Only \"blue\" license plates, which are common in public, were tested thoroughly. Other types of license plates may underperform.\n",
    "\n",
    "\n",
    "#### Model Input:\n",
    "\n",
    "name: \"data\" , shape: [1x3x24x94] - An input image in following format [1xCxHxW]. Expected color order is BGR.\n",
    "\n",
    "name: \"seq_ind\" , shape: [88,1] - An auxiliary blob that is needed for correct decoding. Set this to [0, 1, 1, ..., 1].\n",
    "\n",
    "#### Notes:\n",
    "Since the license plate image could be any size, we need to use ImageLoader to resize it to fit the model input requirements.\n",
    "Augmentation method on image is optional and it may lead to the wrong recognition result. Thus, we recommend you to use it under special conditions like image overexposure or too dark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ShowImage(\n",
    "    OriginImage: np.ndarray, InputImage: np.ndarray\n",
    ") -> matplotlib.figure.Figure:\n",
    "    \"\"\"\n",
    "    Visualise how the image we processed.\n",
    "\n",
    "    Args:\n",
    "        OriginImage (np.ndarray): Any size of color image.\n",
    "        InputImage (np.ndarray): The input of the model before dimension transposed and expanded.\n",
    "\n",
    "    Returns:\n",
    "        Matplotlib figure.\n",
    "    \"\"\"\n",
    "    figure, axis = plt.subplots(1, 2, figsize=(18, 9), squeeze=False)\n",
    "    \n",
    "    # adjust the image channels to the correct order.\n",
    "    b,g,r = cv2.split(OriginImage)\n",
    "    OriginImage = cv2.merge((r,g,b))\n",
    "    axis[0, 0].imshow(OriginImage)\n",
    "    axis[0, 0].set_title(\"OriginImage\")\n",
    "    \n",
    "    # adjust the image channels to the correct order.\n",
    "    b,g,r = cv2.split(InputImage)\n",
    "    InputImage = cv2.merge((r,g,b))\n",
    "    axis[0, 1].imshow(InputImage)\n",
    "    axis[0, 1].set_title(\"InputImage\")\n",
    "    \n",
    "    return figure\n",
    "\n",
    "\n",
    "def ImageLoader(ImagePath: str, Augmentation: str=\"None\") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Process the image if neccessary and then\n",
    "    resize its shape to fit the input requirements.\n",
    "\n",
    "    Args:\n",
    "        ImagePath (string): Relative storage path of color image.\n",
    "        Augmentation (string): Image augmentation method, if 'None', do nothing.\n",
    "                    Including 'None', 'Laplace', 'Log', 'Gamma' and 'EquaHist'.\n",
    "\n",
    "    Returns:\n",
    "        input_img (np.ndarray): The input of the model. The dimension is 1x3x24x94.\n",
    "\n",
    "    \"\"\"\n",
    "    ori_img = cv2.imread(ImagePath,1)\n",
    "\n",
    "    # if gray image passed in, the programme will stop.\n",
    "    assert len(ori_img.shape) == 3, \"Failed to load image.\"\n",
    "    print(f\"Origin image shape: {ori_img.shape}\")\n",
    "\n",
    "    # if invalid augmentation method passed in, the programme will stop.\n",
    "    assert Augmentation in [\n",
    "        \"None\",\n",
    "        \"Laplace\",\n",
    "        \"Log\",\n",
    "        \"Gamma\",\n",
    "        \"EquaHist\",\n",
    "    ], \"Invalid Augmentation.\"\n",
    "\n",
    "    if Augmentation == \"None\":\n",
    "        img = ori_img\n",
    "\n",
    "    elif Augmentation == \"Laplace\":\n",
    "        kernel_sharpen = np.array([[0, 1, 0], [1, -4, 1], [0, 1, 0]])\n",
    "        img = cv2.filter2D(ori_img, -1, kernel_sharpen)\n",
    "\n",
    "    elif Augmentation == \"Log\":\n",
    "        img = 42 * np.log(1.0 + ori_img)\n",
    "        img = np.uint8(img + 0.5)\n",
    "\n",
    "    elif Augmentation == \"Gamma\":\n",
    "        lut = np.zeros(256, dtype=np.float32)\n",
    "        for i in range(256):\n",
    "            lut[i] = 0.00000005 * i**4.0\n",
    "        img = cv2.LUT(ori_img, lut)\n",
    "        img = np.uint8(img + 0.5)\n",
    "\n",
    "    elif Augmentation == \"EquaHist\":\n",
    "        img0 = cv2.equalizeHist(ori_img[:, :, 0])\n",
    "        img1 = cv2.equalizeHist(ori_img[:, :, 1])\n",
    "        img2 = cv2.equalizeHist(ori_img[:, :, 2])\n",
    "\n",
    "        img = cv2.merge([img0, img1, img2])\n",
    "\n",
    "    # resize its shape to fit the model input requirements.\n",
    "    resized_img = cv2.resize(img, (input_width, input_height))\n",
    "\n",
    "    # visualise how the image we process.\n",
    "    ShowImage(ori_img, resized_img)\n",
    "    trans_img = resized_img.transpose(2, 0, 1)\n",
    "    input_img = np.expand_dims(trans_img, axis=0)\n",
    "    return input_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do the Inference\n",
    "Match the output array into correct recognition results\n",
    "Run license plate recognition model with the input and then match the result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Process the Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_img = ImageLoader(ImagePath=\"data/example.png\", Augmentation=\"None\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Input the Data and Get the Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# an auxiliary blob that is needed for correct decoding.\n",
    "# Set this to [0, 1, 1, ..., 1].\n",
    "auxiliary_blob = np.array([0] + [1]*87)\n",
    "# resize it to fit the shape: [88,1].\n",
    "auxiliary_blob = np.resize(88,(88,1))\n",
    "\n",
    "# get the result.\n",
    "result = compiled_model([input_img, auxiliary_blob])[output_layer]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Match the Output Array into Correct Recognition Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def result_to_string(result: np.ndarray) -> str:\n",
    "    \"\"\"\n",
    "    Match the output array into correct recognition results.\n",
    "\n",
    "    Args:\n",
    "        result (np.ndarray): The output of the model. The dimension is 1x88x1x1.\n",
    "\n",
    "    Returns:\n",
    "        str: The license plate recognition results.\n",
    "    \"\"\"\n",
    "    match_dictionary = [\n",
    "        \"0\",\n",
    "        \"1\",\n",
    "        \"2\",\n",
    "        \"3\",\n",
    "        \"4\",\n",
    "        \"5\",\n",
    "        \"6\",\n",
    "        \"7\",\n",
    "        \"8\",\n",
    "        \"9\",\n",
    "        \"<Anhui>\",\n",
    "        \"<Beijing>\",\n",
    "        \"<Chongqing>\",\n",
    "        \"<Fujian>\",\n",
    "        \"<Gansu>\",\n",
    "        \"<Guangdong>\",\n",
    "        \"<Guangxi>\",\n",
    "        \"<Guizhou>\",\n",
    "        \"<Hainan>\",\n",
    "        \"<Hebei>\",\n",
    "        \"<Heilongjiang>\",\n",
    "        \"<Henan>\",\n",
    "        \"<HongKong>\",\n",
    "        \"<Hubei>\",\n",
    "        \"<Hunan>\",\n",
    "        \"<InnerMongolia>\",\n",
    "        \"<Jiangsu>\",\n",
    "        \"<Jiangxi>\",\n",
    "        \"<Jilin>\",\n",
    "        \"<Liaoning>\",\n",
    "        \"<Macau>\",\n",
    "        \"<Ningxia>\",\n",
    "        \"<Qinghai>\",\n",
    "        \"<Shaanxi>\",\n",
    "        \"<Shandong>\",\n",
    "        \"<Shanghai>\",\n",
    "        \"<Shanxi>\",\n",
    "        \"<Sichuan>\",\n",
    "        \"<Tianjin>\",\n",
    "        \"<Tibet>\",\n",
    "        \"<Xinjiang>\",\n",
    "        \"<Yunnan>\",\n",
    "        \"<Zhejiang>\",\n",
    "        \"<police>\",\n",
    "        \"A\",\n",
    "        \"B\",\n",
    "        \"C\",\n",
    "        \"D\",\n",
    "        \"E\",\n",
    "        \"F\",\n",
    "        \"G\",\n",
    "        \"H\",\n",
    "        \"I\",\n",
    "        \"J\",\n",
    "        \"K\",\n",
    "        \"L\",\n",
    "        \"M\",\n",
    "        \"N\",\n",
    "        \"O\",\n",
    "        \"P\",\n",
    "        \"Q\",\n",
    "        \"R\",\n",
    "        \"S\",\n",
    "        \"T\",\n",
    "        \"U\",\n",
    "        \"V\",\n",
    "        \"W\",\n",
    "        \"X\",\n",
    "        \"Y\",\n",
    "        \"Z\",\n",
    "    ]\n",
    "    str_list = list()\n",
    "    for iter in range(88):\n",
    "        if result[0][iter][0][0] != -1:\n",
    "            str_list.append(match_dictionary[int(result[0][iter][0][0])])\n",
    "        else:\n",
    "            break\n",
    "    ans = \"\".join(str_list)\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print out the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the result.\n",
    "plate_recognition = result_to_string(result)\n",
    "\n",
    "# print out the match result.\n",
    "print(f\"The license plate recognition result is: {plate_recognition}\")\n",
    "\n",
    "# compare to the origin image.\n",
    "compare = cv2.imread(\"data/example.png\")\n",
    "\n",
    "# adjust the image channels to the correct order.\n",
    "b,g,r = cv2.split(compare)\n",
    "compare = cv2.merge((r,g,b))\n",
    "plt.imshow(compare)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## References\n",
    "\n",
    "1. [License Plate Recognition Model](https://docs.openvino.ai/2020.2/_models_intel_license_plate_recognition_barrier_0001_description_license_plate_recognition_barrier_0001.html)\n",
    "2. [Open Model Zoo](https://github.com/openvinotoolkit/open_model_zoo/)\n",
    "3. [403-action-recognition-webcam](https://github.com/openvinotoolkit/openvino_notebooks/blob/main/notebooks/403-action-recognition-webcam/403-action-recognition-webcam.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
