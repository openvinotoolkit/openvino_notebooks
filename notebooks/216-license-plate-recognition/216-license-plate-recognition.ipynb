{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# License Plate Recognition with OpenVINOâ„¢\n",
    "\n",
    "This notebook demonstrates license plate recognition with OpenVINO, using the [License Plate Recognition Model](https://github.com/openvinotoolkit/open_model_zoo/tree/master/models/intel/license-plate-recognition-barrier-0001) from [Open Model Zoo](https://github.com/openvinotoolkit/open_model_zoo/). This model uses a small-footprint network trained end-to-end to recognize Chinese license plates in traffic.\n",
    "\n",
    "License plate recognition model helps you get the Chinese license plate number precisely in no time. The input of the color license plate image can be of any size. It will be resized and augmented before being put into the model. After matching the result to correct character, you can get the license plate number. The  notebook shows how to create the following pipeline:\n",
    "\n",
    "![flowchart.png](https://user-images.githubusercontent.com/15709723/162659593-3f620d7a-44d2-4f49-a558-94c35a244a8e.png)\n",
    "\n",
    "> **Note**: Augmentation method on image is optional and it may lead to the wrong recognition result. Therefore, it is recommended to use it under special conditions, such as image being overexposed or too dark.\n",
    "\n",
    "Example image data comes from [CCPD (Chinese City Parking Dataset, ECCV)](https://github.com/detectRecog/CCPD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from openvino.runtime import Core"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Model\n",
    "\n",
    "### Download the Model\n",
    "\n",
    "Use the `omz_downloader` tool from the `openvino-dev` package to download the selected model. If the model is already downloaded, it will be retrieved from the cache."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# A directory where the model will be downloaded.\n",
    "base_model_dir = \"model\"\n",
    "\n",
    "# The name of the model from Open Model Zoo.\n",
    "model_name = \"license-plate-recognition-barrier-0001\"\n",
    "\n",
    "# Selected precision (FP32, FP16, FP16-INT8).\n",
    "precision = \"FP16\"\n",
    "\n",
    "# It will be retrieved from the cache if the model is already downloaded.\n",
    "download_command = (\n",
    "    f\"omz_downloader \"\n",
    "    f\"--name {model_name} \"\n",
    "    f\"--precision {precision} \"\n",
    "    f\"--output_dir {base_model_dir} \"\n",
    "    f\"--cache_dir {base_model_dir}\"\n",
    ")\n",
    "\n",
    "# This code is provided for the first download of the model.\n",
    "! $download_command"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Model\n",
    "\n",
    "First, initialize OpenVINO Runtime. Then, read the network architecture and model weights from the `.bin` and `.xml` files to compile for the desired device. You can choose manually CPU, GPU, MYRIAD etc.\n",
    "\n",
    "If you want OpenVINO to decide which hardware offers the best performance, you need to use `AUTO`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# The output path for the conversion\n",
    "converted_model_path = f\"model/intel/{model_name}/{precision}/{model_name}.xml\"\n",
    "\n",
    "# Initialize OpenVINO Runtime\n",
    "ie_core = Core()\n",
    "# Read the network and corresponding weights from a file.\n",
    "model = ie_core.read_model(model=converted_model_path)\n",
    "# Compile the model for the CPU (you can choose manually CPU, GPU, MYRIAD etc.)\n",
    "# or let the engine choose the best available device (AUTO).\n",
    "compiled_model = ie_core.compile_model(model=model, device_name=\"CPU\")\n",
    "\n",
    "# Get input and output nodes.\n",
    "input_layer = compiled_model.input(0)\n",
    "output_layer = compiled_model.output(0)\n",
    "\n",
    "# Get the input size.\n",
    "input_height, input_width = list(input_layer.shape)[2:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "## Inference\n",
    "\n",
    "### Using ImageLoader to Process Image\n",
    "\n",
    "*Model Limitations: Only \"blue\" license plates, which are common in public, were tested thoroughly. Other types of license plates may underperform.*\n",
    "\n",
    "#### Model Input:\n",
    "\n",
    "name: \"data\" , shape: [1x3x24x94] - An input image in following format [1xCxHxW]. Expected color order is `BGR`.\n",
    "\n",
    "name: \"seq_ind\" , shape: [88, 1] - An auxiliary blob that is needed for correct decoding. Set this to `[1, 1, ..., 1]`.\n",
    "\n",
    "> **Notes**: Since the license plate image could be of any size, use ImageLoader to resize it to fit the model input requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(\n",
    "    origin_image: np.ndarray, input_image: np.ndarray\n",
    ") -> matplotlib.figure.Figure:\n",
    "    \"\"\"\n",
    "    Visualise how the image we processed.\n",
    "\n",
    "    :param origin_image: Any size of color image.\n",
    "    :param input_image: The input of the model before dimension transposed and expanded.\n",
    "    :returns: Matplotlib figure.\n",
    "    \"\"\"\n",
    "    figure, axis = plt.subplots(1, 2, figsize=(18, 9), squeeze=False)\n",
    "    \n",
    "    # Adjust the image channels to the correct order.\n",
    "    origin_image = cv2.cvtColor(origin_image, cv2.COLOR_BGR2RGB)\n",
    "    axis[0, 0].imshow(origin_image)\n",
    "    axis[0, 0].set_title(\"Source Image\")\n",
    "    \n",
    "    # Adjust the image channels to the correct order.\n",
    "    input_image = cv2.cvtColor(input_image, cv2.COLOR_BGR2RGB)\n",
    "    axis[0, 1].imshow(input_image)\n",
    "    axis[0, 1].set_title(\"Input Image\")\n",
    "    \n",
    "    return figure\n",
    "\n",
    "\n",
    "def image_loader(image_path: str, augmentation: str = \"None\") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Process the image if neccessary and then\n",
    "    resize its shape to fit the input requirements.\n",
    "\n",
    "    :param image_path: Relative storage path of color image.\n",
    "    :param augmentation: Image augmentation method, if 'None', do nothing.\n",
    "                         Including 'None', 'Laplace' and 'EquaHist'.\n",
    "    :returns: The input of the model. The dimension is 1x3x24x94.\n",
    "\n",
    "    \"\"\"\n",
    "    ori_img = cv2.imread(image_path, 1)\n",
    "\n",
    "    # If a gray image passed in, the program will stop.\n",
    "    assert len(ori_img.shape) == 3, \"Failed to load image.\"\n",
    "    print(f\"Origin image shape: {ori_img.shape}\")\n",
    "\n",
    "    # If an invalid augmentation method passed in, the program will stop.\n",
    "    assert augmentation in [\n",
    "        \"None\",\n",
    "        \"Laplace\",\n",
    "        \"EquaHist\"\n",
    "    ], \"Invalid Augmentation.\"\n",
    "\n",
    "    if augmentation == \"None\":\n",
    "        img = ori_img\n",
    "\n",
    "    elif augmentation == \"Laplace\":\n",
    "        kernel_sharpen = np.array([[0, 1, 0], [1, -4, 1], [0, 1, 0]])\n",
    "        img = cv2.filter2D(ori_img, -1, kernel_sharpen)\n",
    "\n",
    "    elif augmentation == \"EquaHist\":\n",
    "        img0 = cv2.equalizeHist(ori_img[:, :, 0])\n",
    "        img1 = cv2.equalizeHist(ori_img[:, :, 1])\n",
    "        img2 = cv2.equalizeHist(ori_img[:, :, 2])\n",
    "\n",
    "        img = cv2.merge([img0, img1, img2])\n",
    "\n",
    "    # Resize its shape to fit the model input requirements.\n",
    "    resized_img = cv2.resize(img, (input_width, input_height))\n",
    "\n",
    "    # Visualize the way the image is processed.\n",
    "    show_image(origin_image=ori_img, input_image=resized_img)\n",
    "    trans_img = resized_img.transpose(2, 0, 1)\n",
    "    input_img = np.expand_dims(trans_img, axis=0)\n",
    "    return input_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do the Inference\n",
    "Match the output array into correct recognition results. \n",
    "Run license plate recognition model with the input and then match the result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Process the Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# The path of the test license plate image.\n",
    "test_image_path = \"data/example.png\"\n",
    "\n",
    "input_img = image_loader(image_path=test_image_path, augmentation=\"None\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Input the Data and Get the Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An auxiliary blob that is needed for correct decoding.\n",
    "# Set this to [1, 1, ..., 1].\n",
    "auxiliary_blob = np.array([1] * 88)\n",
    "# Resize it to fit the shape: [88, 1].\n",
    "auxiliary_blob = np.resize(auxiliary_blob, (88, 1))\n",
    "\n",
    "# Get the result.\n",
    "result = compiled_model([input_img, auxiliary_blob])[output_layer]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Match the Output Array into Correct Recognition Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def result_to_string(result: np.ndarray) -> str:\n",
    "    \"\"\"\n",
    "    Match the output array into correct recognition results.\n",
    "\n",
    "    :param result: The output of the model. The dimension is 1x88x1x1.\n",
    "    :returns: The license plate recognition results.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Each float is an integer number encoding a character according to this dictionary.\n",
    "    match_dictionary = open(\"data/match_dictionary.txt\").read().splitlines()\n",
    "    str_list = list()\n",
    "    \n",
    "    # The result is an encoded vector of floats. Its shape is [1, 88, 1, 1].\n",
    "    for idx in result.flatten():\n",
    "        if idx != -1:\n",
    "            str_list.append(match_dictionary[int(idx)])\n",
    "        else:\n",
    "            break\n",
    "            \n",
    "    ans = \"\".join(str_list)\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print out the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the result.\n",
    "plate_recognition = result_to_string(result)\n",
    "\n",
    "# Print out the match result.\n",
    "print(f\"The license plate recognition result is: {plate_recognition}\")\n",
    "\n",
    "# Compare to the origin image.\n",
    "compare = cv2.imread(test_image_path)\n",
    "\n",
    "# Adjust the image channels to the correct order.\n",
    "compare = cv2.cvtColor(compare, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(compare)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## References\n",
    "\n",
    "1. [License Plate Recognition Model](https://github.com/openvinotoolkit/open_model_zoo/tree/master/models/intel/license-plate-recognition-barrier-0001)\n",
    "2. [Open Model Zoo](https://github.com/openvinotoolkit/open_model_zoo/)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
