{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Pose estimation with OpenVINO\n",
    "\n",
    "This notebook demonstrates live pose estimation in OpenVINO.\n",
    "\n",
    "We use [this](https://github.com/openvinotoolkit/open_model_zoo/tree/master/models/intel/human-pose-estimation-0001) pose estimation model from [Open Model Zoo](https://github.com/openvinotoolkit/open_model_zoo/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from IPython import display\n",
    "from numpy.lib.stride_tricks import as_strided\n",
    "from openvino import inference_engine as ie\n",
    "\n",
    "from decoder import OpenPoseDecoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Download model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "base_model_dir = \"model\"\n",
    "\n",
    "model_name = \"human-pose-estimation-0001\"\n",
    "precision = \"FP16\"\n",
    "\n",
    "download_command = f\"omz_downloader --name {model_name} --precision {precision} --output_dir {base_model_dir}\"\n",
    "! $download_command"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model_path = \"model/intel/human-pose-estimation-0001/FP16/human-pose-estimation-0001.xml\"\n",
    "model_weights_path = \"model/intel/human-pose-estimation-0001/FP16/human-pose-estimation-0001.bin\"\n",
    "\n",
    "# initialize inference engine\n",
    "ie_core = ie.IECore()\n",
    "# read the network and corresponding weights from file\n",
    "net = ie_core.read_network(model=model_path, weights=model_weights_path)\n",
    "# load the model on the CPU (you can use GPU or MYRIAD as well)\n",
    "exec_net = ie_core.load_network(net, \"CPU\")\n",
    "\n",
    "# get input and output names of nodes\n",
    "input_key = list(exec_net.input_info)[0]\n",
    "output_keys = list(exec_net.outputs.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "input_key, output_keys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### OpenPoseDecoder\n",
    "\n",
    "Open Pose Decoder from [OpenVINO Model Zoo](https://github.com/openvinotoolkit/open_model_zoo/blob/master/demos/common/python/models/open_pose.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "decoder = OpenPoseDecoder()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Result processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 2d pooling in numpy (from: https://stackoverflow.com/a/54966908/1624463)\n",
    "def pool2d(A, kernel_size, stride, padding, pool_mode=\"max\"):\n",
    "    \"\"\"\n",
    "    2D Pooling\n",
    "\n",
    "    Parameters:\n",
    "        A: input 2D array\n",
    "        kernel_size: int, the size of the window\n",
    "        stride: int, the stride of the window\n",
    "        padding: int, implicit zero paddings on both sides of the input\n",
    "        pool_mode: string, 'max' or 'avg'\n",
    "    \"\"\"\n",
    "    # Padding\n",
    "    A = np.pad(A, padding, mode=\"constant\")\n",
    "\n",
    "    # Window view of A\n",
    "    output_shape = (\n",
    "        (A.shape[0] - kernel_size) // stride + 1,\n",
    "        (A.shape[1] - kernel_size) // stride + 1,\n",
    "    )\n",
    "    kernel_size = (kernel_size, kernel_size)\n",
    "    A_w = as_strided(A, shape=output_shape + kernel_size, strides=(stride * A.strides[0], stride * A.strides[1]) + A.strides)\n",
    "    A_w = A_w.reshape(-1, *kernel_size)\n",
    "\n",
    "    # Return the result of pooling\n",
    "    if pool_mode == \"max\":\n",
    "        return A_w.max(axis=(1, 2)).reshape(output_shape)\n",
    "    elif pool_mode == \"avg\":\n",
    "        return A_w.mean(axis=(1, 2)).reshape(output_shape)\n",
    "\n",
    "\n",
    "def heatmap_nms(heatmaps, pooled_heatmaps):\n",
    "    return heatmaps * (heatmaps == pooled_heatmaps)\n",
    "\n",
    "\n",
    "# get poses from results\n",
    "def process_results(img, results):\n",
    "    pafs = results[output_keys[0]]\n",
    "    heatmaps = results[output_keys[1]]\n",
    "\n",
    "    pooled_heatmaps = np.array([[pool2d(h, kernel_size=3, stride=1, padding=1, pool_mode=\"max\") for h in heatmaps[0]]])\n",
    "    nms_heatmaps = heatmap_nms(heatmaps, pooled_heatmaps)\n",
    "\n",
    "    # decode poses\n",
    "    poses, scores = decoder(heatmaps, nms_heatmaps, pafs)\n",
    "    output_scale = img.shape[1] / exec_net.outputs[output_keys[0]].shape[3], img.shape[0] / exec_net.outputs[output_keys[0]].shape[2]\n",
    "    # multiply coordinates by scaling factor\n",
    "    poses[:, :, :2] *= output_scale\n",
    "\n",
    "    return poses, scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Pose drawing\n",
    "Code based on [Human Pose Estimation Demo](https://github.com/openvinotoolkit/open_model_zoo/tree/master/demos/human_pose_estimation_demo/python)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "colors = ((255, 0, 0), (255, 0, 255), (170, 0, 255), (255, 0, 85), (255, 0, 170), (85, 255, 0), (255, 170, 0), (0, 255, 0), (255, 255, 0),\n",
    "          (0, 255, 85), (170, 255, 0), (0, 85, 255), (0, 255, 170), (0, 0, 255), (0, 255, 255), (85, 0, 255), (0, 170, 255))\n",
    "\n",
    "default_skeleton = ((15, 13), (13, 11), (16, 14), (14, 12), (11, 12), (5, 11), (6, 12), (5, 6), (5, 7),\n",
    "                    (6, 8), (7, 9), (8, 10), (1, 2), (0, 1), (0, 2), (1, 3), (2, 4), (3, 5), (4, 6))\n",
    "\n",
    "\n",
    "def draw_poses(img, poses, point_score_threshold, skeleton=default_skeleton):\n",
    "    if poses.size == 0:\n",
    "        return img\n",
    "\n",
    "    img_limbs = np.copy(img)\n",
    "    for pose in poses:\n",
    "        points = pose[:, :2].astype(np.int32)\n",
    "        points_scores = pose[:, 2]\n",
    "        # Draw joints.\n",
    "        for i, (p, v) in enumerate(zip(points, points_scores)):\n",
    "            if v > point_score_threshold:\n",
    "                cv2.circle(img, tuple(p), 1, colors[i], 2)\n",
    "        # Draw limbs.\n",
    "        for i, j in skeleton:\n",
    "            if points_scores[i] > point_score_threshold and points_scores[j] > point_score_threshold:\n",
    "                cv2.line(img_limbs, tuple(points[i]), tuple(points[j]), color=colors[j], thickness=4)\n",
    "    cv2.addWeighted(img, 0.4, img_limbs, 0.6, 0, dst=img)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Main processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# main function to run pose estimation\n",
    "def run_pose_estimation(source=0, flip=True):\n",
    "    # open video source\n",
    "    cam = cv2.VideoCapture(source)\n",
    "    if not cam.isOpened():\n",
    "        print(f\"Cannot open source {source}\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        while True:\n",
    "            # grab the frame\n",
    "            ret, frame = cam.read()\n",
    "            if not ret:\n",
    "                print(\"Source is empty\")\n",
    "                break\n",
    "            if flip:\n",
    "                frame = cv2.flip(frame, 1)\n",
    "\n",
    "            # resize image and change dims to fit neural network input (see https://github.com/openvinotoolkit/open_model_zoo/tree/master/models/intel/human-pose-estimation-0001)\n",
    "            input_img = cv2.resize(frame, (456, 256), interpolation=cv2.INTER_AREA)\n",
    "            input_img = input_img.transpose(2, 0, 1)[np.newaxis, ...]\n",
    "\n",
    "            # get results\n",
    "            # measure processing time\n",
    "            start_time = time.time()\n",
    "            results = exec_net.infer(inputs={input_key: input_img})\n",
    "            poses, scores = process_results(frame, results)\n",
    "            stop_time = time.time()\n",
    "\n",
    "            frame = draw_poses(frame, poses, 0.1)\n",
    "            # calculate FPS\n",
    "            fps = 1 / (stop_time - start_time)\n",
    "            cv2.putText(frame, f\"FPS: {fps:.2f}\", (20, 40), cv2.FONT_HERSHEY_COMPLEX, 1.0, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "            # encode numpy array to jpg\n",
    "            _, encoded_img = cv2.imencode(\".jpg\", frame, params=[cv2.IMWRITE_JPEG_QUALITY, 90])\n",
    "            # create IPython image\n",
    "            i = display.Image(data=encoded_img)\n",
    "\n",
    "            # display the image in this notebook\n",
    "            display.clear_output(wait=True)\n",
    "            display.display(i)\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"Interrupted\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "    finally:\n",
    "        cam.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run\n",
    "\n",
    "Run with webcam. Set flip to True if you're using the front camera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "run_pose_estimation(flip=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "If you don't have a webcam you can run with video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "run_pose_estimation(\"data/Psy - Gangnam Style.mp4\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}