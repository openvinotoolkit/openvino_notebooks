{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"top\"></a>\n",
    "# Safety Gear Detection Sample Application"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "This sample application demonstrates how a smart video IoT solution may be created using IntelÂ® hardware and software tools to perform safety gear detection. This solution detects any number of objects within a video frame looking specifically for people, safety vests, and hardhats. This is a work in progress notebook. The model and videos are from https://github.com/intel-iot-devkit/safety-gear-detector-python and https://github.com/intel-iot-devkit/sample-videos\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import colorsys\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import urllib\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from IPython.display import (\n",
    "    HTML,\n",
    "    FileLink,\n",
    "    Pretty,\n",
    "    ProgressBar,\n",
    "    Video,\n",
    "    clear_output,\n",
    "    display,\n",
    ")\n",
    "from openvino.inference_engine import IECore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "contained-office"
   },
   "source": [
    "### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "amber-lithuania",
    "tags": []
   },
   "outputs": [],
   "source": [
    "DEVICE = \"CPU\"\n",
    "MODEL_FILE = \"models/mobilenet-ssd.xml\"\n",
    "MODEL_FILE_PERSON = \"models/person-detection-retail-0013.xml\"\n",
    "LABELS_FILE = \"labels.txt\"\n",
    "model_name = os.path.basename(MODEL_FILE)\n",
    "model_name_person = os.path.basename(MODEL_FILE_PERSON)\n",
    "model_xml_path = Path(MODEL_FILE).with_suffix(\".xml\")\n",
    "model_xml_path_person = Path(MODEL_FILE_PERSON).with_suffix(\".xml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_image(path: str):\n",
    "    \"\"\"\n",
    "    Loads an image from `path` and returns it as BGR numpy array. `path`\n",
    "    should point to an image file, either a local filename or an url.\n",
    "    \"\"\"\n",
    "    if path.startswith(\"http\"):\n",
    "        # Set User-Agent to Mozilla because some websites block\n",
    "        # requests with User-Agent Python\n",
    "        request = urllib.request.Request(\n",
    "            path, headers={\"User-Agent\": \"Mozilla/5.0\"}\n",
    "        )\n",
    "        response = urllib.request.urlopen(request)\n",
    "        array = np.asarray(bytearray(response.read()), dtype=\"uint8\")\n",
    "        image = cv2.imdecode(array, -1)  # Loads the image as BGR\n",
    "    else:\n",
    "        image = cv2.imread(path)\n",
    "    return image\n",
    "\n",
    "\n",
    "def to_rgb(image_data) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Convert image_data from BGR to RGB\n",
    "    \"\"\"\n",
    "    return cv2.cvtColor(image_data, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "\n",
    "def convert_result_to_image(resized_image, result, labeldict):\n",
    "    inf_results = result[0][0]\n",
    "    colors = ((255, 0, 0), (0, 255, 0), (0, 0, 255), (0, 0, 255))\n",
    "\n",
    "    resized_image_rgb = cv2.cvtColor(resized_image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    for number, proposal in enumerate(inf_results):\n",
    "        if proposal[2] > 0.5:\n",
    "            ih, iw = resized_image.shape[:-1]\n",
    "            label = np.int(proposal[1])\n",
    "            labelname = labeldict[label]\n",
    "\n",
    "            xmin = np.int(iw * proposal[3])\n",
    "            ymin = max(10, np.int(ih * proposal[4]))\n",
    "            xmax = np.int(iw * proposal[5])\n",
    "            ymax = np.int(ih * proposal[6])\n",
    "\n",
    "            resized_image_rgb = cv2.rectangle(\n",
    "                resized_image_rgb,\n",
    "                (xmin, ymin),\n",
    "                (xmax, ymax),\n",
    "                colors[label - 1],\n",
    "                3,\n",
    "            )\n",
    "            cv2.putText(\n",
    "                resized_image_rgb,\n",
    "                f\"{labelname} {proposal[2]:.2f}\",\n",
    "                (xmin, ymin - 10),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                0.8,\n",
    "                colors[label - 1],\n",
    "                1,\n",
    "                cv2.LINE_AA,\n",
    "            )\n",
    "\n",
    "    result_image_rgb = cv2.resize(resized_image_rgb, (image.shape[:2][::-1]))\n",
    "    return result_image_rgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ColorPalette:\n",
    "    def __init__(self, n, rng=None):\n",
    "        assert n > 0\n",
    "\n",
    "        if rng is None:\n",
    "            rng = random.Random(0xACE)\n",
    "\n",
    "        candidates_num = 100\n",
    "        hsv_colors = [(1.0, 1.0, 1.0)]\n",
    "        for _ in range(1, n):\n",
    "            colors_candidates = [\n",
    "                (rng.random(), rng.uniform(0.8, 1.0), rng.uniform(0.5, 1.0))\n",
    "                for _ in range(candidates_num)\n",
    "            ]\n",
    "            min_distances = [\n",
    "                self.min_distance(hsv_colors, c) for c in colors_candidates\n",
    "            ]\n",
    "            arg_max = np.argmax(min_distances)\n",
    "            hsv_colors.append(colors_candidates[arg_max])\n",
    "\n",
    "        self.palette = [self.hsv2rgb(*hsv) for hsv in hsv_colors]\n",
    "\n",
    "    @staticmethod\n",
    "    def dist(c1, c2):\n",
    "        dh = min(abs(c1[0] - c2[0]), 1 - abs(c1[0] - c2[0])) * 2\n",
    "        ds = abs(c1[1] - c2[1])\n",
    "        dv = abs(c1[2] - c2[2])\n",
    "        return dh * dh + ds * ds + dv * dv\n",
    "\n",
    "    @classmethod\n",
    "    def min_distance(cls, colors_set, color_candidate):\n",
    "        distances = [cls.dist(o, color_candidate) for o in colors_set]\n",
    "        return np.min(distances)\n",
    "\n",
    "    @staticmethod\n",
    "    def hsv2rgb(h, s, v):\n",
    "        return tuple(round(c * 255) for c in colorsys.hsv_to_rgb(h, s, v))\n",
    "\n",
    "    def __getitem__(self, n):\n",
    "        return self.palette[n % len(self.palette)]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.palette)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sensitive-wagner"
   },
   "source": [
    "## Load model and get model information\n",
    "\n",
    "Load the model in Inference Engine with `ie.read_network` and load it to the specified device with `ie.load_network`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "complete-brother",
    "tags": []
   },
   "outputs": [],
   "source": [
    "ie = IECore()\n",
    "net = ie.read_network(\n",
    "    str(model_xml_path),\n",
    "    str(model_xml_path.with_suffix(\".bin\")),\n",
    ")\n",
    "\n",
    "exec_net = ie.load_network(network=net, device_name=DEVICE)\n",
    "\n",
    "input_key = list(exec_net.input_info)[0]\n",
    "output_key = list(exec_net.outputs.keys())[0]\n",
    "\n",
    "network_input_shape = exec_net.input_info[input_key].tensor_desc.dims\n",
    "(network_image_height, network_image_width) = network_input_shape[2:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Safety Gear Detection on a Single Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "central-psychology",
    "outputId": "d864ee96-3fbd-488d-da1a-88e730f34aad",
    "tags": []
   },
   "outputs": [],
   "source": [
    "image = load_image(\"media/safety-gear-image.jpg\")\n",
    "# resize to input shape for network\n",
    "resized_image = cv2.resize(image, (network_image_width, network_image_height))\n",
    "\n",
    "# reshape image to network input shape NCHW\n",
    "input_image = np.expand_dims(np.transpose(resized_image, (2, 0, 1)), 0)\n",
    "plt.imshow(to_rgb(image))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "taken-spanking"
   },
   "source": [
    "### Do inference on image\n",
    "\n",
    "Do the inference, convert the result to an image, and resize it to the original image shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "banner-kruger",
    "tags": []
   },
   "outputs": [],
   "source": [
    "result = exec_net.infer(inputs={input_key: input_image})[output_key]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "labels = open(LABELS_FILE).read().splitlines()\n",
    "labeldict = {i + 1: labelname for i, labelname in enumerate(labels)}\n",
    "\n",
    "result_image_rgb = convert_result_to_image(image, result, labeldict)\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.imshow(result_image_rgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Safety Gear Detection on Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "terminal-dividend",
    "outputId": "87f5ada0-8caf-49c3-fe54-626e2b1967f3",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Uncomment the VIDEO_FILE line below to use a different input video\n",
    "VIDEO_FILE = \"media/Safety_Full_Hat_and_Vest.mp4\"\n",
    "# VIDEO_FILE = \"media/worker_zone_detection_small.mp4\"\n",
    "\n",
    "# Number of seconds of input video to process. Set to 0 to process\n",
    "# the full video.\n",
    "NUM_SECONDS = 4\n",
    "\n",
    "# Set ADVANCE_FRAMES to 1 to process every frame from the input video\n",
    "# Set ADVANCE_FRAMES to 2 to process every second frame. This reduces\n",
    "# the time it takes to process the video\n",
    "ADVANCE_FRAMES = 2\n",
    "\n",
    "# Set SCALE_OUTPUT to reduce the size of the result video\n",
    "# If SCALE_OUTPUT is 0.5, the width and height of the result video\n",
    "# will be half the width and height of the input video\n",
    "SCALE_OUTPUT = 0.5\n",
    "\n",
    "# The format to use for video encoding. VP09 is slow,\n",
    "# but it works on most systems.\n",
    "# Try the THEO encoding if you have FFMPEG installed.\n",
    "# FOURCC = cv2.VideoWriter_fourcc(*\"THEO\")\n",
    "FOURCC = cv2.VideoWriter_fourcc(*\"VP09\")\n",
    "\n",
    "# Create Path objects for the input video and the resulting video\n",
    "video_path = Path(VIDEO_FILE)\n",
    "result_video_path = video_path.with_name(f\"{video_path.stem}_result.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(str(video_path))\n",
    "ret, image = cap.read()\n",
    "if not ret:\n",
    "    raise ValueError(f\"The video at {video_path} cannot be read.\")\n",
    "input_fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "input_video_frame_height, input_video_frame_width = image.shape[:2]\n",
    "\n",
    "target_fps = input_fps / ADVANCE_FRAMES\n",
    "target_frame_height = int(input_video_frame_height * SCALE_OUTPUT)\n",
    "target_frame_width = int(input_video_frame_width * SCALE_OUTPUT)\n",
    "\n",
    "cap.release()\n",
    "print(\n",
    "    f\"The input video has a frame width of {input_video_frame_width}, \"\n",
    "    f\"frame height of {input_video_frame_height} and runs at {input_fps:.2} fps\"\n",
    ")\n",
    "print(\n",
    "    \"The result video will be scaled with a factor \"\n",
    "    f\"{SCALE_OUTPUT}, have width {target_frame_width}, \"\n",
    "    f\" height {target_frame_height}, and run at {target_fps:.2} fps\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize variables\n",
    "input_video_frame_nr = 0\n",
    "start_time = time.perf_counter()\n",
    "total_inference_duration = 0\n",
    "\n",
    "# Open input video\n",
    "cap = cv2.VideoCapture(str(video_path))\n",
    "\n",
    "# Create result video\n",
    "out_video = cv2.VideoWriter(\n",
    "    str(result_video_path),\n",
    "    FOURCC,\n",
    "    target_fps,\n",
    "    (target_frame_width, target_frame_height),\n",
    ")\n",
    "\n",
    "num_frames = int(NUM_SECONDS * input_fps)\n",
    "total_frames = (\n",
    "    cap.get(cv2.CAP_PROP_FRAME_COUNT) if num_frames == 0 else num_frames\n",
    ")\n",
    "progress_bar = ProgressBar(total=total_frames)\n",
    "progress_bar.display()\n",
    "\n",
    "try:\n",
    "    while cap.isOpened():\n",
    "        ret, image = cap.read()\n",
    "        if not ret:\n",
    "            cap.release()\n",
    "            break\n",
    "\n",
    "        if input_video_frame_nr >= total_frames:\n",
    "            break\n",
    "\n",
    "        # Only process every second frame\n",
    "        # Prepare frame for inference\n",
    "        # resize to input shape for network\n",
    "        resized_image = cv2.resize(\n",
    "            image, (network_image_height, network_image_width)\n",
    "        )\n",
    "        # reshape image to network input shape NCHW\n",
    "        input_image = np.expand_dims(np.transpose(resized_image, (2, 0, 1)), 0)\n",
    "\n",
    "        # Do inference\n",
    "        inference_start_time = time.perf_counter()\n",
    "        result = exec_net.infer(inputs={input_key: input_image})[output_key]\n",
    "        inference_stop_time = time.perf_counter()\n",
    "        inference_duration = inference_stop_time - inference_start_time\n",
    "        total_inference_duration += inference_duration\n",
    "\n",
    "        if input_video_frame_nr % (10 * ADVANCE_FRAMES) == 0:\n",
    "            clear_output(wait=True)\n",
    "            progress_bar.display()\n",
    "            # input_video_frame_nr // ADVANCE_FRAMES gives the number of\n",
    "            # frames that have been processed by the network\n",
    "            display(\n",
    "                Pretty(\n",
    "                    f\"Processed frame {input_video_frame_nr // ADVANCE_FRAMES}\"\n",
    "                    f\"/{total_frames // ADVANCE_FRAMES}. \"\n",
    "                    f\"Inference time: {inference_duration:.2f} seconds \"\n",
    "                    f\"({1/inference_duration:.2f} FPS)\"\n",
    "                )\n",
    "            )\n",
    "\n",
    "        # Transform network result to RGB image\n",
    "        result_frame = to_rgb(convert_result_to_image(image, result, labeldict))\n",
    "        # Resize image and result to target frame shape\n",
    "        result_frame = cv2.resize(\n",
    "            result_frame, (target_frame_width, target_frame_height)\n",
    "        )\n",
    "        # Save frame to video\n",
    "        out_video.write(result_frame)\n",
    "\n",
    "        input_video_frame_nr = input_video_frame_nr + ADVANCE_FRAMES\n",
    "        cap.set(1, input_video_frame_nr)\n",
    "\n",
    "        progress_bar.progress = input_video_frame_nr\n",
    "        progress_bar.update()\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"Processing interrupted.\")\n",
    "finally:\n",
    "    clear_output()\n",
    "    processed_frames = num_frames // ADVANCE_FRAMES\n",
    "    out_video.release()\n",
    "    cap.release()\n",
    "    end_time = time.perf_counter()\n",
    "    duration = end_time - start_time\n",
    "\n",
    "    print(\n",
    "        f\"Processed {processed_frames} frames in {duration:.2f} seconds. \"\n",
    "        f\"Total FPS (including video processing): {processed_frames/duration:.2f}.\"\n",
    "        f\"Inference FPS: {processed_frames/total_inference_duration:.2f} \"\n",
    "    )\n",
    "    print(f\"Safety Gear Detection Video saved to '{str(result_video_path)}'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-16T13:38:56.065237Z",
     "iopub.status.busy": "2021-04-16T13:38:56.065237Z",
     "iopub.status.idle": "2021-04-16T13:38:56.085468Z",
     "shell.execute_reply": "2021-04-16T13:38:56.085468Z",
     "shell.execute_reply.started": "2021-04-16T13:38:56.065237Z"
    }
   },
   "source": [
    "### Display or download video with results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO: embed=True doesn't work well for large videos\n",
    "video = Video(result_video_path, width=800, embed=True)\n",
    "if not result_video_path.exists():\n",
    "    plt.imshow(result_frame)\n",
    "    raise ValueError(\n",
    "        \"OpenCV was unable to write the video file. Showing one video frame.\"\n",
    "    )\n",
    "else:\n",
    "    print(\n",
    "        \"Showing Safety Gear Detection video saved at\\n\"\n",
    "        f\"{result_video_path.resolve()}\"\n",
    "    )\n",
    "    print(\n",
    "        \"If you cannot see the video in your browser, please click on the \"\n",
    "        \"following link to download the video \"\n",
    "    )\n",
    "    video_link = FileLink(result_video_path)\n",
    "    video_link.html_link_str = \"<a href='%s' download>%s</a>\"\n",
    "    display(HTML(video_link._repr_html_()))\n",
    "    display(video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openvino_env",
   "language": "python",
   "name": "openvino_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "251.4px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
