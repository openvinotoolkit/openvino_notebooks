{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53a8ed74-319f-4e72-958e-a0e59ced4981",
   "metadata": {},
   "source": [
    "# Person attributes recognition with OpenVINO\n",
    "\n",
    "This tutorial demonstrates person attributes recognition with MidasNet in OpenVINO. Model information can be found [here](https://docs.openvino.ai/latest/omz_models_model_person_attributes_recognition_crossroad_0230.html)\n",
    "\n",
    "  ![ceo](./data/ceo.png)\n",
    "\n",
    "### Description\n",
    "\n",
    "This model presents a person attributes classification algorithm analysis scenario. It produces probability of person attributions existing on the sample and a position of two point on sample, which can be used for color prob (like, color picker in graphical editors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b072cac-10a6-4b10-9f19-f9cfd56c2573",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"person-attributes-recognition-crossroad-0230\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0724d77a-f9d5-416d-9794-88e5e6efbadf",
   "metadata": {},
   "source": [
    "## Preparation\n",
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf12ece-7edb-40a3-b2ad-cf2dcfc8b67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from IPython.display import HTML, FileLink, Video, clear_output, display\n",
    "from openvino.runtime import Core\n",
    "\n",
    "sys.path.append(\"../utils\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f99b35-4e5b-4cfd-b576-cf1f97b9d73a",
   "metadata": {},
   "source": [
    "### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8dd3db-9234-4aeb-b64f-06ef5829cb1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model_dir = Path(\"./model/open_model_zoo_models\")\n",
    "omz_cache_dir = Path(\"./model/open_model_zoo_cache\")\n",
    "model_dir = Path(\"./model\")\n",
    "precision = \"FP16\"\n",
    "FOURCC = cv2.VideoWriter_fourcc(*\"vp09\")\n",
    "\n",
    "# Check if an iGPU is available on this system to use with Benchmark App\n",
    "ie = Core()\n",
    "gpu_available = \"GPU\" in ie.available_devices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2884903e-9ce6-4ab7-886c-cb1ce27e98f6",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Dwonload models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a961f165-6cfc-4ead-9bf8-d7393aa85a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# No need for convert !\n",
    "path_to_model_weights = Path(f'{base_model_dir}/intel/{model_name}/{precision}/{model_name}.bin')\n",
    "\n",
    "if not path_to_model_weights.is_file():\n",
    "    download_command = (f\"omz_downloader --name {model_name} --output_dir {base_model_dir} --cache_dir {omz_cache_dir}\")\n",
    "    print(download_command)\n",
    "    ! $download_command\n",
    "else:\n",
    "    print(\"Model has been download\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98efd3f-dc31-4cd7-92b7-5c9f021b14e7",
   "metadata": {},
   "source": [
    "### Load the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43308987-af68-40aa-baaa-2ebc949aa392",
   "metadata": {},
   "outputs": [],
   "source": [
    "ie = Core()\n",
    "path_to_model = path_to_model_weights.with_suffix(\".xml\")\n",
    "\n",
    "# mark some attributes\n",
    "attrs = [\n",
    "    \"is_male\",\n",
    "    \"has_bag\",\n",
    "    \"has_backpack\",\n",
    "    \"has_hat\",\n",
    "    \"has_longsleeves\",\n",
    "    \"has_longpants\",\n",
    "    \"has_longhair\",\n",
    "    \"has_coat_jacket\",\n",
    "]\n",
    "\n",
    "model = ie.read_model(model=path_to_model)\n",
    "compiled_model = ie.compile_model(model=model, device_name=\"CPU\")\n",
    "recognition_output_layer = next(iter(compiled_model.outputs))\n",
    "recognition_input_layer = next(iter(compiled_model.inputs))\n",
    "\n",
    "print(f\"{recognition_output_layer.shape} is output layer's shape\")\n",
    "print(f\"{recognition_input_layer.shape} is input layer's shape\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "797a3afc-ce4a-4f03-8a41-baede01defcc",
   "metadata": {},
   "source": [
    "## Functions\n",
    "\n",
    "include image processing and model inference "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064593ba-f5c1-4fc8-b714-3c8670ee49de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(\n",
    "    image,\n",
    "    recognition_output_layer=recognition_output_layer,\n",
    "    recognition_input_layer=recognition_input_layer,\n",
    "    attrs=attrs,\n",
    "):\n",
    "    N, C, H, W = recognition_input_layer.shape\n",
    "    # Resize image to meet network expected input sizes\n",
    "\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    resized_image = cv2.resize(image, (W, H))\n",
    "    # Reshape to network input shape\n",
    "    input_image = np.expand_dims(resized_image.transpose(2, 0, 1), 0)\n",
    "    output_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    result = compiled_model([input_image])[recognition_output_layer]\n",
    "\n",
    "    # Use different colors to indicate whether the target has the attribute\n",
    "    has_attr = (0, 255, 255)\n",
    "    no_attr = (255, 0, 255)\n",
    "    # attribute text height\n",
    "    text_height = 20\n",
    "\n",
    "    # there are 8 attributes, put the 8 attributes text into the picture with different color\n",
    "    for index in range(8):\n",
    "        # print(type(result[0][index]))\n",
    "        if result[0][index] > 0.5:\n",
    "            color = has_attr\n",
    "        else:\n",
    "            color = no_attr\n",
    "        cv2.putText(\n",
    "            output_image,\n",
    "            attrs[index],\n",
    "            (35, text_height),\n",
    "            cv2.FONT_HERSHEY_COMPLEX,\n",
    "            1,\n",
    "            color,\n",
    "            2,\n",
    "        )\n",
    "        text_height += 40\n",
    "    return output_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df0d9cd-98de-4bac-b49c-83b02d44fe15",
   "metadata": {},
   "source": [
    "## Load video and play"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa97cb16-6200-4548-bc43-313c0c35c109",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you choose your camera, set the number 0\n",
    "# cap = cv2.VideoCapture(0)\n",
    "# load video\n",
    "mp4dir = Path(\"./data/ceo.mp4\")\n",
    "result_video_path = Path(\"./data/transfer.mp4\")\n",
    "cap = cv2.VideoCapture(str(mp4dir))\n",
    "top_frame = 0\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"Cannot open camera\")\n",
    "    exit()\n",
    "\n",
    "ret, image = cap.read()\n",
    "if not ret:\n",
    "    raise ValueError(f\"The video at {mp4dir} cannot be read.\")\n",
    "input_fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "target_video_frame_height, target_video_frame_width = image.shape[:2]\n",
    "\n",
    "# Create result video\n",
    "out_video = cv2.VideoWriter(\n",
    "    str(result_video_path),\n",
    "    FOURCC,\n",
    "    input_fps,\n",
    "    (target_video_frame_width, target_video_frame_height),\n",
    ")\n",
    "\n",
    "# num_frames = int(4 * input_fps)\n",
    "# total_frames = cap.get(cv2.CAP_PROP_FRAME_COUNT) if num_frames == 0 else num_frames\n",
    "# progress_bar = ProgressBar(total=total_frames)\n",
    "# progress_bar.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5253f47e-4f2d-4566-bd37-1f8bd44c78f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    while True:\n",
    "        # catch every frame\n",
    "        ret, frame = cap.read()\n",
    "        # if run right, ret = True\n",
    "        if not ret:\n",
    "            print(\"Can't receive frame (stream end?). Exiting ...\")\n",
    "            break\n",
    "        top_frame = top_frame + 1\n",
    "        image = process_image(frame)\n",
    "        # Display the result frame E\n",
    "        # cv2.imshow('frame', image)\n",
    "        # print(\"cv had show\")\n",
    "        out_video.write(image)\n",
    "        # you can do with more frames\n",
    "        if top_frame > 200:\n",
    "            break\n",
    "        if cv2.waitKey(1) == ord(\"q\"):\n",
    "            break\n",
    "except KeyboardInterrupt:\n",
    "    print(\"Processing interrupted.\")\n",
    "\n",
    "finally:\n",
    "    clear_output()\n",
    "    out_video.release()\n",
    "    cap.release()\n",
    "\n",
    "# finished all, release allï¼ŒAs there is a famous saying,\n",
    "# the rainbow after the rain is more beautiful, and the suffering life is more brilliant"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff8cd81-400b-4360-8f59-2be5990c4ebb",
   "metadata": {},
   "source": [
    "## Show the video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6839c235-b362-4595-832b-0e89bfcdaa7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "video = Video(result_video_path, embed=True)\n",
    "if not result_video_path.exists():\n",
    "    raise ValueError(\n",
    "        \"OpenCV was unable to write the video file. Showing one video frame.\"\n",
    "    )\n",
    "else:\n",
    "    print(f\"Showing monodepth video saved at\\n{result_video_path.resolve()}\")\n",
    "    print(\n",
    "        \"If you cannot see the video in your browser, please click on the \"\n",
    "        \"following link to download the video \"\n",
    "    )\n",
    "    video_link = FileLink(result_video_path)\n",
    "    video_link.html_link_str = \"<a href='%s' download>%s</a>\"\n",
    "    display(HTML(video_link._repr_html_()))\n",
    "    display(video)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d5a142-59e4-49ee-8817-205a12bc9216",
   "metadata": {},
   "source": [
    "# Delete the downloaded model\n",
    "\n",
    "The purpose of this block is to clear the downloaded Intel model.\n",
    "\n",
    "When you are done with the above code and no longer need it, you can run the code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f407135-81fe-4675-b181-0f5065cc26da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import shutil\n",
    "\n",
    "# # remove model directory\n",
    "# os.remove(result_video_path)\n",
    "# if os.path.exists(model_dir):\n",
    "#     shutil.rmtree(model_dir)\n",
    "# else:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openvino_env",
   "language": "python",
   "name": "openvino_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
