{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43b5eeae",
   "metadata": {},
   "source": [
    "<h1 style=\"text-align: center;\">Stable Diffusion v2.1 using Optimum-Intel OpenVINO</h1>\n",
    "<img src=\"https://github.com/openvinotoolkit/openvino_notebooks/assets/10940214/1858dae4-72fd-401e-b055-66d503d82446\"  width=\"30%\" height=\"30%\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aaf4a4a",
   "metadata": {},
   "source": [
    "Optimum Intel is the interface between the Transformers and Diffusers libraries and the different tools and libraries provided by Intel to accelerate end-to-end pipelines on Intel architectures. More details in this [repository](https://github.com/huggingface/optimum-intel#openvino). \n",
    "\n",
    "`Note: We suggest you to create a different environment and run the following installation command there.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78eac7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q \"optimum-intel[openvino,diffusers]\" \"ipywidgets\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb082175",
   "metadata": {},
   "source": [
    "Stable Diffusion pipeline should brings 6 elements together, a text encoder model with a tokenizer, a UNet model with and scheduler, and an Autoencoder with Decoder and Encoder models. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a664d2f2",
   "metadata": {},
   "source": [
    "![image](https://github.com/openvinotoolkit/openvino_notebooks/assets/10940214/e166f225-1220-44aa-a987-84471e03947d)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ade39f1",
   "metadata": {},
   "source": [
    "The base model used for this example is the \"[stabilityai/stable-diffusion-2-1-base](https://huggingface.co/stabilityai/stable-diffusion-2-1). This model was converted to OpenVINO format, for accelerated inference on CPU or Intel GPU with OpenVINO's integration into Optimum: optimum-intel. The model weights are stored with FP16 precision, which reduces the size of the model by half. You can find the model used in this notebook is \"[helenai/stabilityai-stable-diffusion-2-1-base-ov](https://huggingface.co/helenai/stabilityai-stable-diffusion-2-1-base-ov)\". Let's download the pre-converted model Stable Diffusion 2.1 [Intermediate Representation Format (IR)](https://docs.openvino.ai/2022.3/openvino_docs_MO_DG_IR_and_opsets.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8276743",
   "metadata": {},
   "source": [
    "### Showing Info Available Devices\n",
    "\n",
    "The `available_devices` property shows the available devices in your system. The \"FULL_DEVICE_NAME\" option to `ie.get_property()` shows the name of the device. Check what is the ID name for the discrete GPU, if you have integrated GPU (iGPU) and discrete GPU (dGPU), it will show `device_name=\"GPU.0\"` for iGPU and `device_name=\"GPU.1\"` for dGPU. If you just have either an iGPU or dGPU that will be assigned to `\"GPU\"`\n",
    "\n",
    "Note: For more details about GPU with OpenVINO visit this [link](https://docs.openvino.ai/nightly/openvino_docs_install_guides_configurations_for_intel_gpu.html). If you have been facing any issue in Ubuntu 20.04 or Windows 11 read this [blog](https://blog.openvino.ai/blog-posts/install-gpu-drivers-windows-ubuntu)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8475cd04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openvino.runtime import Core\n",
    "\n",
    "ie = Core()\n",
    "devices = ie.available_devices\n",
    "\n",
    "for device in devices:\n",
    "    device_name = ie.get_property(device, \"FULL_DEVICE_NAME\")\n",
    "    print(f\"{device}: {device_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a98936cf",
   "metadata": {},
   "source": [
    "### Download Pre-Converted Stable Diffusion 2.1 IR "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04bdda50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from optimum.intel.openvino import OVStableDiffusionPipeline\n",
    "# download the pre-converted SD v2.1 model from Hugging Face Hub\n",
    "name = \"helenai/stabilityai-stable-diffusion-2-1-base-ov\"\n",
    "\n",
    "pipe = OVStableDiffusionPipeline.from_pretrained(name, compile=False)\n",
    "pipe.reshape(batch_size=1, height=512, width=512, num_images_per_prompt=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58facf17",
   "metadata": {},
   "source": [
    "### Save the pre-trained models, Select the inference device and compile it\n",
    "\n",
    "You can save the model locally in order to avoid downloading process later. The model will also saved in the cache."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7abb403b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipe.save_pretrained(\"./openvino_ir\") # Uncomment if you need the model for further compilations\n",
    "pipe.to(\"GPU\")\n",
    "pipe.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba6b746d",
   "metadata": {},
   "source": [
    "### Be creative, add the prompt and enjoy the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1b8ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate an image. \n",
    "prompt = \"red car in snowy forest, epic vista, beautiful landscape, 4k, 8k\"\n",
    "output = pipe(prompt, num_inference_steps=17, output_type=\"pil\").images[0]\n",
    "output.save(\"image.png\")\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dfb1c67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
