{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2cd5c88",
   "metadata": {
    "id": "moved-collapse"
   },
   "source": [
    "# Style Transfer on ONNX Models with OpenVINO\n",
    "\n",
    "![Neural Style Transfer network output](https://user-images.githubusercontent.com/77325899/147354137-4fc9e79e-0195-4927-9608-0e3f17973d75.png)\n",
    "\n",
    "This notebook demonstrates [Fast Neural Style Transfer](https://github.com/onnx/models/tree/master/vision/style_transfer/fast_neural_style) on ONNX models with OpenVINO. Style Transfer models mix the content of an image with the style of another image. \n",
    "\n",
    "For this notebook, we use five pretrained models, for the following styles: Mosaic, Rain Princess, Candy, Udnie and Pointilism. The models are from the [ONNX Model Repository](https://github.com/onnx/models) and are based on the research paper [Perceptual Losses for Real-Time Style Transfer and Super-Resolution](https://arxiv.org/abs/1603.08155) by Justin Johnson, Alexandre Alahi and Li Fei-Fei."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d3c779",
   "metadata": {
    "id": "creative-cisco"
   },
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf1ae349",
   "metadata": {
    "id": "faced-honolulu"
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d08d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from enum import Enum\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from IPython.display import HTML, FileLink, clear_output, display\n",
    "from openvino.inference_engine import IECore\n",
    "from yaspin import yaspin\n",
    "\n",
    "sys.path.append(\"../utils\")\n",
    "from notebook_utils import download_file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a29fe4",
   "metadata": {
    "id": "contained-office"
   },
   "source": [
    "### Download Models\n",
    "\n",
    "The `Style` Enum lists the supported styles with url, title and model path properties. Models for all supported styles will be downloaded to `MODEL_DIR` if they have not been downloaded before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf70d65-efff-4642-b3e7-97d738b15104",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_URL = \"https://github.com/onnx/models/raw/master/vision/style_transfer/fast_neural_style/model\"\n",
    "MODEL_DIR = \"model\"\n",
    "\n",
    "\n",
    "class Style(Enum):\n",
    "    MOSAIC = \"mosaic\"\n",
    "    RAIN_PRINCESS = \"rain-princess\"\n",
    "    CANDY = \"candy\"\n",
    "    UDNIE = \"udnie\"\n",
    "    POINTILISM = \"pointilism\"\n",
    "\n",
    "    def __init__(self, *args):\n",
    "        self.model_path = Path(f\"{self.value}-9.onnx\")\n",
    "        self.title = self.value.replace(\"-\", \" \").title()\n",
    "        self.url = f\"{BASE_URL}/{self.model_path}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e60e299-1174-4537-8f30-aa56906e65c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for style in Style:\n",
    "    if not Path(f\"{MODEL_DIR}/{style.model_path}\").exists():\n",
    "        download_file(style.url, directory=MODEL_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e4e8d7-3938-4220-bdbe-cf0a0269c4e5",
   "metadata": {},
   "source": [
    "### Load Image\n",
    "\n",
    "Load an image with OpenCV and convert it to RGB. The style transfer model will be resized to the image shape. This gives the most detailed results, but for larger images, inference will take longer and use more memory. The `resize_to_max` function optionally resizes the image to a maximum size. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c4ec2d",
   "metadata": {
    "tags": [],
    "test_replace": {
     "image =": "image =",
     "max_side=1024": "max_side=256"
    }
   },
   "outputs": [],
   "source": [
    "IMAGE_FILE = \"data/coco_square.jpg\"\n",
    "image = cv2.cvtColor(cv2.imread(IMAGE_FILE), cv2.COLOR_BGR2RGB)\n",
    "\n",
    "\n",
    "def resize_to_max(image: np.ndarray, max_side: int) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Resize image to an image where the largest side has a maximum length of max_side\n",
    "    while keeping aspect ratio. Example: if an original image has width and height of (1000, 500)\n",
    "    and max_side is 300, the resized image will have a width and height of (300, 150).\n",
    "\n",
    "    :param image: Array of image to resize\n",
    "    :param max_side: Maximum length of largest image side\n",
    "    :return: Resized image\n",
    "    \"\"\"\n",
    "    if max(image.shape) <= max_side:\n",
    "        new_image = image\n",
    "    else:\n",
    "        index = np.argmax(image.shape)\n",
    "        factor = max_side / image.shape[index]\n",
    "        height, width = image.shape[:2]\n",
    "        new_height, new_width = int(factor * height), int(factor * width)\n",
    "        new_image = cv2.resize(image, (new_width, new_height))\n",
    "    return new_image\n",
    "\n",
    "\n",
    "# Uncomment the line below to resize large images to a max side length to improve inference speed.\n",
    "# image = resize_to_max(image=image, max_side=1024)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de672364",
   "metadata": {
    "id": "taken-spanking"
   },
   "source": [
    "## Do Inference and Show Results\n",
    "\n",
    "For all five models: do inference, convert the result to an 8-bit image, show the results, and save the results to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c048d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set SAVE_RESULTS to False to disable saving the result images.\n",
    "SAVE_RESULTS = True\n",
    "\n",
    "# find reasonable dimensions for matplotlib plot\n",
    "wh_ratio = image.shape[1] / image.shape[0]\n",
    "figwidth = 15\n",
    "figheight = (figwidth * 0.75) // wh_ratio\n",
    "\n",
    "# Create matplotlib plot and show source image\n",
    "fig, ax = plt.subplots(2, 3, figsize=(figwidth, figheight))\n",
    "axs = ax.ravel()\n",
    "axs[0].imshow(image)\n",
    "axs[0].set_title(\"Source Image\")\n",
    "axs[0].axis(\"off\")\n",
    "\n",
    "# Create IECore instance, prepare output folder\n",
    "ie = IECore()\n",
    "output_folder = Path(\"output\")\n",
    "output_folder.mkdir(exist_ok=True)\n",
    "\n",
    "# Transpose input image to network dimensions and extract image name and shape\n",
    "input_image = np.expand_dims(image.transpose(2, 0, 1), axis=0)\n",
    "image_name = Path(IMAGE_FILE).stem\n",
    "image_shape_str = f\"{image.shape[1]}x{image.shape[0]}\"\n",
    "\n",
    "file_links = []\n",
    "for i, style in enumerate(Style):\n",
    "    # Load model and get model info\n",
    "    net = ie.read_network(model=Path(MODEL_DIR) / style.model_path)\n",
    "    input_key = list(net.input_info)[0]\n",
    "    output_key = list(net.outputs.keys())[0]\n",
    "\n",
    "    # Reshape network to image shape and load network to device\n",
    "    net.reshape({input_key: (1, 3, image.shape[0], image.shape[1])})\n",
    "    exec_net = ie.load_network(network=net, device_name=\"CPU\")\n",
    "\n",
    "    # Do inference\n",
    "    with yaspin(text=f\"Doing inference on {style.title} model\") as sp:\n",
    "        result = exec_net.infer(inputs={input_key: input_image})[output_key]\n",
    "        sp.ok(\"âœ”\")\n",
    "\n",
    "    # Convert inference result to image shape and apply postprocessing\n",
    "    # Postprocessing is described in the model documentation:\n",
    "    # https://github.com/onnx/models/tree/master/vision/style_transfer/fast_neural_style\n",
    "    result = result.squeeze().transpose(1, 2, 0)\n",
    "    result = np.clip(result, 0, 255).astype(np.uint8)\n",
    "\n",
    "    # Show the result\n",
    "    axs[i + 1].imshow(result)\n",
    "    axs[i + 1].set_title(style.title)\n",
    "    axs[i + 1].axis(\"off\")\n",
    "\n",
    "    # Optionally save results to disk\n",
    "    if SAVE_RESULTS:\n",
    "        image_path = f\"{image_name}_{style.model_path.stem}_{image_shape_str}.png\"\n",
    "        output_path = output_folder / image_path\n",
    "        cv2.imwrite(str(output_path), cv2.cvtColor(result, cv2.COLOR_BGR2RGB))\n",
    "        file_link = FileLink(output_path, result_html_prefix=f\"{style.title} image: \")\n",
    "        file_link.html_link_str = \"<a href='%s' download>%s</a>\"\n",
    "        file_links.append(file_link)\n",
    "\n",
    "    del net\n",
    "    del exec_net\n",
    "\n",
    "clear_output(wait=True)\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "if SAVE_RESULTS:\n",
    "    output_path = output_folder / f\"{image_name}_{image_shape_str}_style_transfer.jpg\"\n",
    "    fig.savefig(str(output_path), dpi=300, bbox_inches=\"tight\", pad_inches=0.1)\n",
    "    file_link = FileLink(output_path, result_html_prefix=\"Overview image: \")\n",
    "    file_link.html_link_str = \"<a href='%s' download>%s</a>\"\n",
    "    file_links.append(file_link)\n",
    "    display(HTML(\"Saved image files:\"))\n",
    "    for file_link in file_links:\n",
    "        display(HTML(file_link._repr_html_()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
