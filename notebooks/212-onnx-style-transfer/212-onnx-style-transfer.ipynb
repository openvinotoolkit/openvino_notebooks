{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2cd5c88",
   "metadata": {
    "id": "moved-collapse"
   },
   "source": [
    "# Style Transfer on ONNX Models with OpenVINO™\n",
    "\n",
    "![Neural Style Transfer network output](https://user-images.githubusercontent.com/77325899/147354137-4fc9e79e-0195-4927-9608-0e3f17973d75.png)\n",
    "\n",
    "This notebook demonstrates [Fast Neural Style Transfer](https://github.com/onnx/models/tree/master/vision/style_transfer/fast_neural_style) on ONNX models with OpenVINO. Style Transfer models mix the content of an image with the style of another image. \n",
    "\n",
    "This notebook uses five pre-trained models, for the following styles: Mosaic, Rain Princess, Candy, Udnie and Pointilism. The models are from the [ONNX Model Repository](https://github.com/onnx/models) and are based on the research paper [Perceptual Losses for Real-Time Style Transfer and Super-Resolution](https://arxiv.org/abs/1603.08155) by Justin Johnson, Alexandre Alahi and Li Fei-Fei."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf1ae349",
   "metadata": {
    "id": "faced-honolulu"
   },
   "source": [
    "## Preparation\n",
    "\n",
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d08d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from enum import Enum\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from IPython.display import HTML, FileLink, clear_output, display\n",
    "from openvino.runtime import Core, PartialShape\n",
    "from yaspin import yaspin\n",
    "\n",
    "sys.path.append(\"../utils\")\n",
    "from notebook_utils import download_file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a29fe4",
   "metadata": {
    "id": "contained-office"
   },
   "source": [
    "### Download Models\n",
    "\n",
    "The `Style` Enum lists the supported styles with `url`, `title` and `model_path` properties. Models for all supported styles will be downloaded to `MODEL_DIR` if they have not been downloaded before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf70d65-efff-4642-b3e7-97d738b15104",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_URL = \"https://github.com/onnx/models/raw/main/vision/style_transfer/fast_neural_style/model\"\n",
    "MODEL_DIR = \"model\"\n",
    "\n",
    "\n",
    "class Style(Enum):\n",
    "    MOSAIC = \"mosaic\"\n",
    "    RAIN_PRINCESS = \"rain-princess\"\n",
    "    CANDY = \"candy\"\n",
    "    UDNIE = \"udnie\"\n",
    "    POINTILISM = \"pointilism\"\n",
    "\n",
    "    def __init__(self, *args):\n",
    "        self.model_path = Path(f\"{self.value}-9.onnx\")\n",
    "        self.title = self.value.replace(\"-\", \" \").title()\n",
    "        self.url = f\"{BASE_URL}/{self.model_path}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e60e299-1174-4537-8f30-aa56906e65c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for style in Style:\n",
    "    if not Path(f\"{MODEL_DIR}/{style.model_path}\").exists():\n",
    "        download_file(style.url, directory=MODEL_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e4e8d7-3938-4220-bdbe-cf0a0269c4e5",
   "metadata": {},
   "source": [
    "### Load an Image\n",
    "\n",
    "Load an image with OpenCV and convert it to `RGB`. The style transfer model will be resized to the image shape. This gives the most detailed results, but for larger images, inference will take longer and use more memory. The `resize_to_max` function optionally resizes the image to a maximum size. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c4ec2d",
   "metadata": {
    "tags": [],
    "test_replace": {
     "image =": "image =",
     "max_side=1024": "max_side=256"
    }
   },
   "outputs": [],
   "source": [
    "IMAGE_FILE = \"data/coco_square.jpg\"\n",
    "image = cv2.cvtColor(cv2.imread(IMAGE_FILE), cv2.COLOR_BGR2RGB)\n",
    "\n",
    "\n",
    "def resize_to_max(image: np.ndarray, max_side: int) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Resize image to an image where the largest side has a maximum length of max_side\n",
    "    while keeping aspect ratio. Example: if an original image has width and height of (1000, 500)\n",
    "    and max_side is 300, the resized image will have a width and height of (300, 150).\n",
    "\n",
    "    :param image: Array of image to resize\n",
    "    :param max_side: Maximum length of largest image side\n",
    "    :return: Resized image\n",
    "    \"\"\"\n",
    "    if max(image.shape) <= max_side:\n",
    "        new_image = image\n",
    "    else:\n",
    "        index = np.argmax(image.shape)\n",
    "        factor = max_side / image.shape[index]\n",
    "        height, width = image.shape[:2]\n",
    "        new_height, new_width = int(factor * height), int(factor * width)\n",
    "        new_image = cv2.resize(image, (new_width, new_height))\n",
    "    return new_image\n",
    "\n",
    "\n",
    "# Uncomment the line below to resize large images to a max side length to improve inference speed.\n",
    "# image = resize_to_max(image=image, max_side=1024)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de672364",
   "metadata": {
    "id": "taken-spanking"
   },
   "source": [
    "## Do Inference and Show Results\n",
    "\n",
    "For all five models: do inference, convert the result to an 8-bit image, show the results, and save the results to a disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c048d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set SAVE_RESULTS to False to disable saving the result images.\n",
    "SAVE_RESULTS = True\n",
    "\n",
    "# Find reasonable dimensions for a matplotlib plot.\n",
    "wh_ratio = image.shape[1] / image.shape[0]\n",
    "figwidth = 15\n",
    "figheight = (figwidth * 0.75) // wh_ratio\n",
    "\n",
    "# Create a matplotlib plot and show the source image.\n",
    "fig, ax = plt.subplots(2, 3, figsize=(figwidth, figheight))\n",
    "axs = ax.ravel()\n",
    "axs[0].imshow(image)\n",
    "axs[0].set_title(\"Source Image\")\n",
    "axs[0].axis(\"off\")\n",
    "\n",
    "# Create a `Core` instance, prepare an output folder.\n",
    "ie = Core()\n",
    "output_folder = Path(\"output\")\n",
    "output_folder.mkdir(exist_ok=True)\n",
    "\n",
    "# Transpose the input image to network dimensions and extract the name and the shape of the image.\n",
    "input_image = np.expand_dims(image.transpose(2, 0, 1), axis=0)\n",
    "image_name = Path(IMAGE_FILE).stem\n",
    "image_shape_str = f\"{image.shape[1]}x{image.shape[0]}\"\n",
    "\n",
    "file_links = []\n",
    "for i, style in enumerate(Style):\n",
    "    # Load the model and get model info.\n",
    "    model = ie.read_model(model=Path(MODEL_DIR) / style.model_path)\n",
    "    input_key = model.input(0)\n",
    "\n",
    "    # Reshape the network to the image shape and load the network to a device.\n",
    "    model.reshape({input_key: PartialShape([1, 3, image.shape[0], image.shape[1]])})\n",
    "    compiled_model = ie.compile_model(model=model, device_name=\"CPU\")\n",
    "    output_key = compiled_model.output(0)\n",
    "    # Do inference.\n",
    "    with yaspin(text=f\"Doing inference on {style.title} model\") as sp:\n",
    "        result = compiled_model([input_image])[output_key]\n",
    "        sp.ok(\"✔\")\n",
    "\n",
    "    # Convert the inference result to the image shape and apply postprocessing.\n",
    "    # Postprocessing is described in the model documentation:\n",
    "    # https://github.com/onnx/models/tree/master/vision/style_transfer/fast_neural_style\n",
    "    result = result.squeeze().transpose(1, 2, 0)\n",
    "    result = np.clip(result, 0, 255).astype(np.uint8)\n",
    "\n",
    "    # Show the result.\n",
    "    axs[i + 1].imshow(result)\n",
    "    axs[i + 1].set_title(style.title)\n",
    "    axs[i + 1].axis(\"off\")\n",
    "\n",
    "    # (optional) Save the results to a disk.\n",
    "    if SAVE_RESULTS:\n",
    "        image_path = f\"{image_name}_{style.model_path.stem}_{image_shape_str}.png\"\n",
    "        output_path = output_folder / image_path\n",
    "        cv2.imwrite(str(output_path), cv2.cvtColor(result, cv2.COLOR_BGR2RGB))\n",
    "        file_link = FileLink(output_path, result_html_prefix=f\"{style.title} image: \")\n",
    "        file_link.html_link_str = \"<a href='%s' download>%s</a>\"\n",
    "        file_links.append(file_link)\n",
    "\n",
    "    del model\n",
    "    del compiled_model\n",
    "\n",
    "clear_output(wait=True)\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "if SAVE_RESULTS:\n",
    "    output_path = output_folder / f\"{image_name}_{image_shape_str}_style_transfer.jpg\"\n",
    "    fig.savefig(str(output_path), dpi=300, bbox_inches=\"tight\", pad_inches=0.1)\n",
    "    file_link = FileLink(output_path, result_html_prefix=\"Overview image: \")\n",
    "    file_link.html_link_str = \"<a href='%s' download>%s</a>\"\n",
    "    file_links.append(file_link)\n",
    "    display(HTML(\"Saved image files:\"))\n",
    "    for file_link in file_links:\n",
    "        display(HTML(file_link._repr_html_()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
