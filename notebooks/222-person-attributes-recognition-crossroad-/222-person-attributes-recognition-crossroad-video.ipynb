{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53a8ed74-319f-4e72-958e-a0e59ced4981",
   "metadata": {},
   "source": [
    "# Person attributes recognition with OpenVINO\n",
    "\n",
    "This tutorial demonstrates person attributes recognition with MidasNet in OpenVINO. Model information can be found [here](https://docs.openvino.ai/latest/omz_models_model_person_attributes_recognition_crossroad_0230.html)\n",
    "\n",
    "  ![ceo](./data/ceo.png)\n",
    "\n",
    "### Description\n",
    "\n",
    "This model presents a person attributes classification algorithm analysis scenario. It produces probability of person attributions existing on the sample and a position of two point on sample, which can be used for color prob (like, color picker in graphical editors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b072cac-10a6-4b10-9f19-f9cfd56c2573",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"person-attributes-recognition-crossroad-0230\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0724d77a-f9d5-416d-9794-88e5e6efbadf",
   "metadata": {},
   "source": [
    "## Preparation\n",
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eaf12ece-7edb-40a3-b2ad-cf2dcfc8b67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "from openvino.runtime import Core\n",
    "\n",
    "sys.path.append(\"../utils\")\n",
    "from notebook_utils import DeviceNotFoundAlert, NotebookAlert, load_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f99b35-4e5b-4cfd-b576-cf1f97b9d73a",
   "metadata": {},
   "source": [
    "### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc8dd3db-9234-4aeb-b64f-06ef5829cb1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base_model_dir: model\\open_model_zoo_models, omz_cache_dir: model\\open_model_zoo_cache, gpu_availble: False\n"
     ]
    }
   ],
   "source": [
    "base_model_dir = Path(\"./model/open_model_zoo_models\").expanduser()\n",
    "omz_cache_dir = Path(\"./model/open_model_zoo_cache\").expanduser()\n",
    "model_dir = Path(\"./model\").expanduser()\n",
    "precision = \"FP16\"\n",
    "\n",
    "# Check if an iGPU is available on this system to use with Benchmark App\n",
    "ie = Core()\n",
    "gpu_available = \"GPU\" in ie.available_devices\n",
    "\n",
    "print(\n",
    "    f\"base_model_dir: {base_model_dir}, omz_cache_dir: {omz_cache_dir}, gpu_availble: {gpu_available}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2884903e-9ce6-4ab7-886c-cb1ce27e98f6",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Dwonload models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a961f165-6cfc-4ead-9bf8-d7393aa85a26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model\\open_model_zoo_models\\intel\\person-attributes-recognition-crossroad-0230\\FP16\\person-attributes-recognition-crossroad-0230.bin\n",
      "omz_downloader --name person-attributes-recognition-crossroad-0230 --output_dir model\\open_model_zoo_models --cache_dir model\\open_model_zoo_cache\n",
      "################|| Downloading person-attributes-recognition-crossroad-0230 ||################\n",
      "\n",
      "========== Downloading model\\open_model_zoo_models\\intel\\person-attributes-recognition-crossroad-0230\\FP32\\person-attributes-recognition-crossroad-0230.xml\n",
      "... 100%, 202 KB, 293 KB/s, 0 seconds passed\n",
      "\n",
      "========== Downloading model\\open_model_zoo_models\\intel\\person-attributes-recognition-crossroad-0230\\FP32\\person-attributes-recognition-crossroad-0230.bin\n",
      "... 35%, 1024 KB, 819 KB/s, 1 seconds passed\n",
      "... 71%, 2048 KB, 1440 KB/s, 1 seconds passed\n",
      "... 100%, 2870 KB, 1700 KB/s, 1 seconds passed\n",
      "\n",
      "========== Downloading model\\open_model_zoo_models\\intel\\person-attributes-recognition-crossroad-0230\\FP16\\person-attributes-recognition-crossroad-0230.xml\n",
      "... 100%, 271 KB, 404 KB/s, 0 seconds passed\n",
      "\n",
      "========== Downloading model\\open_model_zoo_models\\intel\\person-attributes-recognition-crossroad-0230\\FP16\\person-attributes-recognition-crossroad-0230.bin\n",
      "... 71%, 1024 KB, 808 KB/s, 1 seconds passed\n",
      "... 100%, 1435 KB, 1106 KB/s, 1 seconds passed\n",
      "\n",
      "========== Downloading model\\open_model_zoo_models\\intel\\person-attributes-recognition-crossroad-0230\\FP16-INT8\\person-attributes-recognition-crossroad-0230.xml\n",
      "... 100%, 529 KB, 513 KB/s, 1 seconds passed\n",
      "\n",
      "========== Downloading model\\open_model_zoo_models\\intel\\person-attributes-recognition-crossroad-0230\\FP16-INT8\\person-attributes-recognition-crossroad-0230.bin\n",
      "... 100%, 750 KB, 2286 KB/s, 0 seconds passed\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#No need for convert !\n",
    "path_to_model_weights = Path(f'{base_model_dir}/intel/{model_name}/{precision}/{model_name}.bin')\n",
    "\n",
    "print(path_to_model_weights)\n",
    "if not path_to_model_weights.is_file():\n",
    "    download_command = (f\"omz_downloader --name {model_name} --output_dir {base_model_dir} --cache_dir {omz_cache_dir}\")\n",
    "    print(download_command)\n",
    "    ! $download_command\n",
    "else:\n",
    "    print(\"Model has been download\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98efd3f-dc31-4cd7-92b7-5c9f021b14e7",
   "metadata": {},
   "source": [
    "### Load the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43308987-af68-40aa-baaa-2ebc949aa392",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model\\open_model_zoo_models\\intel\\person-attributes-recognition-crossroad-0230\\FP16\\person-attributes-recognition-crossroad-0230.xml is the model's path\n",
      "{1, 8, 1, 1} is output layer's shape\n",
      "{1, 3, 160, 80} is input layer's shape\n"
     ]
    }
   ],
   "source": [
    "ie = Core()\n",
    "path_to_model = path_to_model_weights.with_suffix(\".xml\")\n",
    "print(f\"{path_to_model} is the model's path\")\n",
    "\n",
    "# mark some attributes\n",
    "attrs = ['is_male', 'has_bag', 'has_backpack', 'has_hat', 'has_longsleeves', 'has_longpants', 'has_longhair', 'has_coat_jacket']\n",
    "\n",
    "model = ie.read_model(model=path_to_model)\n",
    "compiled_model = ie.compile_model(model=model, device_name=\"CPU\")\n",
    "recognition_output_layer = next(iter(compiled_model.outputs))\n",
    "recognition_input_layer = next(iter(compiled_model.inputs))\n",
    "\n",
    "print(f\"{recognition_output_layer.shape} is output layer's shape\")\n",
    "print(f\"{recognition_input_layer.shape} is input layer's shape\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "797a3afc-ce4a-4f03-8a41-baede01defcc",
   "metadata": {},
   "source": [
    "## Functions\n",
    "\n",
    "include image processing and model inference "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "064593ba-f5c1-4fc8-b714-3c8670ee49de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(image, recognition_output_layer = recognition_output_layer, \n",
    "                  recognition_input_layer = recognition_input_layer,\n",
    "                 attrs = attrs):   \n",
    "    N, C, H, W = recognition_input_layer.shape\n",
    "    # Resize image to meet network expected input sizes\n",
    "    \n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    resized_image = cv2.resize(image, (W, H))\n",
    "    # Reshape to network input shape\n",
    "    input_image = np.expand_dims(resized_image.transpose(2, 0, 1), 0)\n",
    "    output_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB);\n",
    "    result = compiled_model([input_image])[recognition_output_layer]\n",
    "    \n",
    "    # Use different colors to indicate whether the target has the attribute\n",
    "    has_attr = (0,255,255);\n",
    "    no_attr = (255,0,255);\n",
    "    #attribute text height\n",
    "    text_height = 20\n",
    "\n",
    "    #there are 8 attributes, put the 8 attributes text into the picture with different color\n",
    "    for index in range(8):\n",
    "        # print(type(result[0][index]))\n",
    "        if result[0][index] > 0.5:\n",
    "            color = has_attr\n",
    "        else:\n",
    "            color = no_attr\n",
    "        cv2.putText(output_image,attrs[index],(35,text_height),cv2.FONT_HERSHEY_COMPLEX,1,color,2)\n",
    "        text_height += 40\n",
    "    return output_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df0d9cd-98de-4bac-b49c-83b02d44fe15",
   "metadata": {},
   "source": [
    "## Load video and play"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa97cb16-6200-4548-bc43-313c0c35c109",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Can't receive frame (stream end?). Exiting ...\n"
     ]
    }
   ],
   "source": [
    "# if you choose your camera, set the number 0\n",
    "# cap = cv2.VideoCapture(0)\n",
    "# load video \n",
    "mp4dir = Path(\"./data/ceo.mp4\").expanduser()\n",
    "cap = cv2.VideoCapture(str(mp4dir))\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(f\"Cannot open camera\")\n",
    "    exit()\n",
    "\n",
    "while True:\n",
    "    # catch every frame\n",
    "    ret, frame = cap.read()\n",
    "    # if run right, ret = True\n",
    "    if not ret:\n",
    "        print(\"Can't receive frame (stream end?). Exiting ...\")\n",
    "        break\n",
    "    \n",
    "    image = process_image(frame)\n",
    "    # Display the result frame E\n",
    "    cv2.imshow('frame', image)\n",
    "    # print(\"cv had show\")\n",
    "    \n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "    \n",
    "    \n",
    "\n",
    "# finished all, release allï¼ŒAs there is a famous saying,\n",
    "# the rainbow after the rain is more beautiful, and the suffering life is more brilliant\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d5a142-59e4-49ee-8817-205a12bc9216",
   "metadata": {},
   "source": [
    "# Delete the downloaded model\n",
    "\n",
    "The purpose of this block is to clear the downloaded Intel model.\n",
    "\n",
    "When you are done with the above code and no longer need it, you can run the code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2f407135-81fe-4675-b181-0f5065cc26da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model dir has been removed\n"
     ]
    }
   ],
   "source": [
    "# import shutil\n",
    "# import os\n",
    "# # remove model directory\n",
    "# if os.path.exists(model_dir):\n",
    "#     shutil.rmtree(model_dir) \n",
    "#     print('{} dir has been removed'.format(model_dir))\n",
    "# else:\n",
    "#     print('{} dir is not exist'.format(model_dir))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openvino_env",
   "language": "python",
   "name": "openvino_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
