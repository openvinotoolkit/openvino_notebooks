{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53a8ed74-319f-4e72-958e-a0e59ced4981",
   "metadata": {},
   "source": [
    "# Person attributes recognition with OpenVINO\n",
    "\n",
    "This tutorial demonstrates person attributes recognition with MidasNet in OpenVINO. Model information can be found [here](https://docs.openvino.ai/latest/omz_models_model_person_attributes_recognition_crossroad_0230.html)\n",
    "\n",
    "  ![1](./data/1.png)![2](./data/2.png)\n",
    "\n",
    "### Description\n",
    "\n",
    "This model presents a person attributes classification algorithm analysis scenario. It produces probability of person attributions existing on the sample and a position of two point on sample, which can be used for color prob (like, color picker in graphical editors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b072cac-10a6-4b10-9f19-f9cfd56c2573",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"person-attributes-recognition-crossroad-0230\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0724d77a-f9d5-416d-9794-88e5e6efbadf",
   "metadata": {},
   "source": [
    "## Preparation\n",
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf12ece-7edb-40a3-b2ad-cf2dcfc8b67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "from openvino.runtime import Core\n",
    "\n",
    "sys.path.append(\"../utils\")\n",
    "from notebook_utils import load_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f99b35-4e5b-4cfd-b576-cf1f97b9d73a",
   "metadata": {},
   "source": [
    "### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8dd3db-9234-4aeb-b64f-06ef5829cb1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model_dir = Path(\"./model/open_model_zoo_models\").expanduser()\n",
    "omz_cache_dir = Path(\"./model/open_model_zoo_cache\").expanduser()\n",
    "model_dir = Path(\"./model\").expanduser()\n",
    "precision = \"FP16\"\n",
    "\n",
    "# Check if an iGPU is available on this system to use with Benchmark App\n",
    "ie = Core()\n",
    "gpu_available = \"GPU\" in ie.available_devices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2884903e-9ce6-4ab7-886c-cb1ce27e98f6",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Dwonload models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a961f165-6cfc-4ead-9bf8-d7393aa85a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# No need for convert !\n",
    "path_to_model_weights = Path(f'{base_model_dir}/intel/{model_name}/{precision}/{model_name}.bin')\n",
    "\n",
    "if not path_to_model_weights.is_file():\n",
    "    download_command = (f\"omz_downloader --name {model_name} --output_dir {base_model_dir} --cache_dir {omz_cache_dir}\")\n",
    "    ! $download_command\n",
    "else:\n",
    "    print(\"Model has been download\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98efd3f-dc31-4cd7-92b7-5c9f021b14e7",
   "metadata": {},
   "source": [
    "### Load the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43308987-af68-40aa-baaa-2ebc949aa392",
   "metadata": {},
   "outputs": [],
   "source": [
    "ie = Core()\n",
    "path_to_model = path_to_model_weights.with_suffix(\".xml\")\n",
    "print(\"model path is the model's path\")\n",
    "\n",
    "model = ie.read_model(model=path_to_model)\n",
    "compiled_model = ie.compile_model(model=model, device_name=\"CPU\")\n",
    "recognition_output_layer = next(iter(compiled_model.outputs))\n",
    "recognition_input_layer = next(iter(compiled_model.inputs))\n",
    "\n",
    "print(f\"{recognition_output_layer.shape} is output layer's shape\")\n",
    "print(f\"{recognition_input_layer.shape} is input layer's shape\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df2448d8-8577-4cdf-a2a4-e28c9d724a61",
   "metadata": {},
   "source": [
    "## Load image\n",
    "\n",
    "This step loads the image and converts it to the input size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da6d773-e50c-4d59-a68d-225fc7da481d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_file can point to a URL or local image\n",
    "image_file = \"./data/singerstar.jpg\"\n",
    "\n",
    "# mark some attributes\n",
    "attrs = ['is_male', 'has_bag', 'has_backpack', 'has_hat', 'has_longsleeves', 'has_longpants', 'has_longhair', 'has_coat_jacket']\n",
    "\n",
    "image = load_image(image_file)\n",
    "\n",
    "# N,C,H,W = batch size, number of channels, height, width\n",
    "N, C, H, W = recognition_input_layer.shape\n",
    "\n",
    "# Resize image to meet network expected input sizes\n",
    "resized_image = cv2.resize(image, (W, H))\n",
    "\n",
    "# Reshape to network input shape\n",
    "input_image = np.expand_dims(resized_image.transpose(2, 0, 1), 0)\n",
    "\n",
    "output_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB);\n",
    "\n",
    "plt.imshow(output_image);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8609f271-2c73-4b6b-8723-c8e4428824a9",
   "metadata": {},
   "source": [
    "## Do inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59d1af5-0dd6-4b32-a485-37a5917ce066",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the model to inference\n",
    "result = compiled_model([input_image])[recognition_output_layer]\n",
    "\n",
    "# Use different colors to indicate whether the target has the attribute\n",
    "has_attr = (0,255,255);\n",
    "no_attr = (255,0,255);\n",
    "# attribute text height\n",
    "text_height = 50\n",
    "\n",
    "# there are 8 attributes, put the 8 attributes text into the picture with different color\n",
    "for index in range(8):\n",
    "    # print(type(result[0][index]))\n",
    "    if result[0][index] > 0.5:\n",
    "        color = has_attr\n",
    "    else:\n",
    "        color = no_attr\n",
    "    cv2.putText(output_image,attrs[index],(120,text_height),cv2.FONT_HERSHEY_COMPLEX,1,color,2)\n",
    "    text_height += 50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d45aee42-3818-4cad-a4d5-9ec9e6be2337",
   "metadata": {},
   "source": [
    "## Show the result picture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2cd6cdc-a859-49d6-8ecc-fffcf7c87e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_image = cv2.resize(output_image, (W * 2, H * 2))\n",
    "plt.imshow(output_image);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a1a7c9-88b3-4eb3-91a9-7cb05e0832d2",
   "metadata": {},
   "source": [
    "# Delete the downloaded model\n",
    "\n",
    "The purpose of this block is to clear the downloaded Intel model.\n",
    "\n",
    "When you are done with the above code and no longer need it, you can run the code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f407135-81fe-4675-b181-0f5065cc26da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import shutil\n",
    "# import os\n",
    "# # remove model directory\n",
    "# if os.path.exists(model_dir):\n",
    "#     shutil.rmtree(model_dir) \n",
    "#     print(\"model dir has been removed\")\n",
    "# else:\n",
    "#     print(\"model dir is not exist\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openvino_env",
   "language": "python",
   "name": "openvino_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
