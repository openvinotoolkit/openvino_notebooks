{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Asynchronous Inference with OpenVINO™\n",
    "This notebook demonstrates how to use the [Async API](https://docs.openvino.ai/nightly/openvino_docs_deployment_optimization_guide_common.html) for asynchronous execution with OpenVINO. \n",
    "\n",
    "OpenVINO Runtime supports inference in either synchronous or asynchronous mode. The key advantage of the Async API is that when a device is busy with inference, the application can perform other tasks in parallel (e.g. populating inputs or scheduling other requests) rather than wait for the current inference to complete first. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "from openvino.runtime import Core\n",
    "import openvino.runtime as ov\n",
    "from IPython import display\n",
    "import matplotlib.pyplot as plt\n",
    "sys.path.append(\"../utils\")\n",
    "import notebook_utils as utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare model and data processing \n",
    "\n",
    "### Download test model\n",
    "We use a pre-trianed model from OpenVINO's [Open Model Zoo](https://docs.openvino.ai/nightly/model_zoo.html) to start our test. In this case, the model will be excuted to detect the person in each frame of the video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory where model will be downloaded\n",
    "base_model_dir = \"model\"\n",
    "\n",
    "# model name as named in Open Model Zoo\n",
    "model_name = \"person-detection-0202\"\n",
    "precision = \"FP16\"\n",
    "model_path = (\n",
    "    f\"model/intel/{model_name}/{precision}/{model_name}.xml\"\n",
    ")\n",
    "download_command = f\"omz_downloader \" \\\n",
    "                   f\"--name {model_name} \" \\\n",
    "                   f\"--precision {precision} \" \\\n",
    "                   f\"--output_dir {base_model_dir} \" \\\n",
    "                   f\"--cache_dir {base_model_dir}\"\n",
    "! $download_command"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize OpenVINO runtime\n",
    "ie = Core()\n",
    "\n",
    "# read the network and corresponding weights from file\n",
    "model = ie.read_model(model=model_path)\n",
    "\n",
    "# compile the model for the CPU (you can choose manually CPU, GPU, MYRIAD etc.)\n",
    "# or let the engine choose the best available device (AUTO)\n",
    "compiled_model = ie.compile_model(model=model, device_name=\"CPU\")\n",
    "\n",
    "# get input node\n",
    "input_layer_ir = model.input(0)\n",
    "N, C, H, W = input_layer_ir.shape\n",
    "shape = (H, W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create functions for data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(image):\n",
    "    \"\"\"\n",
    "    Define the preprocess function for input data\n",
    "    \n",
    "    :param: image: the orignal input frame\n",
    "    :returns:\n",
    "            resized_image: the image processed\n",
    "    \"\"\"\n",
    "    resized_image = cv2.resize(image, shape)\n",
    "    resized_image = cv2.cvtColor(np.array(resized_image), cv2.COLOR_BGR2RGB)\n",
    "    resized_image = resized_image.transpose((2, 0, 1))\n",
    "    resized_image = np.expand_dims(resized_image, axis=0).astype(np.float32)\n",
    "    return resized_image\n",
    "\n",
    "\n",
    "def postprocess(result, image, fps):\n",
    "    \"\"\"\n",
    "    Define the postprocess function for output data\n",
    "    \n",
    "    :param: result: the inference results\n",
    "            image: the orignal input frame\n",
    "            fps: average throughput calculated for each frame\n",
    "    :returns:\n",
    "            image: the image with bounding box and fps message\n",
    "    \"\"\"\n",
    "    detections = result.reshape(-1, 7)\n",
    "    for i, detection in enumerate(detections):\n",
    "        _, image_id, confidence, xmin, ymin, xmax, ymax = detection\n",
    "        if confidence > 0.5:\n",
    "            xmin = int(max((xmin * image.shape[1]), 10))\n",
    "            ymin = int(max((ymin * image.shape[0]), 10))\n",
    "            xmax = int(min((xmax * image.shape[1]), image.shape[1] - 10))\n",
    "            ymax = int(min((ymax * image.shape[0]), image.shape[0] - 10))\n",
    "            cv2.rectangle(image, (xmin, ymin), (xmax, ymax), (0, 255, 0), 2)\n",
    "            cv2.putText(image, str(round(fps, 2)) + \" fps\", (5, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 3) \n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the test video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = \"../202-vision-superresolution/data/CEO Pat Gelsinger on Leading Intel.mp4\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to improve the throughput of video processing\n",
    "Below we compare the performance of the synchronous and async-based approaches:\n",
    "\n",
    "### Sync Mode (default)\n",
    "Let's see how video processing works with the default approach.<br />\n",
    "Using the synchronous approach, the frame is captured with OpenCV and then immediately processed:\n",
    "\n",
    "<img align='center' src=\"https://user-images.githubusercontent.com/91237924/168452573-d354ea5b-7966-44e5-813d-f9053be4338a.png\" alt=\"drawing\" width=\"600\"/><br />\n",
    "\n",
    ">while(true) {<br />\n",
    "*&emsp;// capture frame<br />\n",
    "&emsp;// populate CURRENT InferRequest<br />\n",
    "&emsp;// Infer CURRENT InferRequest&emsp;//this call is synchronous<br />\n",
    "&emsp;// display CURRENT result<br />*\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sync_api(source, flip, fps, use_popup, skip_first_frames):\n",
    "    \"\"\"\n",
    "    Define the main function for video processing in sync mode\n",
    "    \n",
    "    :param: source: the video path or the ID of your webcam\n",
    "    :returns:\n",
    "            sync_fps: the inference throughput in sync mode\n",
    "    \"\"\"\n",
    "    num = 0\n",
    "    infer_request = compiled_model.create_infer_request()\n",
    "    player = None\n",
    "    try:\n",
    "        # Create a video player\n",
    "        player = utils.VideoPlayer(source, flip=flip, fps=fps, skip_first_frames=skip_first_frames)\n",
    "        # Start capturing\n",
    "        start_time = time.time()\n",
    "        player.start()\n",
    "        if use_popup:\n",
    "            title = \"Press ESC to Exit\"\n",
    "            cv2.namedWindow(title, cv2.WINDOW_GUI_NORMAL | cv2.WINDOW_AUTOSIZE)\n",
    "        while True:\n",
    "            frame = player.next()\n",
    "            if frame is None:\n",
    "                print(\"Source ended\")\n",
    "                break\n",
    "            # if the frame is larger than full HD, reduce its size to improve performance\n",
    "            scale = 1280 / max(frame.shape)\n",
    "            if scale < 1:\n",
    "                frame = cv2.resize(frame, None, fx=scale, fy=scale, interpolation=cv2.INTER_AREA)\n",
    "            resized_frame = preprocess(frame)\n",
    "            infer_request.set_tensor(input_layer_ir, ov.Tensor(resized_frame))\n",
    "            # Start the inference request in synchronous mode \n",
    "            infer_request.infer()\n",
    "            res = infer_request.get_output_tensor(0).data\n",
    "            stop_time = time.time()\n",
    "            total = stop_time - start_time\n",
    "            num = num + 1\n",
    "            sync_fps = num / total \n",
    "            frame = postprocess(res, frame, sync_fps)\n",
    "            # Display the results\n",
    "            if use_popup:\n",
    "                cv2.imshow(title, frame)\n",
    "                key = cv2.waitKey(1)\n",
    "                # escape = 27\n",
    "                if key == 27:\n",
    "                    break\n",
    "            else:\n",
    "                # Encode numpy array to jpg\n",
    "                _, encoded_img = cv2.imencode(\".jpg\", frame, params=[cv2.IMWRITE_JPEG_QUALITY, 90])\n",
    "                # Create IPython image\n",
    "                i = display.Image(data=encoded_img)\n",
    "                # Display the image in this notebook\n",
    "                display.clear_output(wait=True)\n",
    "                display.display(i)         \n",
    "    # ctrl-c\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"Interrupted\")\n",
    "    # Any different error\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "    finally:\n",
    "        if player is not None:\n",
    "            # stop capturing\n",
    "            player.stop()\n",
    "            return sync_fps\n",
    "        if use_popup:\n",
    "            cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test performance in Sync Mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sync_fps = sync_api(source=video_path, flip=False, fps=30, use_popup=False, skip_first_frames=1000)\n",
    "print(f\"average throuput in sync mode: {sync_fps:.2f} fps\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Async Mode \n",
    "\n",
    "Let’s see how the OpenVINO Async API can improve the overall frame rate of an application. The key advantage of the Async approach is as follows: while a device is busy with the inference, the application can do other things in parallel (e.g. populating inputs or scheduling other requests) rather than wait for the current inference to complete first.\n",
    "\n",
    "<img align='center' src=\"https://user-images.githubusercontent.com/91237924/168452572-c2ff1c59-d470-4b85-b1f6-b6e1dac9540e.png\" alt=\"drawing\" width=\"600\"/><br />\n",
    "\n",
    "In the example below, inference is applied to the results of the video decoding. So it is possible to keep multiple infer requests, and while the current request is processed, the input frame for the next is being captured. This essentially hides the latency of capturing, so that the overall frame rate is rather determined only by the slowest part of the pipeline (decoding vs inference) and not by the sum of the stages.\n",
    "\n",
    ">while(true) {<br />\n",
    "*&emsp;// capture frame<br />\n",
    "&emsp;// populate NEXT InferRequest<br />\n",
    "&emsp;// start NEXT InferRequest&emsp;//this call is async and returns immediately<br />\n",
    "&emsp;// wait for the CURRENT InferRequest<br />\n",
    "&emsp;// display CURRENT result<br />\n",
    "&emsp;// swap CURRENT and NEXT InferRequests<br />*\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def async_api(source, flip, fps, use_popup, skip_first_frames):\n",
    "    \"\"\"\n",
    "    Define the main function for video processing in async mode\n",
    "    \n",
    "    :param: source: the video path or the ID of your webcam\n",
    "    :returns:\n",
    "            async_fps: the inference throughput in async mode\n",
    "    \"\"\"\n",
    "    num = 0\n",
    "    # Create 2 infer requests\n",
    "    curr_request = compiled_model.create_infer_request()\n",
    "    next_request = compiled_model.create_infer_request()\n",
    "    player = None\n",
    "    try:\n",
    "        # Create a video player\n",
    "        player = utils.VideoPlayer(source, flip=flip, fps=fps, skip_first_frames=skip_first_frames)\n",
    "        # Start capturing\n",
    "        start_time = time.time()\n",
    "        player.start()\n",
    "        # Read CURRENT frame\n",
    "        frame = player.next()\n",
    "        if use_popup:\n",
    "            title = \"Press ESC to Exit\"\n",
    "            cv2.namedWindow(title, cv2.WINDOW_GUI_NORMAL | cv2.WINDOW_AUTOSIZE)\n",
    "        while True:\n",
    "            # Read NEXT frame\n",
    "            next_frame = player.next()\n",
    "            if frame is None:\n",
    "                print(\"Source ended\")\n",
    "                break\n",
    "            # if frame larger than full HD, reduce size to improve the performance\n",
    "            scale = 1280 / max(frame.shape)\n",
    "            if scale < 1:\n",
    "                frame = cv2.resize(frame, None, fx=scale, fy=scale, interpolation=cv2.INTER_AREA)\n",
    "            resized_frame = preprocess(frame)\n",
    "            curr_request.set_tensor(input_layer_ir, ov.Tensor(resized_frame))\n",
    "            # Start the CURRENT inference request\n",
    "            curr_request.start_async()\n",
    "            # Waiting for NEXT inference result\n",
    "            if next_request.wait_for(-1) == 1:\n",
    "                res = next_request.get_output_tensor(0).data\n",
    "                stop_time = time.time()\n",
    "                total = stop_time - start_time\n",
    "                num = num + 1\n",
    "                async_fps = num / total  \n",
    "                frame = postprocess(res, frame, async_fps)\n",
    "                # Display the results\n",
    "                if use_popup:\n",
    "                    cv2.imshow(title, frame)\n",
    "                    key = cv2.waitKey(1)\n",
    "                    # escape = 27\n",
    "                    if key == 27:\n",
    "                        break\n",
    "                else:\n",
    "                    # Encode numpy array to jpg\n",
    "                    _, encoded_img = cv2.imencode(\".jpg\", frame, params=[cv2.IMWRITE_JPEG_QUALITY, 90])\n",
    "                    # Create IPython image\n",
    "                    i = display.Image(data=encoded_img)\n",
    "                    # Display the image in this notebook\n",
    "                    display.clear_output(wait=True)\n",
    "                    display.display(i)\n",
    "            # Swap CURRENT and NEXT frames\n",
    "            frame = next_frame\n",
    "            # Swap CURRENT and NEXT infer requests\n",
    "            curr_request, next_request = next_request, curr_request         \n",
    "    # ctrl-c\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"Interrupted\")\n",
    "    # Any different error\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "    finally:\n",
    "        if player is not None:\n",
    "            # stop capturing\n",
    "            player.stop()\n",
    "            return async_fps\n",
    "        if use_popup:\n",
    "            cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the perfromance in Async Mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async_fps = async_api(source=video_path, flip=False, fps=30, use_popup=False, skip_first_frames=1000)\n",
    "print(f\"average throuput in async mode: {async_fps:.2f} fps\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare the performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 0.4\n",
    "fontsize = 14\n",
    "\n",
    "plt.rc('font', size=fontsize)\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 8))\n",
    "\n",
    "rects1 = ax.bar([0], sync_fps, width, color='#557f2d')\n",
    "rects2 = ax.bar([width], async_fps, width)\n",
    "ax.set_ylabel(\"frames per second\")\n",
    "ax.set_xticks([0, width]) \n",
    "ax.set_xticklabels([\"Sync mode\", \"Async mode\"])\n",
    "ax.set_xlabel(\"Higher is better\")\n",
    "\n",
    "fig.suptitle('Sync mode VS Async mode')\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
