{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handwritten Chinese and Japanese OCR\n",
    "\n",
    "In this tutorial optical character recognition for handwritten Chinese (simplified) and Japanese is presented. Roman alphabet OCR can be find in [notebook 208](../208-optical-character-recognition). This model is capable of doing only one line of symbols each time. \n",
    "\n",
    "Models used for this notebooks are [handwritten-japanese-recognition](https://docs.openvinotoolkit.org/latest/omz_models_model_handwritten_japanese_recognition_0001.html) and [handwritten-simplified-chinese](https://docs.openvinotoolkit.org/latest/omz_models_model_handwritten_simplified_chinese_recognition_0001.html). To decode models output to readable text [kondate_nakayosi](https://github.com/openvinotoolkit/open_model_zoo/blob/master/data/dataset_classes/kondate_nakayosi.txt) and [scut_ept](https://github.com/openvinotoolkit/open_model_zoo/blob/master/data/dataset_classes/scut_ept.txt) charlists are used. Both model are from [Open Model Zoo](https://github.com/openvinotoolkit/open_model_zoo/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports modules required to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sys\n",
    "from itertools import groupby\n",
    "from openvino.inference_engine import IECore\n",
    "from os import path, makedirs\n",
    "\n",
    "sys.path.append(\"../utils\")\n",
    "from notebook_utils import download_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper class\n",
    "\n",
    "To run OCR we need both model and charlist, for this reason named ```Files``` class is created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Files:\n",
    "    def __init__(self, model: str, charlist_link: str, demo_image_name: str):\n",
    "        self.model = model\n",
    "        self.charlist_link = charlist_link\n",
    "        self.demo_image_name = demo_image_name\n",
    "        self.charlist_name = self.charlist_link.split('/')[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings\n",
    "\n",
    "Set up all consts and folders used in this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directories where data will be placed\n",
    "model_folder = \"model\"\n",
    "data_folder = \"data\"\n",
    "charlist_folder = f\"{model_folder}/charlists\"\n",
    "\n",
    "# Precision used by model\n",
    "precision = \"FP16\"\n",
    "\n",
    "model_extensions = (\"bin\", \"xml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Names and links used for Japanese and Chinese"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Japanese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name of model that will be used\n",
    "handwritten_japanese_model_name = \"handwritten-japanese-recognition-0001\"\n",
    "\n",
    "# Link to charlist\n",
    "japanese_charlist_link = \"https://raw.githubusercontent.com/openvinotoolkit/open_model_zoo/master/data/dataset_classes/kondate_nakayosi.txt\"\n",
    "\n",
    "# Link to demo image\n",
    "japanese_image_link = 'https://github.com/openvinotoolkit/open_model_zoo/raw/master/demos/handwritten_text_recognition_demo/python/data/handwritten_japanese_test.png'\n",
    "\n",
    "# Extract image name from demo link\n",
    "japanese_image_name = 'handwritten_japanese_test.png'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chinese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name of model that will be used\n",
    "handwritten_simplified_chinese_model_name = \"handwritten-simplified-chinese-recognition-0001\"\n",
    "\n",
    "# Link to charlist\n",
    "simplified_chinese_charlist_link = \"https://raw.githubusercontent.com/openvinotoolkit/open_model_zoo/master/data/dataset_classes/scut_ept.txt\"\n",
    "\n",
    "# Link to demo image\n",
    "chinese_image_link = 'https://user-images.githubusercontent.com/36741649/140065813-1970cd70-53c6-4d6c-b403-7e6974df34f7.jpg'\n",
    "\n",
    "# Extract image name from demo link\n",
    "chinese_image_name = 'handwritten_chinese_test.jpg'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create directories for data and model\n",
    "\n",
    "Charlists doesn't require to create additional folder as the download function itself creates subfolder inside model folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "makedirs(data_folder, exist_ok=True)\n",
    "makedirs(model_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download images\n",
    "\n",
    "Download demo images for both models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_file(url=chinese_image_link, filename=chinese_image_name, directory=data_folder, show_progress=False)\n",
    "download_file(url=japanese_image_link, filename=japanese_image_name, directory=data_folder, show_progress=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group files used by languages to classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Japanese files grouped as a class\n",
    "japanese_files = Files(model=handwritten_japanese_model_name, charlist_link=japanese_charlist_link, demo_image_name=japanese_image_name)\n",
    "\n",
    "# Chinese files grouped as a class\n",
    "chinese_files = Files(model=handwritten_simplified_chinese_model_name, charlist_link=simplified_chinese_charlist_link, demo_image_name=chinese_image_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download models and convert public model\n",
    "\n",
    "If it is your first run models will download and convert here. It might take up to ten minutes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_files(language_files: Files):\n",
    "    # Download model\n",
    "    for extension in model_extensions:\n",
    "        path_to_model = f'{model_folder}/intel/{language_files.model}/{precision}/{language_files.model}.{extension}'\n",
    "        if not path.isfile(path_to_model):\n",
    "            download_command = f'omz_downloader --name {language_files.model} --output_dir {model_folder} --precision {precision}'\n",
    "            print(download_command)\n",
    "            ! $download_command\n",
    "\n",
    "    # Download charlist            \n",
    "    if not path.isfile(f'{charlist_folder}/{language_files.charlist_name}'):\n",
    "        download_file(language_files.charlist_link, directory=charlist_folder, show_progress=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Japanese files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_files(language_files=japanese_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Chinese files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_files(language_files=chinese_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Select language\n",
    "\n",
    "Depending on which language you wants to use, uncomment one of lines below to choose as ```currently_used_model``` either ```chinese_files.model``` or ```japanese_files.model```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def used_language(language: str) -> Files:\n",
    "    languages = {\n",
    "        \"chinese\": chinese_files,\n",
    "        \"japaneses\": japaneses_files\n",
    "    }\n",
    "    if language not in languages.keys():\n",
    "        raise KeyError(f\"Invalid language choosen! Please pick one of those: {', '.join(languages.keys())}\")\n",
    "    return languages.get(language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select language by using either use_language(language='chinese') or use_language(language='japanese')\n",
    "\n",
    "selected_language = use_language(language='chinese')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load network and execute it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ie = IECore()\n",
    "\n",
    "path_to_model = f\"{model_folder}/intel/{selected_language.model}/{precision}/{selected_language.model}.xml\"\n",
    "\n",
    "net = ie.read_network(\n",
    "    model=path_to_model\n",
    ")\n",
    "\n",
    "# To check available device names run line below\n",
    "# print(ie.available_devices)\n",
    "\n",
    "exec_net = ie.load_network(network=net, device_name=\"CPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch information about input and output layers \n",
    "\n",
    "It will be needed further to provide input and read output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recognition_output_layer = next(iter(exec_net.outputs))\n",
    "recognition_input_layer = next(iter(exec_net.input_info))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Load an Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Read file name of demo file based on used model\n",
    "\n",
    "file_name = selected_language.demo_image_name\n",
    "\n",
    "# Text detection models expects image in grayscale format\n",
    "# IMPORTANT!!! This model allows to read only one line at time\n",
    "\n",
    "# Read image\n",
    "image = cv2.imread(filename=f\"{data_folder}/{file_name}\", flags=cv2.IMREAD_GRAYSCALE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch information about image and input layer shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch shape\n",
    "image_height, image_width = image.shape\n",
    "\n",
    "# B,C,H,W = batch size, number of channels, height, width\n",
    "_, _, H, W = net.input_info[recognition_input_layer].input_data.shape\n",
    "\n",
    "# Calculate aspect ratio between image width and height to calculate padding\n",
    "aspect_ratio = image_width / image_height\n",
    "\n",
    "# Calculate scale ratio between input shape height and image height to resize image\n",
    "scale_ratio = H / image_height"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resize image to meet network expected input sizes\n",
    "resized_image = cv2.resize(image, None, fx=scale_ratio, fy=scale_ratio, interpolation=cv2.INTER_AREA)\n",
    "\n",
    "# Pad image to meet input size\n",
    "resized_image = np.pad(resized_image, ((0, 0), (0, W - resized_image.shape[1])), mode='edge')\n",
    "\n",
    "# Reshape to network input shape\n",
    "input_image = resized_image[None, None, :, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualise input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 1))\n",
    "plt.axis('off')\n",
    "plt.imshow(resized_image, cmap='gray', vmin=0, vmax=255);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare charlist\n",
    "\n",
    "Depending on used language charlists will differ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get dictionary to encode output, based on model documentation\n",
    "used_charlist = selected_language.charlist_name\n",
    "\n",
    "# With both models, there should be blank symbol added at index 0 of each charlists\n",
    "blank_char = '~'\n",
    "\n",
    "with open(f\"{charlist_folder}/{used_charlist}\", 'r', encoding='utf-8') as charlist:\n",
    "    letters = blank_char + ''.join(line.strip() for line in charlist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run inference on model\n",
    "predictions = exec_net.infer(inputs={recognition_input_layer: input_image})[recognition_output_layer]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process infered data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove unnececery dimension\n",
    "predictions = np.squeeze(predictions)\n",
    "\n",
    "# Run argmax to pick most possible symbols\n",
    "predictions_indexes = np.argmax(predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use groupby to remove concurrent letters, as required by CTC greedy decoding\n",
    "output_text_indexes = list(groupby(predictions_indexes))\n",
    "\n",
    "# Remove grouper objects\n",
    "output_text_indexes, _ = np.transpose(output_text_indexes, (1, 0))\n",
    "\n",
    "# Remove blank symbols \n",
    "output_text_indexes = output_text_indexes[output_text_indexes != 0] \n",
    "\n",
    "# Assign letters to indexes from output array\n",
    "output_text = [letters[letter_index] for letter_index in output_text_indexes]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 1))\n",
    "plt.axis('off')\n",
    "plt.imshow(resized_image, cmap='gray', vmin=0, vmax=255)\n",
    "\n",
    "print(''.join(output_text))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openvino_env",
   "language": "python",
   "name": "openvino_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
