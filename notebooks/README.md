# List of Notebooks

Each notebook is located in a directory. Please follow the instructions in the
[README](https://github.com/openvinotoolkit/openvino_notebooks/) before launching Jupyter Lab or
Jupyter Notebook.

Notebooks that have a ![binder logo](https://mybinder.org/badge_logo.svg) button can be
opened in [Binder](https://mybinder.org/), to try the notebooks without installing anything. Binder is a free online service with limited resources. For better performance, it is recommended to install the notebooks locally by following the instructions in the
[README](https://github.com/openvinotoolkit/openvino_notebooks/).

| Notebook      | Description | Preview     |
| :---:        |    :---   |          :----: |
| [001-hello-world](001-hello-world/001-hello-world.ipynb) &nbsp; [![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/openvinotoolkit/openvino_notebooks/HEAD?filepath=notebooks%2F001-hello-world%2F001-hello-world.ipynb) | <ul><li>A very basic introduction to OpenVINO's [Python API](https://docs.openvinotoolkit.org/latest/ie_python_api/annotated.html)</li><li> Shows how to do inference on a [mobilenetv3](https://docs.openvinotoolkit.org/latest/omz_models_model_mobilenet_v3_small_1_0_224_tf.html) image classification model</li></ul> | <img src="https://user-images.githubusercontent.com/36741649/127170593-86976dc3-e5e4-40be-b0a6-206379cd7df5.jpg" width=300><br>   |
| [002-openvino-api](002-openvino-api/002-openvino-api.ipynb) [![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/openvinotoolkit/openvino_notebooks/HEAD?filepath=notebooks%2F002-openvino-api%2F002-openvino-api.ipynb)  | OpenVINO API tutorial that covers the following: <ul><li>Load Inference Engine and Show Info</li><li>Loading a Model</li><ul><li>IR Model</li><li>ONNX Model</li></ul><li>Getting Information about a Model</li><ul><li>Model Inputs</li><li>Model Outputs</li></ul><li>Doing Inference on a Model</li><li>Reshaping and Resizing</li><ul><li>Change Image Size</li><li>Change Batch Size</li></ul></ul> | <img src="https://user-images.githubusercontent.com/36741649/127170846-c4e13492-3e2f-43cd-b8b7-0cc5691890cf.jpg" width=300><br>  |
| [101-tensorflow-to-openvino](101-tensorflow-to-openvino/101-tensorflow-to-openvino.ipynb) &nbsp; [![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/openvinotoolkit/openvino_notebooks/HEAD?filepath=notebooks%2F101-tensorflow-to-openvino%2F101-tensorflow-to-openvino.ipynb) | <ul><li>Demonstrates how to convert [TensorFlow](https://www.tensorflow.org/) models to OpenVINO IR</li><li>Uses Model Optimizer to convert the same [mobilenetv3](https://docs.openvinotoolkit.org/latest/omz_models_model_mobilenet_v3_small_1_0_224_tf.html) image classification model from `001-hello-world` notebook</li></ul> | <img src="https://user-images.githubusercontent.com/36741649/127170593-86976dc3-e5e4-40be-b0a6-206379cd7df5.jpg" width=300><br> |
| [102-pytorch-onnx-to-openvino](102-pytorch-onnx-to-openvino/102-pytorch-onnx-to-openvino.ipynb) &nbsp; [![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/openvinotoolkit/openvino_notebooks/HEAD?filepath=notebooks%2F102-pytorch-onnx-to-openvino%2F102-pytorch-onnx-to-openvino.ipynb) | <ul><li>Demonstrates how to convert [PyTorch](https://pytorch.org/) models to OpenVINO IR</li><li>Uses Model Optimizer to convert the open source [fastseg](https://github.com/ekzhang/fastseg/) semantic segmentation model</li></ul> | <img src="https://user-images.githubusercontent.com/15709723/125182687-fda1a180-e1c4-11eb-90cf-36a50e5ad1c3.png" width=300>  |
| [104-model-tools](104-model-tools/104-model-tools.ipynb) &nbsp; [![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/openvinotoolkit/openvino_notebooks/HEAD?filepath=notebooks%2F104-model-tools%2F104-model-tools.ipynb) | <ul><li>Demonstrates how to download a model from Open Model Zoo, convert it to OpenVINO's IR format, show information about the model, and asynchronously benchmark the model on CPU, iGPU and both devices combined. | <img src="https://user-images.githubusercontent.com/36741649/127171477-793628c4-8095-42b5-beab-3d39bd34610e.jpg" width=300>  |
| [201-vision-monodepth](201-vision-monodepth/201-vision-monodepth.ipynb) &nbsp; [![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/openvinotoolkit/openvino_notebooks/HEAD?filepath=notebooks%2F201-vision-monodepth%2F201-vision-monodepth.ipynb) | <ul><li>Demonstrates Monocular Depth Estimation with MidasNet model in OpenVINO</li><li>Uses [OpenCV](https://opencv.org/) to load and process frames from an image and a video</li><li>Generates output video showing input and output side by side</li><li>Users can upload their own videos and images, input data will be resized</li></ul> | <img src="https://user-images.githubusercontent.com/36741649/127171553-18396160-1430-4f84-bf3a-b6ca7c83d966.gif" width=300> |
| [202-vision-superresolution-image](202-vision-superresolution/202-vision-superresolution-image.ipynb) &nbsp; [![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/openvinotoolkit/openvino_notebooks/HEAD?filepath=notebooks%2F202-vision-superresolution%2F202-vision-superresolution-image.ipynb)| <ul><li>Demonstrates how to use [single-image-super-resolution-1032](https://docs.openvinotoolkit.org/latest/omz_models_model_single_image_super_resolution_1032.html) from Open Model Zoo</li><li>A raw image is provided and upscaled</li><li>Users can upload their own raw images and try upscaling</li></ul> | <img src="202-vision-superresolution/data/tower.jpg"> ||
| [202-vision-superresolution-video](202-vision-superresolution/202-vision-superresolution-video.ipynb) &nbsp; [![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/openvinotoolkit/openvino_notebooks/HEAD?filepath=notebooks%2F202-vision-superresolution%2F202-vision-superresolution-video.ipynb) | <ul><li>Same as previous notebook, but upscales video instead of just an image</li><li>Users can upload their own video files to try upscaling</li></ul> | <img src="202-vision-superresolution/data/CEO Pat Gelsinger on Leading Intel.gif"> |
| [205-vision-background-removal](205-vision-background-removal/205-vision-background-removal.ipynb) &nbsp; [![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/openvinotoolkit/openvino_notebooks/HEAD?filepath=notebooks%2F205-vision-background-removal%2F205-vision-background-removal.ipynb) | <ul><li>Demonstrates background removal in images</li><li>The open source [U^2-Net](https://github.com/xuebinqin/U-2-Net) model is converted from PyTorch</li><li>Users can upload their own images to remove and replace the background with OpenVINO and OpenCV</li></ul> | <img src="https://user-images.githubusercontent.com/15709723/125184237-f4b6cd00-e1d0-11eb-8e3b-d92c9a728372.png"> |
| [206-vision-paddlegan-anime](206-vision-paddlegan-anime/206-vision-paddlegan-anime.ipynb) &nbsp; [![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/openvinotoolkit/openvino_notebooks/HEAD?filepath=notebooks%2F206-vision-paddlegan-anime%2F206-vision-paddlegan-anime.ipynb) | <ul><li>Demonstrates using PaddlePaddle models with OpenVINO</li><li>The open source [AnimeGAN](https://github.com/PaddlePaddle/PaddleGAN) model is converted with paddle2onnx and then OpenVINO IR with Model Optimizer</li><li>Shows inference results on the AnimeGAN model</li><li>Benchmark app shows performance on CPU, iGPU and both devices together using [MULTI plugin](https://docs.openvinotoolkit.org/latest/openvino_docs_IE_DG_supported_plugins_MULTI.html)</li><li>Users can upload their own images to try out</li></ul> | <img src="https://user-images.githubusercontent.com/15709723/125184441-b4584e80-e1d2-11eb-8964-d8131cd97409.png"> |
| [301-tensorflow-training-openvino](301-tensorflow-training-openvino/301-tensorflow-training-openvino.ipynb) | <ul><li>Demonstrates end-to-end training to deployment workflow starting with TensorFlowâ€™s Flowers classification demo</li><li>Downloads flowers dataset, download keras model, train 10 epochs on CPU, test trained model, convert to OpenVINO IR and test IR performance</li></ul> | `This image most likely belongs to dandelion with a 99.02 percent confidence.`<br><img src="https://upload.wikimedia.org/wikipedia/commons/4/48/A_Close_Up_Photo_of_a_Dandelion.jpg" width=300> |
| [301-tensorflow-training-openvino-pot](301-tensorflow-training-openvino/301-tensorflow-training-openvino-pot.ipynb) | <ul><li>Demonstrates post-training quantization with flower IR model from previous notebook</li><li>Uses [Post Training Optimization Tool](https://docs.openvinotoolkit.org/latest/pot_README.html) from OpenVINO with default quantization method</li><li>Shows benchmark app performance on CPU, iGPU and MULTI:CPU,GPU</li></ul> | `This image most likely belongs to dandelion with a 99.08 percent confidence.`<br><img src="https://upload.wikimedia.org/wikipedia/commons/4/48/A_Close_Up_Photo_of_a_Dandelion.jpg" width=300> |
