{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SpeechBrain Emotion Recognition with OpenVINO\n",
    "\n",
    "[SpeechBrain](https://github.com/speechbrain/speechbrain) is an open-source PyTorch toolkit that accelerates Conversational AI development, i.e., the technology behind speech assistants, chatbots, and large language models. \n",
    "\n",
    "Lear more in [GitHub repo](https://github.com/speechbrain/speechbrain) and [paper](https://arxiv.org/pdf/2106.04624)\n",
    "\n",
    "This notebook tutorial demonstrates optimization and inference of speechbrain emotion recognition model with OpenVINO.\n",
    "\n",
    "#### Table of contents:\n",
    "\n",
    "- [Installations](#Installations)\n",
    "- [Imports](#Imports)\n",
    "- [Prepare base model](#Prepare-base-model)\n",
    "- [Initialize model](#Initialize-model)\n",
    "- [PyTorch inference](#PyTorch-inference)\n",
    "- [SpeechBrain model optimization with Intel OpenVINO](#SpeechBrain-model-optimization-with-Intel-OpenVINO)\n",
    "    - [Step 1: Prepare input tensor](#Step-1:-Prepare-input-tensor)\n",
    "    - [Step 2: Convert model to OpenVINO IR](#Step-2:-Convert-model-to-OpenVINO-IR)\n",
    "    - [Step 3: OpenVINO model inference](#Step-3:-OpenVINO-model-inference)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installations\n",
    "[back to top ⬆️](#Table-of-contents:)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: speechbrain in /home/psakhamo/.venv/lib/python3.10/site-packages (1.0.0)\n",
      "Requirement already satisfied: hyperpyyaml in /home/psakhamo/.venv/lib/python3.10/site-packages (from speechbrain) (1.2.2)\n",
      "Requirement already satisfied: joblib in /home/psakhamo/.venv/lib/python3.10/site-packages (from speechbrain) (1.4.2)\n",
      "Requirement already satisfied: numpy in /home/psakhamo/.venv/lib/python3.10/site-packages (from speechbrain) (1.26.4)\n",
      "Requirement already satisfied: packaging in /home/psakhamo/.venv/lib/python3.10/site-packages (from speechbrain) (24.0)\n",
      "Requirement already satisfied: scipy in /home/psakhamo/.venv/lib/python3.10/site-packages (from speechbrain) (1.13.1)\n",
      "Requirement already satisfied: sentencepiece in /home/psakhamo/.venv/lib/python3.10/site-packages (from speechbrain) (0.2.0)\n",
      "Requirement already satisfied: torch>=1.9 in /home/psakhamo/.venv/lib/python3.10/site-packages (from speechbrain) (2.3.0)\n",
      "Requirement already satisfied: torchaudio in /home/psakhamo/.venv/lib/python3.10/site-packages (from speechbrain) (2.3.0)\n",
      "Requirement already satisfied: tqdm in /home/psakhamo/.venv/lib/python3.10/site-packages (from speechbrain) (4.66.4)\n",
      "Requirement already satisfied: huggingface-hub in /home/psakhamo/.venv/lib/python3.10/site-packages (from speechbrain) (0.23.1)\n",
      "Requirement already satisfied: filelock in /home/psakhamo/.venv/lib/python3.10/site-packages (from torch>=1.9->speechbrain) (3.14.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/psakhamo/.venv/lib/python3.10/site-packages (from torch>=1.9->speechbrain) (4.12.0)\n",
      "Requirement already satisfied: sympy in /home/psakhamo/.venv/lib/python3.10/site-packages (from torch>=1.9->speechbrain) (1.12)\n",
      "Requirement already satisfied: networkx in /home/psakhamo/.venv/lib/python3.10/site-packages (from torch>=1.9->speechbrain) (3.3)\n",
      "Requirement already satisfied: jinja2 in /home/psakhamo/.venv/lib/python3.10/site-packages (from torch>=1.9->speechbrain) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /home/psakhamo/.venv/lib/python3.10/site-packages (from torch>=1.9->speechbrain) (2024.5.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/psakhamo/.venv/lib/python3.10/site-packages (from torch>=1.9->speechbrain) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/psakhamo/.venv/lib/python3.10/site-packages (from torch>=1.9->speechbrain) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/psakhamo/.venv/lib/python3.10/site-packages (from torch>=1.9->speechbrain) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/psakhamo/.venv/lib/python3.10/site-packages (from torch>=1.9->speechbrain) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/psakhamo/.venv/lib/python3.10/site-packages (from torch>=1.9->speechbrain) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/psakhamo/.venv/lib/python3.10/site-packages (from torch>=1.9->speechbrain) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/psakhamo/.venv/lib/python3.10/site-packages (from torch>=1.9->speechbrain) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/psakhamo/.venv/lib/python3.10/site-packages (from torch>=1.9->speechbrain) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/psakhamo/.venv/lib/python3.10/site-packages (from torch>=1.9->speechbrain) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /home/psakhamo/.venv/lib/python3.10/site-packages (from torch>=1.9->speechbrain) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/psakhamo/.venv/lib/python3.10/site-packages (from torch>=1.9->speechbrain) (12.1.105)\n",
      "Requirement already satisfied: triton==2.3.0 in /home/psakhamo/.venv/lib/python3.10/site-packages (from torch>=1.9->speechbrain) (2.3.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/psakhamo/.venv/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.9->speechbrain) (12.5.40)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/psakhamo/.venv/lib/python3.10/site-packages (from huggingface-hub->speechbrain) (6.0.1)\n",
      "Requirement already satisfied: requests in /home/psakhamo/.venv/lib/python3.10/site-packages (from huggingface-hub->speechbrain) (2.32.2)\n",
      "Requirement already satisfied: ruamel.yaml>=0.17.28 in /home/psakhamo/.venv/lib/python3.10/site-packages (from hyperpyyaml->speechbrain) (0.18.6)\n",
      "Requirement already satisfied: ruamel.yaml.clib>=0.2.7 in /home/psakhamo/.venv/lib/python3.10/site-packages (from ruamel.yaml>=0.17.28->hyperpyyaml->speechbrain) (0.2.8)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/psakhamo/.venv/lib/python3.10/site-packages (from jinja2->torch>=1.9->speechbrain) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/psakhamo/.venv/lib/python3.10/site-packages (from requests->huggingface-hub->speechbrain) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/psakhamo/.venv/lib/python3.10/site-packages (from requests->huggingface-hub->speechbrain) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/psakhamo/.venv/lib/python3.10/site-packages (from requests->huggingface-hub->speechbrain) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/psakhamo/.venv/lib/python3.10/site-packages (from requests->huggingface-hub->speechbrain) (2024.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/psakhamo/.venv/lib/python3.10/site-packages (from sympy->torch>=1.9->speechbrain) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Looking in indexes: https://download.pytorch.org/whl/cpu\n",
      "Requirement already satisfied: torch>=1.9.0 in /home/psakhamo/.venv/lib/python3.10/site-packages (2.3.0)\n",
      "Requirement already satisfied: torchaudio>=1.9.0 in /home/psakhamo/.venv/lib/python3.10/site-packages (2.3.0)\n",
      "Requirement already satisfied: filelock in /home/psakhamo/.venv/lib/python3.10/site-packages (from torch>=1.9.0) (3.14.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/psakhamo/.venv/lib/python3.10/site-packages (from torch>=1.9.0) (4.12.0)\n",
      "Requirement already satisfied: sympy in /home/psakhamo/.venv/lib/python3.10/site-packages (from torch>=1.9.0) (1.12)\n",
      "Requirement already satisfied: networkx in /home/psakhamo/.venv/lib/python3.10/site-packages (from torch>=1.9.0) (3.3)\n",
      "Requirement already satisfied: jinja2 in /home/psakhamo/.venv/lib/python3.10/site-packages (from torch>=1.9.0) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /home/psakhamo/.venv/lib/python3.10/site-packages (from torch>=1.9.0) (2024.5.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/psakhamo/.venv/lib/python3.10/site-packages (from torch>=1.9.0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/psakhamo/.venv/lib/python3.10/site-packages (from torch>=1.9.0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/psakhamo/.venv/lib/python3.10/site-packages (from torch>=1.9.0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/psakhamo/.venv/lib/python3.10/site-packages (from torch>=1.9.0) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/psakhamo/.venv/lib/python3.10/site-packages (from torch>=1.9.0) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/psakhamo/.venv/lib/python3.10/site-packages (from torch>=1.9.0) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/psakhamo/.venv/lib/python3.10/site-packages (from torch>=1.9.0) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/psakhamo/.venv/lib/python3.10/site-packages (from torch>=1.9.0) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/psakhamo/.venv/lib/python3.10/site-packages (from torch>=1.9.0) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /home/psakhamo/.venv/lib/python3.10/site-packages (from torch>=1.9.0) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/psakhamo/.venv/lib/python3.10/site-packages (from torch>=1.9.0) (12.1.105)\n",
      "Requirement already satisfied: triton==2.3.0 in /home/psakhamo/.venv/lib/python3.10/site-packages (from torch>=1.9.0) (2.3.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/psakhamo/.venv/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.9.0) (12.5.40)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/psakhamo/.venv/lib/python3.10/site-packages (from jinja2->torch>=1.9.0) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/psakhamo/.venv/lib/python3.10/site-packages (from sympy->torch>=1.9.0) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: transformers>=4.30.0 in /home/psakhamo/.venv/lib/python3.10/site-packages (4.41.1)\n",
      "Requirement already satisfied: huggingface_hub>=0.8.0 in /home/psakhamo/.venv/lib/python3.10/site-packages (0.23.1)\n",
      "Requirement already satisfied: SoundFile in /home/psakhamo/.venv/lib/python3.10/site-packages (0.12.1)\n",
      "Requirement already satisfied: filelock in /home/psakhamo/.venv/lib/python3.10/site-packages (from transformers>=4.30.0) (3.14.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/psakhamo/.venv/lib/python3.10/site-packages (from transformers>=4.30.0) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/psakhamo/.venv/lib/python3.10/site-packages (from transformers>=4.30.0) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/psakhamo/.venv/lib/python3.10/site-packages (from transformers>=4.30.0) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/psakhamo/.venv/lib/python3.10/site-packages (from transformers>=4.30.0) (2024.5.15)\n",
      "Requirement already satisfied: requests in /home/psakhamo/.venv/lib/python3.10/site-packages (from transformers>=4.30.0) (2.32.2)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /home/psakhamo/.venv/lib/python3.10/site-packages (from transformers>=4.30.0) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/psakhamo/.venv/lib/python3.10/site-packages (from transformers>=4.30.0) (0.4.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/psakhamo/.venv/lib/python3.10/site-packages (from transformers>=4.30.0) (4.66.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/psakhamo/.venv/lib/python3.10/site-packages (from huggingface_hub>=0.8.0) (2024.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/psakhamo/.venv/lib/python3.10/site-packages (from huggingface_hub>=0.8.0) (4.12.0)\n",
      "Requirement already satisfied: cffi>=1.0 in /home/psakhamo/.venv/lib/python3.10/site-packages (from SoundFile) (1.16.0)\n",
      "Requirement already satisfied: pycparser in /home/psakhamo/.venv/lib/python3.10/site-packages (from cffi>=1.0->SoundFile) (2.22)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/psakhamo/.venv/lib/python3.10/site-packages (from requests->transformers>=4.30.0) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/psakhamo/.venv/lib/python3.10/site-packages (from requests->transformers>=4.30.0) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/psakhamo/.venv/lib/python3.10/site-packages (from requests->transformers>=4.30.0) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/psakhamo/.venv/lib/python3.10/site-packages (from requests->transformers>=4.30.0) (2024.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install speechbrain\n",
    "%pip install \"torch>=1.9.0\" \"torchaudio>=1.9.0\" --index-url https://download.pytorch.org/whl/cpu\n",
    "%pip install \"transformers>=4.30.0\" \"huggingface_hub>=0.8.0\" \"SoundFile\"\n",
    "%pip install -q \"openvino>=2024.1.0\" \"nncf>=2.10.0\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports\n",
    "[back to top ⬆️](#Table-of-contents:)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "torchvision is not available - cannot save figures\n"
     ]
    }
   ],
   "source": [
    "import torch, torchaudio\n",
    "from speechbrain.inference.interfaces import foreign_class\n",
    "from speechbrain.inference.interfaces import Pretrained\n",
    "\n",
    "import openvino as ov\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare base model\n",
    "[back to top ⬆️](#Table-of-contents:)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/psakhamo/.venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53431609fede4ac6acfd271e49bae00c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.84k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/psakhamo/.venv/lib/python3.10/site-packages/transformers/configuration_utils.py:364: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8dd9aaa6269e44c880b7fd1d3e02c000",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/380M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fe77ae01539422d88083ec9a3e3350a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/159 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "classifier = foreign_class(\n",
    "    source=\"speechbrain/emotion-recognition-wav2vec2-IEMOCAP\",\n",
    "    pymodule_file=\"custom_interface.py\",\n",
    "    classname=\"CustomEncoderWav2vec2Classifier\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize model\n",
    "[back to top ⬆️](#Table-of-contents:)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wav2vec2 torch model\n",
    "torch_model = classifier.mods[\"wav2vec2\"].model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyTorch inference \n",
    "[back to top ⬆️](#Table-of-contents:)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emotion Recognition with SpeechBrain PyTorch model: ['ang']\n"
     ]
    }
   ],
   "source": [
    "out_prob, score, index, text_lab = classifier.classify_file(\"speechbrain/emotion-recognition-wav2vec2-IEMOCAP/anger.wav\")\n",
    "print(f\"Emotion Recognition with SpeechBrain PyTorch model: {text_lab}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SpeechBrain model optimization with Intel OpenVINO\n",
    "[back to top ⬆️](#Table-of-contents:)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Prepare input tensor\n",
    "[back to top ⬆️](#Table-of-contents:)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using sample audio file\n",
    "signals = []\n",
    "batch_size = 1\n",
    "signal, sr = torchaudio.load(str(\"./anger.wav\"), channels_first=False)\n",
    "norm_audio = classifier.audio_normalizer(signal, sr)\n",
    "signals.append(norm_audio)\n",
    "\n",
    "sequence_length = norm_audio.shape[-1]\n",
    "\n",
    "wavs = torch.stack(signals, dim=0)\n",
    "wav_len = torch.tensor([sequence_length] * batch_size).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Convert model to OpenVINO IR\n",
    "[back to top ⬆️](#Table-of-contents:)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/psakhamo/.venv/lib/python3.10/site-packages/transformers/modeling_utils.py:4481: FutureWarning: `_is_quantized_training_enabled` is going to be deprecated in transformers 4.39.0. Please use `model.hf_quantizer.is_trainable` instead\n",
      "  warnings.warn(\n",
      "/home/psakhamo/.venv/lib/python3.10/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py:968: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if attn_output.size() != (bsz, self.num_heads, tgt_len, self.head_dim):\n"
     ]
    }
   ],
   "source": [
    "# Model optimization process \n",
    "input_tensor = wavs.float()\n",
    "ov_model = ov.convert_model(torch_model, example_input=input_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: OpenVINO model inference\n",
    "[back to top ⬆️](#Table-of-contents:)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emotion Recognition with OpenVINO Model: ['ang']\n"
     ]
    }
   ],
   "source": [
    "# sample set of configuration parameters\n",
    "target_device = \"CPU\" #default\n",
    "opts = {\"device_name\": target_device, \"PERFORMANCE_HINT\":\"LATENCY\"}\n",
    "\n",
    "core = ov.Core()\n",
    "compiled_model = core.compile_model(ov_model, config=opts)\n",
    "output = compiled_model.outputs[0]\n",
    "\n",
    "# Perform model inference\n",
    "output_tensor = compiled_model(wavs)[output]\n",
    "output_tensor = torch.from_numpy(output_tensor)\n",
    "\n",
    "# output post-processing \n",
    "outputs = classifier.mods.avg_pool(output_tensor, wav_len)\n",
    "outputs = outputs.view(outputs.shape[0], -1)\n",
    "outputs = classifier.mods.output_mlp(outputs).squeeze(1)\n",
    "ov_out_prob = classifier.hparams.softmax(outputs)\n",
    "score, index = torch.max(ov_out_prob, dim=-1)\n",
    "text_lab = classifier.hparams.label_encoder.decode_torch(index)\n",
    "\n",
    "print(f\"Emotion Recognition with OpenVINO Model: {text_lab}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "openvino_notebooks": {
   "imageUrl": "...",
   "tags": {
    "categories": [
     "Optimize",
     "Model Demos",
     "AI Trends"
    ],
    "libraries": [],
    "tasks": [
     "Audio Classification"
    ]
   }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
