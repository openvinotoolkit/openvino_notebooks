{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Imports modules required to run"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "try:\n",
    "    import librosa\n",
    "except OSError:\n",
    "    import sys\n",
    "    import types\n",
    "    sys.modules['soundfile'] = types.ModuleType('fake_soundfile')\n",
    "    import librosa\n",
    "\n",
    "import numpy as np\n",
    "import scipy\n",
    "import wave\n",
    "from openvino.inference_engine import IECore\n",
    "from os import path, makedirs, listdir\n",
    "from shutil import copy"
   ],
   "outputs": [],
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Settings"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "ie = IECore()\n",
    "\n",
    "model_folder = \"model\"\n",
    "download_folder = \"output\"\n",
    "data_folder = \"data\"\n",
    "\n",
    "precision = \"FP16\"\n",
    "model_name = \"quartznet-15x5-en\"\n",
    "model_extensions = (\"bin\", \"xml\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Download models and convert public model\n",
    "\n",
    "If it is your first run models will download and convert here. It might take up to ten minutes. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "makedirs(model_folder, exist_ok=True)\n",
    "makedirs(download_folder, exist_ok=True)\n",
    "\n",
    "# Check if models are already downloaded in download directory\n",
    "try:\n",
    "    for extension in model_extensions:\n",
    "        if not path.isfile(f'{model_folder}/{model_name}.{extension}'):\n",
    "            raise FileNotFoundError\n",
    "except FileNotFoundError:\n",
    "    download_command = f\"omz_downloader --name {model_name} --output_dir {download_folder} --precision {precision} --num_attempts 3\"\n",
    "    convert_command = f\"omz_converter --name {model_name} --precisions {precision} --download_dir {download_folder} --output_dir {download_folder}\"\n",
    "    # Run commands, first download model than convert it to inferable \n",
    "    ! $download_command\n",
    "    print('Models downloded')\n",
    "    # Models are downloaded straight to output folder, we will keep all not used files outside of models directory\n",
    "    ! $convert_command\n",
    "    print('Model converted')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Copy models to model folder\n",
    "\n",
    "At this point both models are kept in download_folder (by default named 'output'). We need only .bin and .xml files from there that we will copy to model directory."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "for file_name in listdir(f\"{download_folder}/public/{model_name}/{precision}\"):\n",
    "    copy(src=f\"{download_folder}/public/{model_name}/{precision}/{file_name}\", dst=model_folder)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load an Image"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Create data folder\n",
    "makedirs(data_folder, exist_ok=True)\n",
    "audio_file_name = \"how_are_you_doing.wav\"\n",
    "alphabet = \" abcdefghijklmnopqrstuvwxyz'\"\n",
    "\n",
    "# Example of usage\n",
    "wave_read = wave.open(f'{data_folder}/{audio_file_name}')\n",
    "channel_num, sample_width, sampling_rate, pcm_length, compression_type, _ = wave_read.getparams()"
   ],
   "outputs": [],
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "assert sample_width == 2, \"Only 16-bit WAV PCM supported\"\n",
    "assert compression_type == 'NONE', \"Only linear PCM WAV files supported\"\n",
    "assert channel_num == 1, \"Only mono WAV PCM supported\"\n",
    "assert sampling_rate == 16000, \"Only 16 KHz audio supported\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "audio = wave_read.readframes(pcm_length * channel_num)\n",
    "audio = np.frombuffer(audio, dtype=np.int16)\n",
    "audio = audio.reshape((pcm_length, channel_num))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def audio_to_melspectrum(audio, sampling_rate, padding=16):\n",
    "        assert sampling_rate == 16000, \"Only 16 KHz audio supported\"\n",
    "        preemph = 0.97\n",
    "        preemphased = np.concatenate([audio[:1], audio[1:] - preemph * audio[:-1].astype(np.float32)])\n",
    "\n",
    "        win_length = round(sampling_rate * 0.02)\n",
    "        spec = np.abs(librosa.core.spectrum.stft(preemphased, n_fft=512, hop_length=round(sampling_rate * 0.01),\n",
    "            win_length=win_length, center=True, window=scipy.signal.windows.hann(win_length), pad_mode='reflect'))\n",
    "        mel_basis = librosa.filters.mel(sampling_rate, 512, n_mels=64, fmin=0.0, fmax=8000.0, htk=False)\n",
    "        log_melspectrum = np.log(np.dot(mel_basis, np.power(spec, 2)) + 2 ** -24)\n",
    "\n",
    "        normalized = (log_melspectrum - log_melspectrum.mean(1)[:, None]) / (log_melspectrum.std(1)[:, None] + 1e-5)\n",
    "        remainder = normalized.shape[1] % padding\n",
    "        if remainder != 0:\n",
    "            return np.pad(normalized, ((0, 0), (0, padding - remainder)))[None]\n",
    "        return normalized[None]\n",
    "\n",
    "def ctc_greedy_decode(pred):\n",
    "    pred = np.squeeze(pred)\n",
    "    prev_id = blank_id = len(alphabet)\n",
    "    transcription = []\n",
    "    for idx in pred.argmax(axis=1):\n",
    "        if prev_id != idx != blank_id:\n",
    "            transcription.append(alphabet[idx])\n",
    "        prev_id = idx\n",
    "    return ''.join(transcription)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "audio = audio_to_melspectrum(audio.flatten(), sampling_rate)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "net = ie.read_network(\n",
    "    model=f\"{model_folder}/{model_name}.xml\"\n",
    ")\n",
    "net.reshape({next(iter(net.input_info)): audio.shape})\n",
    "exec_net = ie.load_network(net, \"CPU\")\n",
    "\n",
    "input_layer_ir = next(iter(exec_net.input_info))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "character_probs = exec_net.infer({input_layer_ir: audio}).values()\n",
    "\n",
    "character_probs = next(iter(character_probs))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "transcription = ctc_greedy_decode(character_probs)\n",
    "print(transcription)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
  "metadata": {
  "kernelspec": {
   "display_name": "openvino_env",
   "language": "python",
   "name": "openvino_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
