{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resnet-18 QAT TIMM\n",
    "\n",
    "This notebook demonstrates on how to use a pretrained Resnet18 model available from the pytorch-image-model package, retraining the network for cats and dog dataset, and use quantization aware training to quantatize the model and later compiling it to the Open Vino IR format to be used for inference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import torch.optim as optim\n",
    "import nncf\n",
    "from nncf.torch import create_compressed_model, register_default_init_args\n",
    "import timm\n",
    "from nncf import NNCFConfig\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "from openvino.runtime import Core\n",
    "import cv2\n",
    "from cat_dog import Custom_dataset\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset and Dataloader\n",
    "\n",
    "Create a train_set and a test and load the data to pytorch Dataloader which will be used for training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Custom_dataset('train.csv','dataset/training_set',transform=transforms.ToTensor())\n",
    "test_set = Custom_dataset('test.csv','dataset/test_set',transform=transforms.ToTensor())\n",
    "trainloader = DataLoader(train_dataset,batch_size=64,shuffle=True,num_workers=8)\n",
    "test_loader = DataLoader(train_dataset,batch_size=64,shuffle=False,num_workers=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Resnet18 model on custom dataset\n",
    "The training and testing part of the model have been implemented in the function given below for ease of use. The model will be trained on the cats and dogs dataset which consist of 2 classes and 8000 images for training and 2000 images for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer,loss_fn,epoch):\n",
    "    '''\n",
    "    train the model\n",
    "    '''\n",
    "    model.train()\n",
    "    counter = 0\n",
    "    correct = 0\n",
    "    print(\"Epoch \"+str(epoch))\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = loss_fn(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        pred = output.argmax(dim=1,keepdim=False)\n",
    "        correct += (pred == target).sum().item()\n",
    "        counter += target.size(0)\n",
    "    print(\"Accuracy after epoch %s is %s \"%(epoch,100*correct/len(train_loader.dataset)))\n",
    "\n",
    "def test(model, device, test_loader):\n",
    "    '''\n",
    "    test the model\n",
    "    '''\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    acc = 100. * correct / len(test_loader.dataset)\n",
    "    print('\\nTest set: Accuracy: {}/{} ({:.2f}%)\\n'.format(correct, len(test_loader.dataset), acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting the Pre-trained Resnet18 model from TIMM\n",
    "\n",
    "To train the model on the custom dataset and later use it for QAT, we need to use a pretrained Resnet18 model. We obatin one from the Pytorch Image Model. We fine tune it to our datset by running it for 3 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = timm.create_model('resnet18',pretrained=True)\n",
    "# Changing the final layer of the model for our custom class\n",
    "model.fc = nn.Linear(512,2)\n",
    "# Model is transfered to the GPU for faster training\n",
    "model = model.to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
    "loss = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the model for 3 epochs as it is observed that is fine tuned quickly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 3\n",
    "for epoch in range(epochs):\n",
    "    train(model,device,trainloader,optimizer,loss,epoch)\n",
    "    test(model,device,test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The pytorch weights have been saved inside the model folder\n",
    "PATH = 'model/resnet_18_cat_dog.pth'\n",
    "torch.save(model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The FP32 pytorch model weights has been converted to ONNX format which will later be used to convert to OPENVINO IR format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_input = torch.randn(1, 3, 224, 224).to(device)\n",
    "\n",
    "torch.onnx.export(model, dummy_input, 'model/fp32/resnet_18_cat_dog.onnx')\n",
    "print(f\"FP32 ONNX model was exported to model folder.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nncf_config_dict = {\n",
    "    \"input_info\": {\n",
    "      \"sample_size\": [1, 3, 224, 224]\n",
    "    },\n",
    "    \"compression\": {\n",
    "        \"algorithm\": \"quantization\", \n",
    "    }\n",
    "}\n",
    "\n",
    "nncf_config = NNCFConfig.from_dict(nncf_config_dict)\n",
    "# Provide data loaders for compression algorithm initialization, if necessary\n",
    "nncf_config = register_default_init_args(nncf_config, trainloader)\n",
    "# Apply the specified compression algorithms to the model\n",
    "compression_ctrl, model = create_compressed_model(model, nncf_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We test the quantized model on the test set\n",
    "acc1 = test(model, device, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We finetune it for 1 epoch\n",
    "epochs = 1\n",
    "for epoch in range(epochs):\n",
    "    train(model,device,trainloader,optimizer,loss,epoch)\n",
    "    test(model,device,test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then export our finetuned int8 model to ONNX format via the export_model function of compression_ctrl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_8_path = 'model/resnet_18_cat_dog_int_8.onnx'\n",
    "compression_ctrl.export_model(int_8_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then convert the FP32 and INT8 ONNX model to OpenVINO IR format which will later be used for benchmark usage.\n",
    "We specify the input_model path via the --input_model and the output_dir where the model will be saved via the --output_dir. We also specify the input image dimension to the model via the --input_shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mo --input_model model/fp32/resnet_18_cat_dog.onnx --input_shape \"[1,3, 224, 224]\"  --data_type FP16 --output_dir model/fp32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mo --input_model model/int8/resnet_18_cat_dog_int_8.onnx --input_shape \"[1,3, 224, 224]\"  --data_type FP16 --output_dir model/int8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmarking FP32 vs INT8 model\n",
    "\n",
    "We will now start benchmarking the FP32 model vs the INT8 model. We will do it via comparing the time taken for both the models to go through the entire test_set which consist of 1000 images. We also print frames-per-second achived from both the models. A benchmark function has been created which takes in the input image, passed it onto the model and gives us the output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ie = Core()\n",
    "model = ie.read_model(model=\"model/fp32/resnet_18_cat_dog.xml\")\n",
    "\n",
    "# To test the INT8 model, simply comment the model variable above and uncomment the variable below\n",
    "\n",
    "# model = ie.read_model(model=\"model/int8/resnet_18_cat_dog_int_8.xml\")\n",
    "compiled_model = ie.compile_model(model=model, device_name=\"CPU\")\n",
    "\n",
    "output_layer = compiled_model.output(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing the input image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(image):\n",
    "    img = cv2.cvtColor(cv2.imread(filename=image), code=cv2.COLOR_BGR2RGB)\n",
    "    input_image = cv2.resize(src=img, dsize=(224, 224),interpolation = cv2.INTER_LINEAR)\n",
    "    input_image = np.expand_dims(input_image.transpose(2, 0, 1), 0)\n",
    "    input_image = input_image/255\n",
    "    return input_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmark function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark(model,output_layer):\n",
    "    img_dir = os.listdir('dataset/test_set')\n",
    "    img_dir.sort()\n",
    "    prediction_class = ('cat','dog')\n",
    "\n",
    "    \n",
    "    for i in os.listdir('dataset/test_set'):\n",
    "        filename = 'dataset/test_set/'+ i\n",
    "        img = preprocess(filename)\n",
    "        output = model([img])[output_layer]\n",
    "        result_index = np.argmax(output)\n",
    "        print('filename = %s and prediction = %s '%(i,prediction_class[result_index]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate the time taken and FPS obatained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dir  = os.listdir('dataset/training_set')\n",
    "start = time.time()\n",
    "test_go = benchmark(compiled_model,output_layer)\n",
    "end = time.time()\n",
    "total_time = end-start\n",
    "print('time taken = %s and FPS = %s '%(total_time,len(img_dir)/total_time))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "201b1d8849bf6c53c6b9fb185096d6526d98506cbb387347941199a972780f30"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
