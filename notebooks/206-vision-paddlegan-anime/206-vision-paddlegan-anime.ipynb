{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7607ce35-db52-4e1c-add7-8abed748de6a",
   "metadata": {},
   "source": [
    "# Photo to Anime with PaddleGAN and OpenVINO\n",
    "\n",
    "This notebook demonstrates converting a [PaddlePaddle/PaddleGAN](https://github.com/PaddlePaddle/PaddleGAN) AnimeGAN model to OpenVINO IR format, and shows inference results on the PaddleGAN and IR models.\n",
    "\n",
    "https://github.com/PaddlePaddle/PaddleGAN/blob/develop/docs/en_US/tutorials/animegan.md"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a9e69d-27cc-421a-b526-7cc31cbb06bd",
   "metadata": {},
   "source": [
    "## Preparation\n",
    "\n",
    "PaddleGAN requires installation of `paddlepaddle`, `ppgan` and `paddle2onnx`. These packages are not installed by the default OpenVINO Notebooks requirements. Running the cell below checks if the PaddleGAN packages are installed, and installs them if necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed38a3ce-b123-46ef-812c-85c8f6abb45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "installed = !pip show paddle2onnx ppgan paddlepaddle\n",
    "if \"WARNING\" in installed.get_nlstr():\n",
    "    !pip install --upgrade paddle2onnx ppgan paddlepaddle\n",
    "else:\n",
    "    print(\"The PaddleGAN requirements are installed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21719447-f2d9-48d6-bf9a-4a5fb9f5a12a",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41056f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import mo_onnx\n",
    "import numpy as np\n",
    "import paddle\n",
    "from openvino.inference_engine import IECore\n",
    "from paddle.static import InputSpec\n",
    "from ppgan.apps import AnimeGANPredictor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8aaf4da-a840-4c07-bd4c-b703fa5c58fa",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764178fb-c9b2-4005-8dc8-84018b12c439",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The filenames of the downloaded and converted models\n",
    "MODEL_NAME = \"paddlegen_anime\"\n",
    "\n",
    "model_path = Path(MODEL_NAME)\n",
    "ir_path = model_path.with_suffix(\".xml\")\n",
    "onnx_path = model_path.with_suffix(\".onnx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad5fe05",
   "metadata": {},
   "source": [
    "## Inference on Paddle Model\n",
    "\n",
    "The PaddleGAN [documentation](https://github.com/PaddlePaddle/PaddleGAN/blob/develop/docs/en_US/tutorials/animegan.md) explains to run the model with `.run()`. Let's see what that function does, and check other relevant functions that are called from that function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151fd351",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = AnimeGANPredictor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1e7c30-18c8-48f3-b889-9f8cfe06159c",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.run??"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb85af2-148f-4974-82e8-049b4e74d9a1",
   "metadata": {},
   "source": [
    "The function:\n",
    "\n",
    "1. loads an image with OpenCV and converts it to RGB\n",
    "2. transforms the image \n",
    "3. propagates the transformed image through the generator model and postprocesses the results to return an array with a [0,255] range\n",
    "4. transposes the result from (C,H,W) to (H,W,C) shape\n",
    "5. resizes the result image to the original image size\n",
    "6. optionally adjusts the brightness of the result image\n",
    "7. saves the image\n",
    "\n",
    "We can execute these steps manually and confirm that the result looks correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07798dbb-28e1-4511-81f9-17fc6f440692",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1. Load the image and convert to RGB\n",
    "image_path = Path(\"coco_bike.jpg\")\n",
    "\n",
    "image = cv2.cvtColor(\n",
    "    cv2.imread(str(image_path), flags=cv2.IMREAD_COLOR), cv2.COLOR_BGR2RGB\n",
    ")\n",
    "\n",
    "# Step 2. Transform the image\n",
    "transformed_image = predictor.transform(image)\n",
    "input_tensor = paddle.to_tensor(transformed_image[None, ::])\n",
    "\n",
    "# Step 3. Do inference. Setting the model to `.eval()` and using `.no_grad()`\n",
    "predictor.generator.eval()\n",
    "with paddle.no_grad():\n",
    "    result = predictor.generator(input_tensor)\n",
    "\n",
    "# Step 4. Convert the inference result to an image and transpose to image shape\n",
    "result_image_pg = (result * 0.5 + 0.5)[0].numpy() * 255\n",
    "result_image_pg = result_image_pg.transpose((1, 2, 0))\n",
    "\n",
    "# Step 5. Resize the result image\n",
    "result_image_pg = cv2.resize(result_image_pg, image.shape[:2][::-1])\n",
    "\n",
    "# Step 6. Adjust the brightness\n",
    "result_image_pg = predictor.adjust_brightness(result_image_pg, image)\n",
    "\n",
    "# Step 7. Save the result image\n",
    "anime_image_path_pg = image_path.with_name(\n",
    "    image_path.stem + \"_anime_pg\"\n",
    ").with_suffix(\".jpg\")\n",
    "if cv2.imwrite(str(anime_image_path_pg), result_image_pg[:, :, (2, 1, 0)]):\n",
    "    print(f\"The anime image was saved to {anime_image_path_pg}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b97f27-ab08-4584-8194-190ff90159ed",
   "metadata": {},
   "source": [
    "### Show Inference Results on PaddleGAN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89eda041-cde2-4eeb-b4ae-4624f3f49175",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(25, 15))\n",
    "ax[0].imshow(image)\n",
    "ax[1].imshow(result_image_pg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2446c4e-adce-44ab-8f67-6d5aed988803",
   "metadata": {},
   "source": [
    "## Model Conversion to ONNX and IR\n",
    "\n",
    "We convert the PaddleGAN model to OpenVINO IR by first converting PaddleGAN to ONNX with `paddle2onnx` and then converting the ONNX model to IR with OpenVINO's Model Optimizer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb6be9f",
   "metadata": {},
   "source": [
    "### Convert to ONNX\n",
    "\n",
    "Exporting to ONNX requires specifying an input shape with PaddlePaddle's `InputSpec` and calling `paddle.onnx.export`. We check the input shape of the transformed image and use that as input shape for the ONNX model. Exporting to ONNX should not take long. If exporting succeeded, the output of the next cell will include `ONNX model saved in paddlegan_anime.onnx`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926ca201-392b-4f19-9c9f-2de766378f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6735bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.generator.eval()\n",
    "x_spec = InputSpec([None, 3, 576, 800], \"float32\", \"x\")\n",
    "paddle.onnx.export(\n",
    "    predictor.generator, str(model_path), input_spec=[x_spec], opset_version=11\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f8c13a",
   "metadata": {},
   "source": [
    "### Convert to IR\n",
    "\n",
    "The OpenVINO IR format allows storing the preprocessing normalization in the model file. It is then no longer necessary to normalize input images manually. Let's check the transforms that the `.run()` function used:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35a7570-6b66-48cb-ac41-d4e7887cccd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.__init__??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51965742-8aad-4f44-beea-3f4d5a73fccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = predictor.transform.transforms[0]\n",
    "t.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1aef64-9bfe-4c5c-82ea-3f0399b5791a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Uncomment the line below to see the documentation and code of the ResizeToScale function\n",
    "# t??"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03050508-a108-47fd-a95b-7a9f9e6c84a0",
   "metadata": {},
   "source": [
    "There are three transforms: resize, transpose, and normalize, where normalize uses a mean and scale of [127.5,127.5,127.5]. \n",
    "\n",
    "The ResizeToScale function is called with (256,256) as argument for size. Further inspection of the function shows that this is\n",
    "the minimum size to resize to. By default, the ResizeToScale transform resizes images to 800x576.\n",
    "\n",
    "Now that we know the mean and standard deviation values, and the shape of the model, we can call Model Optimizer and convert the model to IR with these values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae08c137-aeda-432a-839c-91c56264e8e7",
   "metadata": {},
   "source": [
    "**Convert Model to IR with Model Optimizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca6c5101-d33c-4105-ae45-5a4251431473",
   "metadata": {},
   "outputs": [],
   "source": [
    "mo = mo_onnx.__file__\n",
    "python = sys.executable\n",
    "onnx_path = model_path.with_suffix(\".onnx\")\n",
    "print(\"Exporting ONNX model to IR... This may take a few minutes.\")\n",
    "! $python $mo --input_model $onnx_path --input_shape \"[1,3,576,800]\" --model_name $MODEL_NAME --data_type \"FP16\" --mean_values=\"[127.5,127.5,127.5]\" --scale_values=\"[127.5,127.5,127.5]\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8dd16dd-7c6e-4f92-847a-d7d759292c9d",
   "metadata": {},
   "source": [
    "## Show Inference Results on IR and PaddleGAN model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c7dbcf-a433-4db9-9b28-075274f9b629",
   "metadata": {},
   "source": [
    "If the Model Optimizer output in the cell above showed _SUCCESS_, model conversion succeeded and the IR model is generated. \n",
    "\n",
    "We can use the model for inference now with the `adjust_brightness()` method from the PaddleGAN model, but in order to use the IR model without installing PaddleGAN, it is useful to check what these functions do and extract them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6297ec13-ed12-4a0c-b362-45d7f0a3ab12",
   "metadata": {},
   "source": [
    "### Create Postprocessing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9dddaa-09bc-4ae1-bf01-05d9b73fe676",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.adjust_brightness??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ad69f2-773c-41f8-b5b2-175b9a24d7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.calc_avg_brightness??"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de60ff1-7391-4c1f-b4b3-27abc3c49e35",
   "metadata": {},
   "source": [
    "The average brightness is computed by a standard formula, see https://www.w3.org/TR/AERT/#color-contrast. To adjust the brightness, the difference in brightness between the source and destination (anime) image is computed and the brightness of the destination image is  adjusted based on that. The image is then converted to an 8-bit image.\n",
    "\n",
    "We copy these functions to the next cell, and will use them for inference on the IR model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b77c029-1112-4ad6-903a-141242def5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (c) 2020 PaddlePaddle Authors. Licensed under the Apache License, Version 2.0\n",
    "\n",
    "\n",
    "def calc_avg_brightness(img):\n",
    "    R = img[..., 0].mean()\n",
    "    G = img[..., 1].mean()\n",
    "    B = img[..., 2].mean()\n",
    "\n",
    "    brightness = 0.299 * R + 0.587 * G + 0.114 * B\n",
    "    return brightness, B, G, R\n",
    "\n",
    "\n",
    "def adjust_brightness(dst, src):\n",
    "    brightness1, B1, G1, R1 = AnimeGANPredictor.calc_avg_brightness(src)\n",
    "    brightness2, B2, G2, R2 = AnimeGANPredictor.calc_avg_brightness(dst)\n",
    "    brightness_difference = brightness1 / brightness2\n",
    "    dstf = dst * brightness_difference\n",
    "    dstf = np.clip(dstf, 0, 255)\n",
    "    dstf = np.uint8(dstf)\n",
    "    return dstf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74bce1ee-f070-42b9-b92f-95e37b82ea02",
   "metadata": {},
   "source": [
    "### Do Inference on IR Model\n",
    "\n",
    "Load the IR model, and do inference, following the same steps as for the PaddleGAN model. See the [OpenVINO Inference Engine API notebook](../002-openvino-api/002-openvino-api.ipynb) for more information about inference on IR models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0f83cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and prepare the IR model.\n",
    "ie = IECore()\n",
    "net = ie.read_network(ir_path)\n",
    "exec_net = ie.load_network(net, \"CPU\")\n",
    "input_key = next(iter(net.input_info.keys()))\n",
    "output_key = next(iter(net.outputs.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc56b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1. Load the image and convert to RGB\n",
    "\n",
    "image = cv2.cvtColor(\n",
    "    cv2.imread(str(image_path), flags=cv2.IMREAD_COLOR), cv2.COLOR_BGR2RGB\n",
    ")\n",
    "\n",
    "# Step 2. Transform the image (only resize and transpose are still required)\n",
    "resized_image = cv2.resize(image, (800, 576))\n",
    "input_image = resized_image.transpose(2, 0, 1)[None, :, :, :]\n",
    "\n",
    "# Step 3. Do inference.\n",
    "result_ir = exec_net.infer({input_key: input_image})\n",
    "\n",
    "# Step 4. Convert the inference result to an image and transpose to image shape\n",
    "result_image_ir = (result_ir[output_key] * 0.5 + 0.5)[0] * 255\n",
    "result_image_ir = result_image_ir.transpose((1, 2, 0))\n",
    "\n",
    "# Step 5. Resize the result image\n",
    "result_image_ir = cv2.resize(result_image_ir, image.shape[:2][::-1])\n",
    "\n",
    "# Step 6. Adjust the brightness\n",
    "result_image_ir = adjust_brightness(result_image_ir, image)\n",
    "\n",
    "# Step 7. Save the result image\n",
    "anime_fn_ir = image_path.with_name(image_path.stem + \"_anime_ir\").with_suffix(\n",
    "    \".jpg\"\n",
    ")\n",
    "if cv2.imwrite(str(anime_fn_ir), result_image_ir[:, :, (2, 1, 0)]):\n",
    "    print(f\"The anime image was saved to {anime_fn_ir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d62495d-cb89-44f1-9e43-d946fb1a27d3",
   "metadata": {},
   "source": [
    "**Show inference results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc44b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 3, figsize=(25, 15))\n",
    "ax[0].imshow(image)\n",
    "ax[1].imshow(result_image_pg)\n",
    "ax[2].imshow(result_image_ir)\n",
    "ax[0].set_title(\"Image\")\n",
    "ax[1].set_title(\"PaddleGAN result\")\n",
    "ax[2].set_title(\"OpenVINO IR result\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "063ce658-b757-45da-9c7d-929b4be89e43",
   "metadata": {},
   "source": [
    "## Performance Comparison\n",
    "\n",
    "Measure the time it takes to do inference on an image. This gives an indication of performance. For more accurate benchmarking, use the [OpenVINO benchmark tool](https://github.com/openvinotoolkit/openvino/tree/master/inference-engine/tools/benchmark_tool)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5172a4a-f6ef-4142-8917-6c877706b8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.perf_counter()\n",
    "exec_net.infer(inputs={input_key: input_image})\n",
    "end = time.perf_counter()\n",
    "time_ir = end - start\n",
    "print(\n",
    "    f\"IR model in Inference Engine/CPU: {time_ir:.3f} \"\n",
    "    f\"seconds per image, FPS: {1/time_ir:.2f}\"\n",
    ")\n",
    "\n",
    "with paddle.no_grad():\n",
    "    start = time.perf_counter()\n",
    "    predictor.generator(input_tensor)\n",
    "    end = time.perf_counter()\n",
    "    time_torch = end - start\n",
    "print(\n",
    "    f\"PaddleGAN model on CPU: {time_torch:.3f} seconds per image, \"\n",
    "    f\"FPS: {1/time_torch:.2f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46078510-e54d-448c-9166-31c1bf2e6598",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "* PaddleGAN: https://github.com/PaddlePaddle/PaddleGAN\n",
    "* Paddle2ONNX: https://github.com/PaddlePaddle/paddle2onnx\n",
    "* OpenVINO ONNX support: https://docs.openvinotoolkit.org/latest/openvino_docs_IE_DG_ONNX_Support.html\n",
    "* OpenVINO Model Optimizer Documentation: https://docs.openvinotoolkit.org/latest/openvino_docs_MO_DG_prepare_model_convert_model_Converting_Model_General.html\n",
    "\n",
    "The PaddleGAN code that is shown in this notebook is written by PaddlePaddle Authors and licensed under the Apache 2.0 license. \n",
    "The license for this code is displayed below.\n",
    "\n",
    "    #  Copyright (c) 2020 PaddlePaddle Authors. All Rights Reserve.\n",
    "    #\n",
    "    #Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "    #you may not use this file except in compliance with the License.\n",
    "    #You may obtain a copy of the License at\n",
    "    #\n",
    "    #    http://www.apache.org/licenses/LICENSE-2.0\n",
    "    #\n",
    "    #Unless required by applicable law or agreed to in writing, software\n",
    "    #distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "    #WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "    #See the License for the specific language governing permissions and\n",
    "    #limitations under the License."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad471d6a-873d-41de-8baa-e78a61aae1ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openvino_env",
   "language": "python",
   "name": "openvino_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
