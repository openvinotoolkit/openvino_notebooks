{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f855a151",
   "metadata": {},
   "source": [
    "# Quantization Aware Training with NNCF, using TensorFlow Framework\n",
    "\n",
    "The goal of this notebook to demonstrate how to use the Neural Network Compression Framework [NNCF](https://github.com/openvinotoolkit/nncf) 8-bit quantization to optimize a TensorFlow model for inference with OpenVINO Toolkit. The optimization process contains the following steps:\n",
    "* Transform the original FP32 model to INT8\n",
    "* Use fine-tuning to restore the accuracy\n",
    "* Export optimized and original models to Frozen Graph and then to OpenVINO\n",
    "* Measure and compare the performance of models\n",
    "\n",
    "For more advanced usage, please refer to these [examples](https://github.com/openvinotoolkit/nncf/tree/develop/examples).\n",
    "\n",
    "We selected the ResNet-18 model with Imagenette dataset. Imagenette is a subset of 10 easily classified classes from the Imagenet dataset. Using the smaller model and dataset will speed up training and download time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddd1b744",
   "metadata": {},
   "source": [
    "## Imports and Settings\n",
    "Import NNCF and all auxiliary packages from your Python code.\n",
    "Set a name for the model, input image size, used batch size, and the learning rate. Also define paths where Frozen Graph and OpenVINO IR versions of the models will be stored.\n",
    "\n",
    "> NOTE: All NNCF logging messages below ERROR level (INFO and WARNING) are disabled to simplify the tutorial. For production use, it is recommended to enable logging, by removing ```set_log_level(logging.ERROR)```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1e95247",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:nncf:Skip applying a patch to building extension with a reason: PyTorch version is not supported for this\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error building extension 'quantized_functions_cpu': [1/1] \"C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Professional\\VC\\Tools\\MSVC\\14.29.30037\\bin\\Hostx64\\x64/link.exe\" functions_cpu.o tensor_funcs.o /nologo /DLL c10.lib torch_cpu.lib torch.lib torch_python.lib /LIBPATH:c:\\Users\\jakubdeb\\repos\\openvino_notebooks\\venv_39_1701\\Scripts\\libs /LIBPATH:c:\\Users\\jakubdeb\\repos\\openvino_notebooks\\venv_39_1701\\lib\\site-packages\\torch\\lib /out:quantized_functions_cpu.pyd\r\nFAILED: quantized_functions_cpu.pyd \r\n\"C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Professional\\VC\\Tools\\MSVC\\14.29.30037\\bin\\Hostx64\\x64/link.exe\" functions_cpu.o tensor_funcs.o /nologo /DLL c10.lib torch_cpu.lib torch.lib torch_python.lib /LIBPATH:c:\\Users\\jakubdeb\\repos\\openvino_notebooks\\venv_39_1701\\Scripts\\libs /LIBPATH:c:\\Users\\jakubdeb\\repos\\openvino_notebooks\\venv_39_1701\\lib\\site-packages\\torch\\lib /out:quantized_functions_cpu.pyd\r\nLINK : fatal error LNK1104: cannot open file 'python39.lib'\r\nninja: build stopped: subcommand failed.\r\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\jakubdeb\\repos\\openvino_notebooks\\venv_39_1701\\lib\\site-packages\\torch\\utils\\cpp_extension.py\u001b[0m in \u001b[0;36m_run_ninja_build\u001b[1;34m(build_directory, verbose, error_prefix)\u001b[0m\n\u001b[0;32m   1532\u001b[0m             \u001b[0mstdout_fileno\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1533\u001b[1;33m             subprocess.run(\n\u001b[0m\u001b[0;32m   1534\u001b[0m                 \u001b[0mcommand\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\subprocess.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[0;32m    527\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcheck\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mretcode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 528\u001b[1;33m             raise CalledProcessError(retcode, process.args,\n\u001b[0m\u001b[0;32m    529\u001b[0m                                      output=stdout, stderr=stderr)\n",
      "\u001b[1;31mCalledProcessError\u001b[0m: Command '['ninja', '-v']' returned non-zero exit status 1.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-419fd047ea5d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mnncf\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mNNCFConfig\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mnncf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_creation\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcreate_compressed_model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mnncf\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mregister_default_init_args\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jakubdeb\\repos\\openvino_notebooks\\venv_39_1701\\lib\\site-packages\\nncf\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[1;31m# Required for correct COMPRESSION_ALGORITHMS registry functioning\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mbinarization\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0malgo\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mbinarization_algo\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mquantization\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0malgo\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mquantization_algo\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0msparsity\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconst\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0malgo\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mconst_sparsity_algo\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jakubdeb\\repos\\openvino_notebooks\\venv_39_1701\\lib\\site-packages\\nncf\\binarization\\algo.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mnncf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malgo_selector\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mCOMPRESSION_ALGORITHMS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mZeroCompressionLoss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mnncf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompression\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mCompressionLevel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mnncf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompression\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mCompressionLoss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jakubdeb\\repos\\openvino_notebooks\\venv_39_1701\\lib\\site-packages\\nncf\\algo_selector.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mnncf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransformations\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayout\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPTTransformationLayout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mnncf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnncf_network\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mNNCFNetwork\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mnncf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompression\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mCompressionLevel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jakubdeb\\repos\\openvino_notebooks\\venv_39_1701\\lib\\site-packages\\nncf\\nncf_network.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mnncf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransformations\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommands\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPTInsertionCommand\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mnncf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransformations\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommands\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPTTargetPoint\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mnncf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhw_config\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mHWConfig\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mnncf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mNNCF_MODULES\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mnncf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mNNCF_WRAPPED_USER_MODULES_DICT\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jakubdeb\\repos\\openvino_notebooks\\venv_39_1701\\lib\\site-packages\\nncf\\hw_config.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mnncf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moperator_metatypes\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mOPERATOR_METATYPES\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mnncf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhw_config_op_names\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mHWConfigOpName\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mnncf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mquantization\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mAsymmetricQuantizer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mnncf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mquantization\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mQuantizationMode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mnncf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mquantization\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mQuantizerConfig\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jakubdeb\\repos\\openvino_notebooks\\venv_39_1701\\lib\\site-packages\\nncf\\quantization\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \"\"\"\n\u001b[0;32m     13\u001b[0m \u001b[1;31m# Required for correct QUANTIZATION_MODULES registry functioning\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlayers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\jakubdeb\\repos\\openvino_notebooks\\venv_39_1701\\lib\\site-packages\\nncf\\quantization\\layers.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mnncf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommon\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogger\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlogger\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnncf_logger\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mnncf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommon\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mquantization\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstructs\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mQuantizationMode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mQuantizerConfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mQuantizerSpec\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mnncf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mquantization\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mquantize_functions\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msymmetric_quantize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0masymmetric_quantize\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m     \u001b[0mExportQuantizeToFakeQuantize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mget_scale_zp_from_input_low_input_high\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mExportQuantizeToONNXQuantDequant\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTuneRange\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mnncf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer_utils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mCOMPRESSION_MODULES\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jakubdeb\\repos\\openvino_notebooks\\venv_39_1701\\lib\\site-packages\\nncf\\quantization\\quantize_functions.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mnncf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0madd_domain\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mextensions\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mQuantizedFunctionsCPU\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mQuantizedFunctionsCUDA\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdynamic_graph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpatch_pytorch\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mregister_operator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunctions\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSTRound\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclamp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jakubdeb\\repos\\openvino_notebooks\\venv_39_1701\\lib\\site-packages\\nncf\\quantization\\extensions.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 62\u001b[1;33m \u001b[0mQuantizedFunctionsCPU\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mQuantizedFunctionsCPULoader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jakubdeb\\repos\\openvino_notebooks\\venv_39_1701\\lib\\site-packages\\nncf\\quantization\\extensions.py\u001b[0m in \u001b[0;36mload\u001b[1;34m()\u001b[0m\n\u001b[0;32m     44\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m         return load('quantized_functions_cpu', CPU_EXT_SRC_LIST, extra_include_paths=EXT_INCLUDE_DIRS,\n\u001b[0m\u001b[0;32m     47\u001b[0m                     verbose=False)\n\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jakubdeb\\repos\\openvino_notebooks\\venv_39_1701\\lib\\site-packages\\torch\\utils\\cpp_extension.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(name, sources, extra_cflags, extra_cuda_cflags, extra_ldflags, extra_include_paths, build_directory, verbose, with_cuda, is_python_module, keep_intermediates)\u001b[0m\n\u001b[0;32m    984\u001b[0m                 verbose=True)\n\u001b[0;32m    985\u001b[0m     '''\n\u001b[1;32m--> 986\u001b[1;33m     return _jit_compile(\n\u001b[0m\u001b[0;32m    987\u001b[0m         \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    988\u001b[0m         \u001b[1;33m[\u001b[0m\u001b[0msources\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msources\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0msources\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jakubdeb\\repos\\openvino_notebooks\\venv_39_1701\\lib\\site-packages\\torch\\utils\\cpp_extension.py\u001b[0m in \u001b[0;36m_jit_compile\u001b[1;34m(name, sources, extra_cflags, extra_cuda_cflags, extra_ldflags, extra_include_paths, build_directory, verbose, with_cuda, is_python_module, keep_intermediates)\u001b[0m\n\u001b[0;32m   1191\u001b[0m                             \u001b[0mclean_ctx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclean_ctx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1192\u001b[0m                         )\n\u001b[1;32m-> 1193\u001b[1;33m                     _write_ninja_file_and_build_library(\n\u001b[0m\u001b[0;32m   1194\u001b[0m                         \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1195\u001b[0m                         \u001b[0msources\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msources\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jakubdeb\\repos\\openvino_notebooks\\venv_39_1701\\lib\\site-packages\\torch\\utils\\cpp_extension.py\u001b[0m in \u001b[0;36m_write_ninja_file_and_build_library\u001b[1;34m(name, sources, extra_cflags, extra_cuda_cflags, extra_ldflags, extra_include_paths, build_directory, verbose, with_cuda)\u001b[0m\n\u001b[0;32m   1295\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1296\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Building extension module {}...'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1297\u001b[1;33m     _run_ninja_build(\n\u001b[0m\u001b[0;32m   1298\u001b[0m         \u001b[0mbuild_directory\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1299\u001b[0m         \u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jakubdeb\\repos\\openvino_notebooks\\venv_39_1701\\lib\\site-packages\\torch\\utils\\cpp_extension.py\u001b[0m in \u001b[0;36m_run_ninja_build\u001b[1;34m(build_directory, verbose, error_prefix)\u001b[0m\n\u001b[0;32m   1553\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'output'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0merror\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# type: ignore\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1554\u001b[0m             \u001b[0mmessage\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;34m\": {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1555\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1556\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Error building extension 'quantized_functions_cpu': [1/1] \"C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Professional\\VC\\Tools\\MSVC\\14.29.30037\\bin\\Hostx64\\x64/link.exe\" functions_cpu.o tensor_funcs.o /nologo /DLL c10.lib torch_cpu.lib torch.lib torch_python.lib /LIBPATH:c:\\Users\\jakubdeb\\repos\\openvino_notebooks\\venv_39_1701\\Scripts\\libs /LIBPATH:c:\\Users\\jakubdeb\\repos\\openvino_notebooks\\venv_39_1701\\lib\\site-packages\\torch\\lib /out:quantized_functions_cpu.pyd\r\nFAILED: quantized_functions_cpu.pyd \r\n\"C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Professional\\VC\\Tools\\MSVC\\14.29.30037\\bin\\Hostx64\\x64/link.exe\" functions_cpu.o tensor_funcs.o /nologo /DLL c10.lib torch_cpu.lib torch.lib torch_python.lib /LIBPATH:c:\\Users\\jakubdeb\\repos\\openvino_notebooks\\venv_39_1701\\Scripts\\libs /LIBPATH:c:\\Users\\jakubdeb\\repos\\openvino_notebooks\\venv_39_1701\\lib\\site-packages\\torch\\lib /out:quantized_functions_cpu.pyd\r\nLINK : fatal error LNK1104: cannot open file 'python39.lib'\r\nninja: build stopped: subcommand failed.\r\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import logging\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow.python.keras import layers\n",
    "from tensorflow.python.keras import models\n",
    "\n",
    "from nncf import NNCFConfig\n",
    "from nncf.tensorflow.helpers.model_creation import create_compressed_model\n",
    "from nncf.tensorflow.initialization import register_default_init_args\n",
    "from nncf.common.utils.logger import set_log_level\n",
    "\n",
    "MODEL_DIR = Path(\"model\")\n",
    "OUTPUT_DIR = Path(\"output\")\n",
    "MODEL_DIR.mkdir(exist_ok=True)\n",
    "OUTPUT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "BASE_MODEL_NAME = \"ResNet-18\"\n",
    "\n",
    "fp32_h5_path = Path(MODEL_DIR / (BASE_MODEL_NAME + \"_fp32\")).with_suffix(\".h5\")\n",
    "fp32_sm_path = Path(OUTPUT_DIR / (BASE_MODEL_NAME + \"_fp32\"))\n",
    "fp32_ir_path = Path(OUTPUT_DIR / \"saved_model\").with_suffix(\".xml\")\n",
    "int8_pb_path = Path(OUTPUT_DIR / (BASE_MODEL_NAME + \"_int8\")).with_suffix(\".pb\")\n",
    "int8_pb_name = Path(BASE_MODEL_NAME + \"_int8\").with_suffix(\".pb\")\n",
    "int8_ir_path = int8_pb_path.with_suffix(\".xml\")\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "IMG_SIZE = (64, 64)  # Default Imagenet image size\n",
    "NUM_CLASSES = 10  # For Imagenette dataset\n",
    "\n",
    "LR = 1e-5\n",
    "\n",
    "MEAN_RGB = (0.485 * 255, 0.456 * 255, 0.406 * 255)  # From Imagenet dataset\n",
    "STDDEV_RGB = (0.229 * 255, 0.224 * 255, 0.225 * 255)  # From Imagenet dataset\n",
    "\n",
    "fp32_pth_url = \"https://storage.openvinotoolkit.org/repositories/nncf/openvino_notebook_ckpts/305_resnet18_imagenette_fp32.h5\"\n",
    "_ = tf.keras.utils.get_file(fp32_h5_path.resolve(), fp32_pth_url)\n",
    "print(f'Absolute path where the model weights are saved:\\n {fp32_h5_path.resolve()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f178c3c1",
   "metadata": {},
   "source": [
    "## Dataset Preprocessing\n",
    "\n",
    "Download and prepare Imagenette 160px dataset.\n",
    "- Number of classes: 10\n",
    "- Download size: 94.18 MiB\n",
    "| Split        | Examples |\n",
    "|--------------|----------|\n",
    "| 'train'      | 12,894   |\n",
    "| 'validation' | 500      |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc3b1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets, datasets_info = tfds.load('imagenette/160px', shuffle_files=True, as_supervised=True, with_info=True)\n",
    "train_dataset, validation_dataset = datasets['train'], datasets['validation']\n",
    "fig = tfds.show_examples(train_dataset, datasets_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e18adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(image, label):\n",
    "    image = tf.image.resize(image, IMG_SIZE)\n",
    "    image = image - MEAN_RGB\n",
    "    image = image / STDDEV_RGB\n",
    "    label = tf.one_hot(label, NUM_CLASSES)\n",
    "    return image, label\n",
    "\n",
    "\n",
    "train_dataset = (train_dataset.map(preprocessing, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "                              .batch(BATCH_SIZE)\n",
    "                              .prefetch(tf.data.experimental.AUTOTUNE))\n",
    "\n",
    "validation_dataset = (validation_dataset.map(preprocessing, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "                                        .batch(BATCH_SIZE)\n",
    "                                        .prefetch(tf.data.experimental.AUTOTUNE))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "978e0fdb",
   "metadata": {},
   "source": [
    "## Define a Floating-Point Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b5eccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def residual_conv_block(filters, stage, block, strides=(1, 1), cut='pre'):\n",
    "    def layer(input_tensor):\n",
    "        x = layers.BatchNormalization(epsilon=2e-5)(input_tensor)\n",
    "        x = layers.Activation('relu')(x)\n",
    "\n",
    "        # defining shortcut connection\n",
    "        if cut == 'pre':\n",
    "            shortcut = input_tensor\n",
    "        elif cut == 'post':\n",
    "            shortcut = layers.Conv2D(filters, (1, 1), strides=strides, kernel_initializer='he_uniform', \n",
    "                                     use_bias=False)(x)\n",
    "\n",
    "        # continue with convolution layers\n",
    "        x = layers.ZeroPadding2D(padding=(1, 1))(x)\n",
    "        x = layers.Conv2D(filters, (3, 3), strides=strides, kernel_initializer='he_uniform', use_bias=False)(x)\n",
    "\n",
    "        x = layers.BatchNormalization(epsilon=2e-5)(x)\n",
    "        x = layers.Activation('relu')(x)\n",
    "        x = layers.ZeroPadding2D(padding=(1, 1))(x)\n",
    "        x = layers.Conv2D(filters, (3, 3), kernel_initializer='he_uniform', use_bias=False)(x)\n",
    "\n",
    "        # add residual connection\n",
    "        x = layers.Add()([x, shortcut])\n",
    "        return x\n",
    "\n",
    "    return layer\n",
    "\n",
    "\n",
    "def ResNet18(input_shape=None):\n",
    "    \"\"\"Instantiates the ResNet18 architecture.\"\"\"\n",
    "    img_input = layers.Input(shape=input_shape, name='data')\n",
    "\n",
    "    # ResNet18 bottom\n",
    "    x = layers.BatchNormalization(epsilon=2e-5, scale=False)(img_input)\n",
    "    x = layers.ZeroPadding2D(padding=(3, 3))(x)\n",
    "    x = layers.Conv2D(64, (7, 7), strides=(2, 2), kernel_initializer='he_uniform', use_bias=False)(x)\n",
    "    x = layers.BatchNormalization(epsilon=2e-5)(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    x = layers.ZeroPadding2D(padding=(1, 1))(x)\n",
    "    x = layers.MaxPooling2D((3, 3), strides=(2, 2), padding='valid')(x)\n",
    "\n",
    "    # ResNet18 body\n",
    "    repetitions = (2, 2, 2, 2)\n",
    "    for stage, rep in enumerate(repetitions):\n",
    "        for block in range(rep):\n",
    "            filters = 64 * (2 ** stage)\n",
    "            if block == 0 and stage == 0:\n",
    "                x = residual_conv_block(filters, stage, block, strides=(1, 1), cut='post')(x)\n",
    "            elif block == 0:\n",
    "                x = residual_conv_block(filters, stage, block, strides=(2, 2), cut='post')(x)\n",
    "            else:\n",
    "                x = residual_conv_block(filters, stage, block, strides=(1, 1), cut='pre')(x)\n",
    "    x = layers.BatchNormalization(epsilon=2e-5)(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "\n",
    "    # ResNet18 top\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Dense(NUM_CLASSES)(x)\n",
    "    x = layers.Activation('softmax')(x)\n",
    "\n",
    "    # Create model\n",
    "    model = models.Model(img_input, x)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d49af16",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SHAPE = IMG_SIZE + (3,)\n",
    "model = ResNet18(input_shape=IMG_SHAPE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97fcd3fc",
   "metadata": {},
   "source": [
    "## Pre-train Floating-Point Model\n",
    "\n",
    "Using NNCF for model compression assumes that the user has a pre-trained model and a training pipeline.\n",
    "\n",
    "> **NOTE** For the sake of simplicity of the tutorial, we propose to skip FP32 model training and load the weights that are provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e34f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the floating-point weights\n",
    "model.load_weights(fp32_h5_path)\n",
    "\n",
    "# Compile the floating-point model\n",
    "model.compile(loss=tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.1),\n",
    "              metrics=[tf.keras.metrics.CategoricalAccuracy(name='acc@1')])\n",
    "\n",
    "# Validate the floating-point model\n",
    "test_loss, test_acc = model.evaluate(validation_dataset,\n",
    "                                     callbacks=tf.keras.callbacks.ProgbarLogger(stateful_metrics=['acc@1']))\n",
    "print(f\"\\nAccuracy of FP32 model: {test_acc:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b80f67d6",
   "metadata": {},
   "source": [
    "Save the floating-point model to the saved model, which will be later used for conversion to OpenVINO IR and further performance measurement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450cbcb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(fp32_sm_path)\n",
    "print(f'Absolute path where the model is saved:\\n {fp32_sm_path.resolve()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b81167",
   "metadata": {},
   "source": [
    "## Create and Initialize Quantization\n",
    "\n",
    "NNCF enables compression-aware training by integrating into regular training pipelines. The framework is designed so that modifications to your original training code are minor. Quantization is the simplest scenario and requires only 3 modifications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b74e77",
   "metadata": {},
   "source": [
    "1. Configure NNCF parameters to specify compression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cafb190",
   "metadata": {},
   "outputs": [],
   "source": [
    "nncf_config_dict = {\n",
    "    \"input_info\": {\"sample_size\": [1, 3] + list(IMG_SIZE)},\n",
    "    \"log_dir\": str(OUTPUT_DIR),  # log directory for NNCF-specific logging outputs\n",
    "    \"compression\": {\n",
    "        \"algorithm\": \"quantization\",  # specify the algorithm here\n",
    "    },\n",
    "}\n",
    "nncf_config = NNCFConfig.from_dict(nncf_config_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0fb9e4d",
   "metadata": {},
   "source": [
    "2. Provide data loader to initialize the values of quantization ranges and determine which activation should be signed or unsigned from the collected statistics using a given number of samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d541d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "nncf_config = register_default_init_args(nncf_config=nncf_config,\n",
    "                                         data_loader=train_dataset,\n",
    "                                         batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc64e3e",
   "metadata": {},
   "source": [
    "3. Create a wrapped model ready for compression fine-tuning from a pre-trained FP32 model and configuration object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c9021c",
   "metadata": {},
   "outputs": [],
   "source": [
    "compression_ctrl, model = create_compressed_model(model, nncf_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffadfd04",
   "metadata": {},
   "source": [
    "Evaluate the new model on the validation set after initialization of quantization. The accuracy should be not far from the accuracy of the floating-point FP32 model for a simple case like the one we are demonstrating now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4aa6d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the int8 model\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(lr=LR),\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.1),\n",
    "              metrics=[tf.keras.metrics.CategoricalAccuracy(name='acc@1')])\n",
    "\n",
    "# Validate the int8 model\n",
    "test_loss, test_acc = model.evaluate(validation_dataset,\n",
    "                                     callbacks=tf.keras.callbacks.ProgbarLogger(stateful_metrics=['acc@1']))\n",
    "print(f\"\\nAccuracy of INT8 model after initialization: {test_acc:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d0b8f8",
   "metadata": {},
   "source": [
    "## Fine-tune the Compressed Model\n",
    "\n",
    "At this step, a regular fine-tuning process is applied to restore accuracy drop. Normally, several epochs of tuning are required with a small learning rate, the same that is usually used at the end of the training of the original model. No other changes in the training pipeline are required. Here is a simple example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4047d88",
   "metadata": {
    "scrolled": true,
    "tags": [],
    "test_replace": {
     "fit(train_dataset,": "fit(validation_dataset,"
    }
   },
   "outputs": [],
   "source": [
    "# Train the int8 model\n",
    "model.fit(train_dataset,\n",
    "          epochs=1)\n",
    "\n",
    "# Validate the int8 model\n",
    "test_loss, test_acc = model.evaluate(validation_dataset,\n",
    "                                     callbacks=tf.keras.callbacks.ProgbarLogger(stateful_metrics=['acc@1']))\n",
    "print(f\"\\nAccuracy of INT8 model after fine-tuning: {test_acc:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af453ef",
   "metadata": {},
   "source": [
    "Save the INT8 model to the frozen graph (saved model does not work with quantized model for now). Frozen graph will be later used for conversion to OpenVINO IR and further performance measurement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b208b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "compression_ctrl.export_model(int8_pb_path, 'frozen_graph')\n",
    "print(f'Absolute path where the int8 model is saved:\\n {int8_pb_path.resolve()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73345cd0",
   "metadata": {},
   "source": [
    "## Export Frozen Graph Models to OpenVINO™ Intermediate Representation (IR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1248a563",
   "metadata": {},
   "source": [
    "Call the OpenVINO Model Optimizer tool to convert the Saved Model and Frozen Graph models to OpenVINO IR. The models are saved to the current directory.\n",
    "\n",
    "See the [Model Optimizer Developer Guide](https://docs.openvinotoolkit.org/latest/openvino_docs_MO_DG_Deep_Learning_Model_Optimizer_DevGuide.html) for more information about Model Optimizer.\n",
    "\n",
    "Executing this command may take a while. There may be some errors or warnings in the output. Model Optimization successfully export to IR if the last lines of the output include: `[ SUCCESS ] Generated IR version 10 model`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92fda382",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mo --framework=tf --input_shape=[1,64,64,3] --input=data --saved_model_dir=$fp32_sm_path --output_dir=$OUTPUT_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8adccc72",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mo --framework=tf --input_shape=[1,64,64,3] --input=Placeholder --input_model=$int8_pb_path --output_dir=$OUTPUT_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d3bbaf",
   "metadata": {},
   "source": [
    "## Benchmark Model Performance by Computing Inference Time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f048b410",
   "metadata": {},
   "source": [
    "Finally, we will measure the inference performance of the FP32 and INT8 models. To do this, we use [Benchmark Tool](https://docs.openvinotoolkit.org/latest/openvino_inference_engine_tools_benchmark_tool_README.html) - OpenVINO's inference performance measurement tool. By default, Benchmark Tool runs inference for 60 seconds in asynchronous mode on CPU. It returns inference speed as latency (milliseconds per image) and throughput (frames per second) values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "304a76c9",
   "metadata": {},
   "source": [
    "> **NOTE**: In this notebook we run benchmark_app for 15 seconds to give a quick indication of performance. For more accurate performance, we recommended running benchmark_app in a terminal/command prompt after closing other applications. Run benchmark_app -m model.xml -d CPU to benchmark async inference on CPU for one minute. Change CPU to GPU to benchmark on GPU. Run benchmark_app --help to see an overview of all command line options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63355744",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def parse_benchmark_output(benchmark_output):\n",
    "    parsed_output = [line for line in benchmark_output if not (line.startswith(r\"[\") or line.startswith(\"  \") or line == \"\")]\n",
    "    print(*parsed_output, sep='\\n')\n",
    "\n",
    "\n",
    "print('Benchmark FP32 model (IR)')\n",
    "benchmark_output = ! benchmark_app -m $fp32_ir_path -d CPU -api async -t 15\n",
    "parse_benchmark_output(benchmark_output)\n",
    "\n",
    "print('\\nBenchmark INT8 model (IR)')\n",
    "benchmark_output = ! benchmark_app -m $int8_ir_path -d CPU -api async -t 15\n",
    "parse_benchmark_output(benchmark_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60b19e9",
   "metadata": {},
   "source": [
    "Show CPU Information for reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a6407c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openvino.inference_engine import Core\n",
    "\n",
    "ie = Core()\n",
    "ie.get_metric(device_name='CPU', metric_name=\"FULL_DEVICE_NAME\")"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Отсутствует",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
