{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af7b6f13",
   "metadata": {},
   "source": [
    "# INT8 acceleration of semantic segmentation with NNCF/POT for OpenVINO\n",
    "\n",
    "This notebook runs through the process of enabling [NNCF](https://github.com/openvinotoolkit/nncf) in a simple semantic segmentation pipeline for training UNet on Camvid, and comparing results against the Post-Training Optimization Tool ([POT](https://docs.openvinotoolkit.org/latest/pot_README.html))'s quantization.\n",
    "\n",
    "> NOTE: _For this notebook to function, please make sure that your Python environment has `openvino`, `openvino-dev` and `nncf[torch]` packages installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27cb5c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\npython = sys.executable\n%ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c29922",
   "metadata": {},
   "source": [
    "Get the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a33c1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/alexgkendall/SegNet-Tutorial data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d32df7",
   "metadata": {},
   "source": [
    "### Obtaining the uncompressed (FP32) performance and accuracy baselines\n",
    "Download the FP32 pre-trained weights checkpoint for UNet on CamVid:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad25d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -o unet_camvid.pth https://storage.openvinotoolkit.org/repositories/nncf/openvino_notebook_ckpts/303_unet_camvid.pth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a2f0f0",
   "metadata": {},
   "source": [
    "Measure the baseline FP32 accuracy in PyTorch and produce an ONNX for future OpenVINO ingestion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab64ffea",
   "metadata": {},
   "outputs": [],
   "source": [
    "!$python main.py -m test export --resume unet_camvid.pth --data data/CamVid -b 1 --to-onnx unet_camvid.onnx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c02839c0",
   "metadata": {},
   "source": [
    "Evaluate the FP32 model on OpenVINO (accuracy and performance); first, convert the ONNX file to the intermediate representation (IR) using the [Model Optimizer](https://docs.openvinotoolkit.org/latest/openvino_docs_MO_DG_Deep_Learning_Model_Optimizer_DevGuide.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b03409d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mo --input_model unet_camvid.onnx --mean_values [99.603,103.329,105.6567] --scale_values [75.643,77.821,76.746] --reverse_input_channels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c358c68",
   "metadata": {},
   "source": [
    "Measure the accuracy (mIoU metric) on the target dataset using the Accuracy Checker tool (part of the `openvino-dev` package with the prepared .yml specification of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b96b4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!accuracy_check -c unet_camvid.yml -m unet_camvid.xml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b197df4b",
   "metadata": {},
   "source": [
    "For measuring performance, we use the [Benchmark Tool](https://docs.openvinotoolkit.org/latest/openvino_inference_engine_tools_benchmark_tool_README.html) - OpenVINO's inference performance measurement tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6c9dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!benchmark_app -m unet_camvid.xml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74242ffb",
   "metadata": {},
   "source": [
    "### POT approach\n",
    "Use POT to obtain an INT8 model. Note that this path requires your dataset to be supported by the Accuracy Checker tool (part of the `openvino-dev` Python package), which is not true for all datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194fe6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pot -q accuracy_aware --max-drop 0.01 -m unet_camvid.xml -w unet_camvid.bin --ac-config unet_camvid.yml --output-dir pot_int8 --name unet_camvid_pot_aa_int8 -e -d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "177da51c",
   "metadata": {},
   "source": [
    "Measure performance for the INT8-POT model (the accuracy results are already visible in the POT output above) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7714b8a0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!benchmark_app -m pot_int8/optimized/unet_camvid_pot_aa_int8.xml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b103e4f3",
   "metadata": {},
   "source": [
    "### NNCF approach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf52ada",
   "metadata": {},
   "source": [
    "Make sure that NNCF is installed in your Python environment - either from the source repository or the PyPI using `pip install nncf` - then integrate NNCF into the training pipeline. The line below apples the patch to allow for producing NNCF-compressed INT8 models. 5 lines of code (excluding import statements) and a simple .json config is enough for this integration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffdd3a06",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!patch -p1 < nncf.patch\n",
    "!cat nncf.patch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b6eb082",
   "metadata": {},
   "source": [
    "Perform compression-aware fine-tuning using NNCF, starting from the regular PyTorch checkpoint (unet_camvid.pth), for 10 epochs, picking the best result and exporting it into an INT8 ONNX file (unet_camvid_int8.onnx). The training takes about 10 minutes on a single NVIDIA RTX 2080 Ti GPU. Note that there is no requirement for the support of the dataset by a third-party tool in order to obtain the results since the dataset is already supported by the source training pipeline and NNCF integrates into the pipeline seamlessly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5407b25b",
   "metadata": {"test_replace": {"epochs 10": "epochs 1"}},
   "outputs": [],
   "source": [
    "!$python main.py -m train test export --resume unet_camvid.pth --data data/CamVid -b 3 --epochs 10 --to-onnx unet_camvid_int8.onnx --nncf_config unet_camvid_int8.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7757acfe",
   "metadata": {},
   "source": [
    "Convert the NNCF-INT8 ONNX file into the NNCF-INT8 IR for OpenVINO ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8600f717",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mo --input_model unet_camvid_int8.onnx --mean_values [99.603,103.329,105.6567] --scale_values [75.643,77.821,76.746] --reverse_input_channels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86aa1555",
   "metadata": {},
   "source": [
    "Evaluate the NNCF-INT8 model in OpenVINO, accuracy and performance-wise:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3631088b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!accuracy_check -c unet_camvid.yml -m unet_camvid_int8.xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beadd11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!benchmark_app -m unet_camvid_int8.xml"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
