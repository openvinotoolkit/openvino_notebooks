{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Video subtitles generation using Whisper and OpenVINO\n",
    "\n",
    "Whisper is a general-purpose speech recognition model. It is a multi-task model that can perform multilingual speech recognition as well as speech translation and language identification. In this demo we will use its capabilities for generation subtitles to video on several languages.\n",
    "\n",
    "Notebook contains following steps:\n",
    "1. Convert model to ONNX format.\n",
    "2. Convert model to IR using OpenVINO Model Optimizer tool.\n",
    "3. Run Whisper pipeline with OpenVINO models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "clone and install model repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\eaidova\\repos\\openvino_notebooks\\notebooks\\225-whisper-subtitels-generation\\whisper\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'whisper' already exists and is not an empty directory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\eaidova\\repos\\openvino_notebooks\\notebooks\\225-whisper-subtitels-generation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python: can't open file 'c:\\Users\\eaidova\\repos\\openvino_notebooks\\notebooks\\225-whisper-subtitels-generation\\whisper\\setup.py': [Errno 2] No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/openai/whisper.git\n",
    "%cd whisper\n",
    "!python setup.py develop\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\eaidova\\Anaconda3\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "c:\\Users\\eaidova\\Anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.FB5AE2TYXYH2IJRDKGDGQ3XBKLKTF43H.gfortran-win_amd64.dll\n",
      "c:\\Users\\eaidova\\Anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.WCDJNK7YVMPZQ2ME2ZZHJJRJ3JIKNDB7.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Whisper(\n",
       "  (encoder): AudioEncoder(\n",
       "    (conv1): Conv1d(80, 1024, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (conv2): Conv1d(1024, 1024, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "    (blocks): ModuleList(\n",
       "      (0): ResidualAttentionBlock(\n",
       "        (attn): MultiHeadAttention(\n",
       "          (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (out): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU(approximate=none)\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "        (mlp_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (1): ResidualAttentionBlock(\n",
       "        (attn): MultiHeadAttention(\n",
       "          (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (out): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU(approximate=none)\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "        (mlp_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (2): ResidualAttentionBlock(\n",
       "        (attn): MultiHeadAttention(\n",
       "          (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (out): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU(approximate=none)\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "        (mlp_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (3): ResidualAttentionBlock(\n",
       "        (attn): MultiHeadAttention(\n",
       "          (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (out): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU(approximate=none)\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "        (mlp_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (4): ResidualAttentionBlock(\n",
       "        (attn): MultiHeadAttention(\n",
       "          (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (out): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU(approximate=none)\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "        (mlp_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (5): ResidualAttentionBlock(\n",
       "        (attn): MultiHeadAttention(\n",
       "          (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (out): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU(approximate=none)\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "        (mlp_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (6): ResidualAttentionBlock(\n",
       "        (attn): MultiHeadAttention(\n",
       "          (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (out): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU(approximate=none)\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "        (mlp_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (7): ResidualAttentionBlock(\n",
       "        (attn): MultiHeadAttention(\n",
       "          (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (out): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU(approximate=none)\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "        (mlp_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (8): ResidualAttentionBlock(\n",
       "        (attn): MultiHeadAttention(\n",
       "          (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (out): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU(approximate=none)\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "        (mlp_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (9): ResidualAttentionBlock(\n",
       "        (attn): MultiHeadAttention(\n",
       "          (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (out): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU(approximate=none)\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "        (mlp_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (10): ResidualAttentionBlock(\n",
       "        (attn): MultiHeadAttention(\n",
       "          (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (out): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU(approximate=none)\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "        (mlp_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (11): ResidualAttentionBlock(\n",
       "        (attn): MultiHeadAttention(\n",
       "          (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (out): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU(approximate=none)\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "        (mlp_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (12): ResidualAttentionBlock(\n",
       "        (attn): MultiHeadAttention(\n",
       "          (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (out): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU(approximate=none)\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "        (mlp_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (13): ResidualAttentionBlock(\n",
       "        (attn): MultiHeadAttention(\n",
       "          (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (out): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU(approximate=none)\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "        (mlp_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (14): ResidualAttentionBlock(\n",
       "        (attn): MultiHeadAttention(\n",
       "          (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (out): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU(approximate=none)\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "        (mlp_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (15): ResidualAttentionBlock(\n",
       "        (attn): MultiHeadAttention(\n",
       "          (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (out): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU(approximate=none)\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "        (mlp_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (16): ResidualAttentionBlock(\n",
       "        (attn): MultiHeadAttention(\n",
       "          (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (out): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU(approximate=none)\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "        (mlp_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (17): ResidualAttentionBlock(\n",
       "        (attn): MultiHeadAttention(\n",
       "          (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (out): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU(approximate=none)\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "        (mlp_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (18): ResidualAttentionBlock(\n",
       "        (attn): MultiHeadAttention(\n",
       "          (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (out): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU(approximate=none)\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "        (mlp_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (19): ResidualAttentionBlock(\n",
       "        (attn): MultiHeadAttention(\n",
       "          (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (out): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU(approximate=none)\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "        (mlp_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (20): ResidualAttentionBlock(\n",
       "        (attn): MultiHeadAttention(\n",
       "          (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (out): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU(approximate=none)\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "        (mlp_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (21): ResidualAttentionBlock(\n",
       "        (attn): MultiHeadAttention(\n",
       "          (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (out): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU(approximate=none)\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "        (mlp_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (22): ResidualAttentionBlock(\n",
       "        (attn): MultiHeadAttention(\n",
       "          (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (out): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU(approximate=none)\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "        (mlp_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (23): ResidualAttentionBlock(\n",
       "        (attn): MultiHeadAttention(\n",
       "          (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (out): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU(approximate=none)\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "        (mlp_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (ln_post): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (decoder): TextDecoder(\n",
       "    (token_embedding): Embedding(51865, 1024)\n",
       "    (blocks): ModuleList(\n",
       "      (0): ResidualAttentionBlock(\n",
       "        (attn): MultiHeadAttention(\n",
       "          (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (out): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (cross_attn): MultiHeadAttention(\n",
       "          (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (out): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (cross_attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU(approximate=none)\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "        (mlp_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (1): ResidualAttentionBlock(\n",
       "        (attn): MultiHeadAttention(\n",
       "          (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (out): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (cross_attn): MultiHeadAttention(\n",
       "          (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (out): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (cross_attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU(approximate=none)\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "        (mlp_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (2): ResidualAttentionBlock(\n",
       "        (attn): MultiHeadAttention(\n",
       "          (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (out): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (cross_attn): MultiHeadAttention(\n",
       "          (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (out): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (cross_attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU(approximate=none)\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "        (mlp_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (3): ResidualAttentionBlock(\n",
       "        (attn): MultiHeadAttention(\n",
       "          (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (out): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (cross_attn): MultiHeadAttention(\n",
       "          (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (out): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (cross_attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU(approximate=none)\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "        (mlp_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (4): ResidualAttentionBlock(\n",
       "        (attn): MultiHeadAttention(\n",
       "          (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (out): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (cross_attn): MultiHeadAttention(\n",
       "          (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (out): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (cross_attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU(approximate=none)\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "        (mlp_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (5): ResidualAttentionBlock(\n",
       "        (attn): MultiHeadAttention(\n",
       "          (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (out): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (cross_attn): MultiHeadAttention(\n",
       "          (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (out): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (cross_attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU(approximate=none)\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "        (mlp_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (6): ResidualAttentionBlock(\n",
       "        (attn): MultiHeadAttention(\n",
       "          (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (out): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (cross_attn): MultiHeadAttention(\n",
       "          (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (out): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (cross_attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU(approximate=none)\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "        (mlp_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (7): ResidualAttentionBlock(\n",
       "        (attn): MultiHeadAttention(\n",
       "          (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (out): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (cross_attn): MultiHeadAttention(\n",
       "          (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (out): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (cross_attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU(approximate=none)\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "        (mlp_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (8): ResidualAttentionBlock(\n",
       "        (attn): MultiHeadAttention(\n",
       "          (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (out): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (cross_attn): MultiHeadAttention(\n",
       "          (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (out): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (cross_attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU(approximate=none)\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "        (mlp_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (9): ResidualAttentionBlock(\n",
       "        (attn): MultiHeadAttention(\n",
       "          (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (out): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (cross_attn): MultiHeadAttention(\n",
       "          (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (out): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (cross_attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU(approximate=none)\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "        (mlp_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (10): ResidualAttentionBlock(\n",
       "        (attn): MultiHeadAttention(\n",
       "          (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (out): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (cross_attn): MultiHeadAttention(\n",
       "          (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (out): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (cross_attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU(approximate=none)\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "        (mlp_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (11): ResidualAttentionBlock(\n",
       "        (attn): MultiHeadAttention(\n",
       "          (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (out): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (cross_attn): MultiHeadAttention(\n",
       "          (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (out): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (cross_attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU(approximate=none)\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "        (mlp_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (12): ResidualAttentionBlock(\n",
       "        (attn): MultiHeadAttention(\n",
       "          (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (out): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (cross_attn): MultiHeadAttention(\n",
       "          (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (out): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (cross_attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU(approximate=none)\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "        (mlp_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (13): ResidualAttentionBlock(\n",
       "        (attn): MultiHeadAttention(\n",
       "          (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (out): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (cross_attn): MultiHeadAttention(\n",
       "          (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (out): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (cross_attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU(approximate=none)\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "        (mlp_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (14): ResidualAttentionBlock(\n",
       "        (attn): MultiHeadAttention(\n",
       "          (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (out): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (cross_attn): MultiHeadAttention(\n",
       "          (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (out): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (cross_attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU(approximate=none)\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "        (mlp_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (15): ResidualAttentionBlock(\n",
       "        (attn): MultiHeadAttention(\n",
       "          (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (out): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (cross_attn): MultiHeadAttention(\n",
       "          (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (out): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (cross_attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU(approximate=none)\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "        (mlp_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (16): ResidualAttentionBlock(\n",
       "        (attn): MultiHeadAttention(\n",
       "          (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (out): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (cross_attn): MultiHeadAttention(\n",
       "          (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (out): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (cross_attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU(approximate=none)\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "        (mlp_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (17): ResidualAttentionBlock(\n",
       "        (attn): MultiHeadAttention(\n",
       "          (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (out): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (cross_attn): MultiHeadAttention(\n",
       "          (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (out): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (cross_attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU(approximate=none)\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "        (mlp_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (18): ResidualAttentionBlock(\n",
       "        (attn): MultiHeadAttention(\n",
       "          (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (out): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (cross_attn): MultiHeadAttention(\n",
       "          (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (out): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (cross_attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU(approximate=none)\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "        (mlp_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (19): ResidualAttentionBlock(\n",
       "        (attn): MultiHeadAttention(\n",
       "          (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (out): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (cross_attn): MultiHeadAttention(\n",
       "          (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (out): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (cross_attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU(approximate=none)\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "        (mlp_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (20): ResidualAttentionBlock(\n",
       "        (attn): MultiHeadAttention(\n",
       "          (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (out): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (cross_attn): MultiHeadAttention(\n",
       "          (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (out): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (cross_attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU(approximate=none)\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "        (mlp_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (21): ResidualAttentionBlock(\n",
       "        (attn): MultiHeadAttention(\n",
       "          (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (out): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (cross_attn): MultiHeadAttention(\n",
       "          (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (out): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (cross_attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU(approximate=none)\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "        (mlp_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (22): ResidualAttentionBlock(\n",
       "        (attn): MultiHeadAttention(\n",
       "          (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (out): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (cross_attn): MultiHeadAttention(\n",
       "          (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (out): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (cross_attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU(approximate=none)\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "        (mlp_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (23): ResidualAttentionBlock(\n",
       "        (attn): MultiHeadAttention(\n",
       "          (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (out): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (cross_attn): MultiHeadAttention(\n",
       "          (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (out): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (cross_attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU(approximate=none)\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "        (mlp_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import whisper\n",
    "\n",
    "model = whisper.load_model(\"medium\")\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert model to ONNX\n",
    "\n",
    "Model consists of 2 parts:\n",
    "* Encoder\n",
    "* Decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Whisper Encoder to ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\eaidova\\Anaconda3\\lib\\site-packages\\whisper\\model.py:152: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert x.shape[1:] == self.positional_embedding.shape, \"incorrect audio shape\"\n",
      "c:\\Users\\eaidova\\Anaconda3\\lib\\site-packages\\whisper\\model.py:90: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  scale = (n_state // self.n_head) ** -0.25\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "mel = torch.zeros((1, 80, 3000))\n",
    "\n",
    "torch.onnx.export(model.encoder, mel, 'whisper_encoder.onnx', input_names=['mel'], output_names=['audio_features'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Whisper decoder to ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from typing import Optional, Union, List\n",
    "from functools import partial\n",
    "\n",
    "positional_embeddings_size = model.decoder.positional_embedding.shape[0]\n",
    "\n",
    "def save_to_cache(cache, module, output):\n",
    "    if module not in cache or output.shape[1] > positional_embeddings_size:\n",
    "        cache[module] = output  # save as-is, for the first token or cross attention\n",
    "    else:\n",
    "        cache[module] = torch.cat([cache[module], output], dim=1).detach()\n",
    "    return cache[module]\n",
    "  \n",
    "def attention_forward(\n",
    "        attention_module,\n",
    "        x: torch.Tensor,\n",
    "        xa: Optional[torch.Tensor] = None,\n",
    "        mask: Optional[torch.Tensor] = None,\n",
    "        kv_cache: Optional[dict] = None,\n",
    "        idx: int = 0\n",
    "):\n",
    "    q = attention_module.query(x)\n",
    "\n",
    "    if kv_cache is None or xa is None:\n",
    "        # hooks, if installed (i.e. kv_cache is not None), will prepend the cached kv tensors;\n",
    "        # otherwise, perform key/value projections for self- or cross-attention as usual.\n",
    "        k = attention_module.key(x if xa is None else xa)\n",
    "        v = attention_module.value(x if xa is None else xa)\n",
    "        if kv_cache is not None:\n",
    "            k = save_to_cache(kv_cache, f'k_{idx}', k)\n",
    "            v = save_to_cache(kv_cache, f'v_{idx}', v)\n",
    "    else:\n",
    "        # for cross-attention, calculate keys and values once and reuse in subsequent calls.\n",
    "        k = kv_cache.get(f'k_{idx}', save_to_cache(kv_cache, f'k_{idx}', attention_module.key(xa)))\n",
    "        v = kv_cache.get(f'v_{idx}', save_to_cache(kv_cache, f'v_{idx}', attention_module.value(xa)))\n",
    "\n",
    "    wv = attention_module.qkv_attention(q, k, v, mask)\n",
    "    return attention_module.out(wv), kv_cache\n",
    "\n",
    "\n",
    "def block_forward(\n",
    "        residual_block,\n",
    "        x: torch.Tensor,\n",
    "        xa: Optional[torch.Tensor] = None,\n",
    "        mask: Optional[torch.Tensor] = None,\n",
    "        kv_cache: Optional[dict] = None,\n",
    "        idx:int = 0\n",
    "    ):\n",
    "        x0, kv_cache = residual_block.attn(residual_block.attn_ln(x), mask=mask, kv_cache=kv_cache, idx=f'{idx}a')\n",
    "        x = x + x0\n",
    "        if residual_block.cross_attn:\n",
    "            x1, kv_cache = residual_block.cross_attn(residual_block.cross_attn_ln(x), xa, kv_cache=kv_cache, idx=f'{idx}c')\n",
    "            x = x + x1\n",
    "        x = x + residual_block.mlp(residual_block.mlp_ln(x))\n",
    "        return x, kv_cache\n",
    "\n",
    "for idx, block in enumerate(model.decoder.blocks):\n",
    "    block.forward = partial(block_forward, block, idx=idx)\n",
    "    block.attn.forward = partial(attention_forward, block.attn)\n",
    "    if block.cross_attn:\n",
    "        block.cross_attn.forward = partial(attention_forward, block.cross_attn)\n",
    "\n",
    "\n",
    "def decoder_forward(decoder, x: torch.Tensor, xa: torch.Tensor, kv_cache: Optional[dict] = None):\n",
    "    \"\"\"\n",
    "    x : torch.LongTensor, shape = (batch_size, <= n_ctx) the text tokens\n",
    "    xa : torch.Tensor, shape = (batch_size, n_mels, n_audio_ctx)\n",
    "        the encoded audio features to be attended on\n",
    "    \"\"\"\n",
    "    offset = next(iter(kv_cache.values())).shape[1] if kv_cache else 0\n",
    "    x = decoder.token_embedding(x) + decoder.positional_embedding[offset : offset + x.shape[-1]]\n",
    "    x = x.to(xa.dtype)\n",
    "\n",
    "    for block in decoder.blocks:\n",
    "        x, kv_cache = block(x, xa, mask=decoder.mask, kv_cache=kv_cache)\n",
    "\n",
    "    x = decoder.ln(x)\n",
    "    logits = (x @ torch.transpose(decoder.token_embedding.weight.to(x.dtype), 1, 0)).float()\n",
    "\n",
    "    return logits, kv_cache\n",
    "\n",
    "model.decoder.forward = partial(decoder_forward, model.decoder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = torch.ones((5, 3), dtype=torch.int64)\n",
    "audio_features = torch.ones((1, 1500, 1024))\n",
    "\n",
    "logits, kv_cache = model.decoder(tokens, audio_features, kv_cache={})\n",
    "kv_cache = {k: v for k, v in kv_cache.items()}\n",
    "tokens = torch.ones((5, 1), dtype=torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-1209e68a6a67>:8: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if module not in cache or output.shape[1] > positional_embeddings_size:\n"
     ]
    }
   ],
   "source": [
    "outputs = [f'out_{k}' for k in kv_cache.keys()]\n",
    "inputs = [f'in_{k}' for k in kv_cache.keys()]\n",
    "dynamic_axes = {'tokens': {0: 'beam_size', 1: 'seq_len'}, 'audio_features': {0: 'beam_size'}, 'logits': {0: 'beam_size', 1: 'seq_len'}}\n",
    "dynamic_outs = {o: {0: 'beam_size', 1: 'prev_seq_len'} for o in outputs}\n",
    "dynamic_inp = {i: {0: 'beam_size', 1: 'prev_seq_len'}  for i in inputs}\n",
    "dynamic_axes.update(dynamic_outs)\n",
    "dynamic_axes.update(dynamic_inp)\n",
    "torch.onnx.export(\n",
    "    model.decoder, {'x': tokens, 'xa': audio_features, 'kv_cache': kv_cache},\n",
    "'whisper_decoder.onnx',\n",
    "input_names=['tokens', 'audio_features'] + inputs,\n",
    "output_names=['logits'] + outputs,\n",
    "dynamic_axes=dynamic_axes\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OpenVINOAudioEncoder(torch.nn.Module):\n",
    "    def __init__(self, core, model_path, device='CPU'):\n",
    "        super().__init__()\n",
    "        self.model = core.read_model(model_path)\n",
    "        self.compiled_model = core.compile_model(self.model, device)\n",
    "        self.output_blob = self.compiled_model.output(0)\n",
    "\n",
    "    def forward(self, mel:torch.Tensor):\n",
    "        return torch.from_numpy(self.compiled_model(mel)[self.output_blob])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OpenVINOTextDecoder(torch.nn.Module):\n",
    "    def __init__(self, core, model_path, device='CPU'):\n",
    "        super().__init__()\n",
    "        self._core = core\n",
    "        self.model = core.read_model(model_path)\n",
    "        self._input_names = [inp.any_name for inp in self.model.inputs]\n",
    "        self.compiled_model = core.compile_model(self.model, device)\n",
    "        self.device = device\n",
    "    \n",
    "    def init_past_inputs(self, feed_dict):\n",
    "        beam_size = feed_dict['tokens'].shape[0]\n",
    "        audio_len = feed_dict['audio_features'].shape[-1]\n",
    "        previous_seq_len = 0\n",
    "        for name in self._input_names:\n",
    "            if name in ['tokens', 'audio_features']:\n",
    "                continue\n",
    "            feed_dict[name] = np.zeros((beam_size, previous_seq_len, audio_len), dtype=np.float32)\n",
    "        return feed_dict\n",
    "\n",
    "    def preprocess_kv_cache_inputs(self, feed_dict, kv_cache):\n",
    "        if not kv_cache:\n",
    "            return self.init_past_inputs(feed_dict)\n",
    "        for k, v in kv_cache.items():\n",
    "            new_k = f'in_{k}'\n",
    "            if new_k in self._input_names:\n",
    "                feed_dict[new_k] = v\n",
    "        return feed_dict\n",
    "\n",
    "    def postprocess_outputs(self, outputs):\n",
    "        logits = None\n",
    "        kv_cache = {}\n",
    "        for output_t, out in outputs.items():\n",
    "            if 'logits' in output_t.get_names():\n",
    "                logits = torch.from_numpy(out)\n",
    "            else:\n",
    "                tensor_name = output_t.any_name\n",
    "                kv_cache[tensor_name.replace('out_', '')] = torch.from_numpy(out)\n",
    "        return logits, kv_cache\n",
    "\n",
    "    def forward(self, x:torch.Tensor, xa:torch.Tensor, kv_cache: Optional[dict]=None):\n",
    "        feed_dict = {'tokens': x, 'audio_features': xa}\n",
    "        feed_dict = (self.preprocess_kv_cache_inputs(feed_dict, kv_cache))\n",
    "        res = self.compiled_model(feed_dict)\n",
    "        return self.postprocess_outputs(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from whisper.decoding import DecodingTask, Inference, DecodingOptions, DecodingResult\n",
    "\n",
    "\n",
    "class OpenVINOInference(Inference):\n",
    "    def __init__(self, model: \"Whisper\", initial_token_length: int):\n",
    "        self.model: \"Whisper\" = model\n",
    "        self.initial_token_length = initial_token_length\n",
    "        self.kv_cache = {}\n",
    "    \n",
    "    def logits(self, tokens: torch.Tensor, audio_features: torch.Tensor) -> torch.Tensor:\n",
    "        if tokens.shape[-1] > self.initial_token_length:\n",
    "            # only need to use the last token except in the first forward pass\n",
    "            tokens = tokens[:, -1:]\n",
    "        logits, self.kv_cache = self.model.decoder(tokens, audio_features, kv_cache=self.kv_cache)\n",
    "        return logits\n",
    "\n",
    "    def cleanup_caching(self):\n",
    "        self.kv_cache = {}\n",
    "\n",
    "    def rearrange_kv_cache(self, source_indices):\n",
    "        for module, tensor in self.kv_cache.items():\n",
    "            # update the key/value cache to contain the selected sequences\n",
    "            self.kv_cache[module] = tensor[source_indices]\n",
    "\n",
    "\n",
    "class OpenVINODecodingTask(DecodingTask):\n",
    "    def __init__(self, model: \"Whisper\", options: DecodingOptions):\n",
    "        super().__init__(model, options)\n",
    "        self.inference = OpenVINOInference(model, len(self.initial_tokens))\n",
    "\n",
    "@torch.no_grad()\n",
    "def decode(model: \"Whisper\", mel: torch.Tensor, options: DecodingOptions = DecodingOptions()) -> Union[DecodingResult, List[DecodingResult]]:\n",
    "    \"\"\"\n",
    "    Performs decoding of 30-second audio segment(s), provided as Mel spectrogram(s).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model: Whisper\n",
    "        the Whisper model instance\n",
    "\n",
    "    mel: torch.Tensor, shape = (80, 3000) or (*, 80, 3000)\n",
    "        A tensor containing the Mel spectrogram(s)\n",
    "\n",
    "    options: DecodingOptions\n",
    "        A dataclass that contains all necessary options for decoding 30-second segments\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    result: Union[DecodingResult, List[DecodingResult]]\n",
    "        The result(s) of decoding contained in `DecodingResult` dataclass instance(s)\n",
    "    \"\"\"\n",
    "    single = mel.ndim == 2\n",
    "    if single:\n",
    "        mel = mel.unsqueeze(0)\n",
    "\n",
    "    result = OpenVINODecodingTask(model, options).run(mel)\n",
    "    \n",
    "    if single:\n",
    "        result = result[0]\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openvino.tools import mo\n",
    "from openvino.runtime import serialize\n",
    "encoder_model = mo.convert(input_model='whisper_encoder.onnx', data_type='FP16')\n",
    "serialize(encoder_model, 'whisper_encoder.xml')\n",
    "\n",
    "input_shapes = 'tokens[1..5 1..224],audio_features[1..5 1500 1024]'\n",
    "for k, v in kv_cache.items():\n",
    "    if k.endswith('a'):\n",
    "        input_shapes += f',in_{k}[1..5 0..224 1024]' \n",
    "decoder_model = mo.convert(input_model='whisper_decoder.onnx', data_type='FP16', input=input_shapes)\n",
    "serialize(decoder_model, 'whisper_decoder.xml')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model.decoder\n",
    "del model.encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openvino.runtime import Core\n",
    "from collections import namedtuple\n",
    "\n",
    "Parameter = namedtuple('Parameter', ['device'])\n",
    "\n",
    "core = Core()\n",
    "\n",
    "model.encoder = OpenVINOAudioEncoder(core, 'whisper_encoder.xml')\n",
    "model.decoder = OpenVINOTextDecoder(core, 'whisper_decoder.xml')\n",
    "model.decode = partial(decode, model)\n",
    "\n",
    "def parameters():\n",
    "    return iter([Parameter(torch.device('cpu'))])\n",
    "\n",
    "model.parameters = parameters\n",
    "\n",
    "def logits(model, tokens: torch.Tensor, audio_features: torch.Tensor):\n",
    "    return model.decoder(tokens, audio_features, None)[0]\n",
    "\n",
    "model.logits = partial(logits, model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "from moviepy.editor import VideoFileClip\n",
    "import numpy as np\n",
    "from scipy.io import wavfile\n",
    "\n",
    "def resample(audio, src_sample_rate, dst_sample_rate):\n",
    "    if src_sample_rate == dst_sample_rate:\n",
    "        return audio\n",
    "    duration = audio.shape[0] / src_sample_rate\n",
    "    resampled_data = np.zeros(shape=(int(duration * dst_sample_rate)), dtype=np.float32)\n",
    "    x_old = np.linspace(0, duration, audio.shape[0], dtype=np.float32)\n",
    "    x_new = np.linspace(0, duration, resampled_data.shape[0], dtype=np.float32)\n",
    "    resampled_audio = np.interp(x_new, x_old, audio)\n",
    "    return resampled_audio.astype(np.float32)\n",
    "\n",
    "def audio_to_float(audio):\n",
    "    return audio.astype(np.float32) / np.iinfo(audio.dtype).max\n",
    "\n",
    "\n",
    "def get_audio(video_file):\n",
    "    input_video = VideoFileClip(str(video_file))\n",
    "    input_video.audio.write_audiofile(video_file.stem + '.wav')\n",
    "    input_audio_file = video_file.stem + '.wav'\n",
    "    sample_rate, audio = wavfile.read(io.BytesIO(open(input_audio_file, 'rb').read()))\n",
    "    audio = audio_to_float(audio)\n",
    "    if audio.ndim == 2:\n",
    "        audio = audio.mean(axis=1)\n",
    "    resampled_audio = resample(audio, sample_rate, 16000)\n",
    "    return resampled_audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Writing audio in Nono_ch_15s.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "video_file = Path(\"../../../whisper/Nono_ch_15s.mp4\")\n",
    "audio = get_audio(video_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected language: chinese\n"
     ]
    }
   ],
   "source": [
    "transcription = model.transcribe(audio, beam_size=5, best_of=5, task='translate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_timestamp(seconds: float):\n",
    "    assert seconds >= 0, \"non-negative timestamp expected\"\n",
    "    milliseconds = round(seconds * 1000.0)\n",
    "\n",
    "    hours = milliseconds // 3_600_000\n",
    "    milliseconds -= hours * 3_600_000\n",
    "\n",
    "    minutes = milliseconds // 60_000\n",
    "    milliseconds -= minutes * 60_000\n",
    "\n",
    "    seconds = milliseconds // 1_000\n",
    "    milliseconds -= seconds * 1_000\n",
    "\n",
    "    return (f\"{hours}:\" if hours > 0 else \"00:\") + f\"{minutes:02d}:{seconds:02d},{milliseconds:03d}\"\n",
    "\n",
    "def prepare_srt_bilingual(transcription, translation):\n",
    "    segment_lines = []\n",
    "    for segment1, segment2 in zip(transcription['segments'], translation['segments']):\n",
    "        segment_lines.append(str(segment1['id'] + 1) +'\\n')\n",
    "        time_start = format_timestamp(segment1['start'])\n",
    "        time_end = format_timestamp(segment1['end'])\n",
    "        time_str = f'{time_start} --> {time_end}\\n'\n",
    "        segment_lines.append(time_str)\n",
    "        segment_lines.append(segment1['text'] + '\\n' + segment2['text'] + '\\n\\n')\n",
    "    return segment_lines\n",
    "\n",
    "\n",
    "def prepare_srt(transcription):\n",
    "    segment_lines = []\n",
    "    for segment in transcription['segments']:\n",
    "        segment_lines.append(str(segment['id'] + 1) +'\\n')\n",
    "        time_start = format_timestamp(segment['start'])\n",
    "        time_end = format_timestamp(segment['end'])\n",
    "        time_str = f'{time_start} --> {time_end}\\n'\n",
    "        segment_lines.append(time_str)\n",
    "        segment_lines.append(segment['text'] + '\\n\\n')\n",
    "    return segment_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "srt_lines = prepare_srt(transcription)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "00:00:00,000 --> 00:00:02,600\n",
      " The world of AI is developing rapidly.\n",
      "\n",
      "2\n",
      "00:00:02,600 --> 00:00:04,760\n",
      " From the technology little white to a technical big cow,\n",
      "\n",
      "3\n",
      "00:00:04,760 --> 00:00:07,360\n",
      " Complete the gorgeous transformation of professional life.\n",
      "\n",
      "4\n",
      "00:00:07,360 --> 00:00:35,360\n",
      " Unlock the Intel AI Developer Certification Certified.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(''.join(srt_lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\eaidova\\Anaconda3\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "c:\\Users\\eaidova\\Anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.FB5AE2TYXYH2IJRDKGDGQ3XBKLKTF43H.gfortran-win_amd64.dll\n",
      "c:\\Users\\eaidova\\Anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.WCDJNK7YVMPZQ2ME2ZZHJJRJ3JIKNDB7.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "from openvino.runtime import Core\n",
    "core = Core()\n",
    "encoder_model = core.read_model('whisper_encoder.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchaudio\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import whisper\n",
    "\n",
    "Path('librispeech').mkdir(parents=True, exist_ok=True)\n",
    "class LibriSpeech(torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "    A simple class to wrap LibriSpeech and trim/pad the audio to 30 seconds.\n",
    "    It will drop the last few seconds of a very small portion of the utterances.\n",
    "    \"\"\"\n",
    "    def __init__(self, split=\"test-clean\", device='cpu'):\n",
    "        self.dataset = torchaudio.datasets.LIBRISPEECH(\n",
    "            root='librispeech',\n",
    "            url=split,\n",
    "            download=True,\n",
    "        )\n",
    "        self.device = device\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        audio, sample_rate, text, _, _, _ = self.dataset[item]\n",
    "        assert sample_rate == 16000\n",
    "        audio = whisper.pad_or_trim(audio.flatten()).to(self.device)\n",
    "        mel = whisper.log_mel_spectrogram(audio)\n",
    "        \n",
    "        return (mel, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = LibriSpeech(\"test-clean\")\n",
    "loader = torch.utils.data.DataLoader(dataset, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the transformation method. This method should\n",
    "# take a data item from the data source and transform it\n",
    "# into the model expected input.\n",
    "def transform_fn(data_item):\n",
    "    mel, _ = data_item\n",
    "    return mel.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nncf import ptq\n",
    "from openvino.runtime import serialize\n",
    "# Wrap framework-specific data source into `NNCFDataLoader` object.\n",
    "validation_dataset = ptq.create_dataloader(loader, transform_fn)\n",
    "\n",
    "quantized_encoder_model = ptq.quantize(encoder_model, validation_dataset, model_type='transformer')\n",
    "serialize(quantized_encoder_model, 'whisper_encoder_int8.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e0404472fd7b5b63117a9fa5c50283296e2708c2449c6090d2cdf8903f95897f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
