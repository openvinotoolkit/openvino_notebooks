# TensorFlow Lite to OpenVINOâ„¢ Model Conversion Tutorial
[![Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/openvinotoolkit/openvino_notebooks/blob/main/notebooks/119-tflite-to-openvino/119-tflite-to-openvino.ipynb)

<img src="https://github.com/openvinotoolkit/openvino_notebooks/assets/29454499/581d8354-1615-453c-9825-ac1a0b937a73" width=300>

This tutorial explains how to convert [TensorFlow Lite](https://www.tensorflow.org/lite/guide) models to OpenVINO IR. The notebook shows how to convert the [EfficientNet Lite B0 model](https://tfhub.dev/tensorflow/lite-model/efficientnet/lite0/fp32/2) and then classify an image with OpenVINO Runtime.

## Notebook Contents

The notebook uses [model conversion API](https://docs.openvino.ai/2023.0/openvino_docs_model_processing_introduction.html) to convert model to OpenVINO Intermediate Representation format.

## Installation Instructions

This is a self-contained example that relies solely on its own code.</br>
We recommend  running the notebook in a virtual environment. You only need a Jupyter server to start.
For details, please refer to [Installation Guide](../../README.md).
