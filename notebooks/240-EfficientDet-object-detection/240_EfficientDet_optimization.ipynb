{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "js4jU4zhchQ_"
      },
      "source": [
        "# EfficientDet with OpenVINOâ„¢\n",
        "Research Paper : [EfficientDet: Scalable and Efficient Object Detection](https://openaccess.thecvf.com/content_CVPR_2020/papers/Tan_EfficientDet_Scalable_and_Efficient_Object_Detection_CVPR_2020_paper.pdf)\\\n",
        "EfficientDets are a family of object detection models, which achieve state-of-the-art 55.1mAP on COCO test-dev, yet being 4x - 9x smaller and using 13x - 42x fewer FLOPs than previous detectors. Our models also run 2x - 4x faster on GPU, and 5x - 11x faster on CPU than other detectors.\\\n",
        "<img src='https://raw.githubusercontent.com/google/automl/master/efficientdet/g3doc/network.png' width=450 height=200>\n",
        "<img src='https://raw.githubusercontent.com/google/automl/master/efficientdet/g3doc/params.png' width=250 height=200>\\\n",
        "In this notebook, you will learn how to use the EfficientDet model and optimize it with OpenVINO API\n",
        "\n",
        "## The tutorial consists of the following steps:\n",
        "\n",
        "* Downloading and exporting the efficientDet-d0 from TensorFlow-HUB\n",
        "  * Validating inference of tf-model\n",
        "* Converting tf-model to OpenVINO-IR(Intermediate representation) file\n",
        "  * Validating inference of OpenVINO-model\n",
        "  * Evaluating performance by AP( average Precision)\n",
        "\n",
        "[Will be included later]\n",
        "* Post-training optimization with OpenVINO NNCF (Neural Network Compression Framework)\n",
        "  * Quantization of FP16/32 model to INT8 model\n",
        "  * Validating Inference of INT8 model\n",
        "  * Evaluating performance of INT8 model by AP\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NOYWoDWfEyRD"
      },
      "source": [
        "### Prerequisites"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xAKESkEz16iP"
      },
      "outputs": [],
      "source": [
        "# These dependencies will be added to the requirements.txt once approved.\n",
        "!pip install tensorflow-hub pycocotools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ayCC8c6-3_wn"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import pathlib\n",
        "import json\n",
        "import sys\n",
        "\n",
        "sys.path.append('../utils/')\n",
        "from notebook_utils import load_image , download_file"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LppdKk6Ih7YH"
      },
      "source": [
        "### Downloading the model\n",
        "* Download a pre-trained model of EfficientDet with help of tensorflow_hub API.\n",
        "* [TensorFlow Hub](https://tfhub.dev/) is a repository of reusable assets for machine learning with TensorFlow. In particular, it provides pre-trained SavedModels that can be reused to solve new tasks with less training time and less training data.\n",
        "* You can choose any model from the EfficientDet family , right now you will use [efficientdet-d0](https://tfhub.dev/tensorflow/efficientdet/d0/1) for this notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uFsX02FUgPJw"
      },
      "outputs": [],
      "source": [
        "efficientDet_d0 = 'https://tfhub.dev/tensorflow/efficientdet/d0/1'\n",
        "model = hub.load(efficientDet_d0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uh6Ur1yw9rI8"
      },
      "source": [
        "### Utility Functions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VyhFlWZR3hFg"
      },
      "outputs": [],
      "source": [
        "# COCO-2017 label\n",
        "coco_label = {0:'__background__',1: 'person',2: 'bicycle',3: 'car',4: 'motorcycle',5: 'airplane',6: 'bus',7: 'train',8: 'truck',9: 'boat',\n",
        "              10: 'traffic light',11: 'fire hydrant',12: 'street sign',13: 'stop sign',14: 'parking meter',15: 'bench',16: 'bird',\n",
        "              17: 'cat',18: 'dog',19: 'horse',20: 'sheep',21: 'cow',22: 'elephant',23: 'bear',24: 'zebra',25: 'giraffe',\n",
        "              26: 'hat',27: 'backpack',28: 'umbrella',29: 'shoe',30: 'eye glasses',31: 'handbag',32: 'tie',33: 'suitcase',34: 'frisbee',\n",
        "              35: 'skis',36: 'snowboard',37: 'sports ball',38: 'kite',39: 'baseball bat',40: 'baseball glove',41: 'skateboard',42: 'surfboard',\n",
        "              43: 'tennis racket',44: 'bottle',45: 'plate',46: 'wine glass',47: 'cup',48: 'fork',49: 'knife',50: 'spoon',51: 'bowl',\n",
        "              52: 'banana',53: 'apple',54: 'sandwich',55: 'orange',56: 'broccoli',57: 'carrot',58: 'hot dog',59: 'pizza',60: 'donut',\n",
        "              61: 'cake',62: 'chair',63: 'couch',64: 'potted plant',65: 'bed',66: 'mirror',67: 'dining table',68: 'window',69: 'desk',70: 'toilet',\n",
        "              71: 'door',72: 'tv',73: 'laptop',74: 'mouse',75: 'remote',76: 'keyboard',77: 'cell phone',78: 'microwave',79: 'oven',80: 'toaster',\n",
        "              81: 'sink',82: 'refrigerator',83: 'blender',84: 'book',85: 'clock',86: 'vase',87: 'scissors',88: 'teddy bear',89: 'hair drier',90: 'toothbrush',91: 'hair brush',}\n",
        "\n",
        "label_color = {i: [np.random.randint(0, 255) for _ in range(3)] for i in range(len(coco_label))}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v8i1dPYKAD46"
      },
      "outputs": [],
      "source": [
        "def preprocess_image(path:pathlib.Path):\n",
        "    \"\"\"\n",
        "    Load and preprocess image for EfficientDet model\n",
        "\n",
        "    Parameters:\n",
        "        path (Path) : path of image / URL\n",
        "    Returns:\n",
        "        img (tensor) : input tensor of image after processing\n",
        "    \"\"\"\n",
        "\n",
        "    # loading\n",
        "    img = load_image(path)\n",
        "\n",
        "    # handling grayscale/binary images\n",
        "    if (img.shape[-1]) == 1:\n",
        "        gray = cv2.imread(str(path),cv2.IMREAD_GRAYSCALE)\n",
        "        img = cv2.cvtColor(gray,cv2.COLOR_GRAY2RGB)\n",
        "\n",
        "    else:\n",
        "        img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    h,w,c = img.shape\n",
        "    img = img.reshape([1,h,w,3])\n",
        "    img = tf.cast(img,tf.uint8)\n",
        "\n",
        "    return img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "narmgUdY8ygA"
      },
      "outputs": [],
      "source": [
        "from typing import Dict\n",
        "\n",
        "\n",
        "def visualize(path:pathlib.Path ,pred:Dict ,n_bbox:int = 10,\n",
        "              label:Dict[int,str] = coco_label,label_color:Dict[int,int] = label_color):\n",
        "    \"\"\"\n",
        "    Add Bounding-Box(BBOX) and labels over detected object in image\n",
        "\n",
        "    1) Load image in cv2 for image manipulation\n",
        "    2) Added BBOX and labels(COCO-2017)\n",
        "\n",
        "    Parameters:\n",
        "        cpath (Path) : complete path of image\n",
        "        pred (np.ndarray) : predictions in format [id,x_min,y_min,x_max,y_max,confidence,label]\n",
        "        n_bbox (int) : number of bbox on the image (first n will be choosen)\n",
        "        label (Dict[int,str]) : mapping between class and class name\n",
        "        label_color (Dict[int,int]) : mapping between class and class-drwaing-color\n",
        "\n",
        "    Returns:\n",
        "        im (np.ndarray) : image with bbox and labels\n",
        "    \"\"\"\n",
        "    if not isinstance(pred['detection_scores'],(np.ndarray)):\n",
        "        scores = pred['detection_scores'].numpy().reshape(100)\n",
        "        classes = pred['detection_classes'].numpy().reshape(100)\n",
        "        bboxes = pred['detection_boxes'].numpy().reshape(100,4)\n",
        "    else:\n",
        "        scores = pred['detection_scores'].reshape(100)\n",
        "        classes = pred['detection_classes'].reshape(100)\n",
        "        bboxes = pred['detection_boxes'].reshape(100,4)\n",
        "\n",
        "    img = load_image(path)\n",
        "    img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
        "    h,w,c = img.shape\n",
        "\n",
        "    for i in range(n_bbox):\n",
        "\n",
        "        classs = classes[i]\n",
        "        bbox = bboxes[i]\n",
        "        score = scores[i]\n",
        "\n",
        "        y_min ,x_min ,y_max ,x_max = bbox[0] * h ,bbox[1] * w ,bbox[2] * h ,bbox[3] * w\n",
        "\n",
        "        # adding bbox to image\n",
        "        img = cv2.rectangle(image=img,\n",
        "                            start_point=(round(x_min),round(y_min)),\n",
        "                            end_point=(round(x_max),round(y_max)),\n",
        "                            color=label_color[classs],\n",
        "                            thickness=2)\n",
        "        \n",
        "        # adding label and score over bbox\n",
        "        img = cv2.putText(image=img,\n",
        "                          text=f'{label[classs].upper()} {int(score*100)}%',\n",
        "                          org=(round(x_min),round(y_min)),\n",
        "                          font=cv2.FONT_HERSHEY_SIMPLEX,\n",
        "                          fontScale=1,\n",
        "                          color=label_color[classs],\n",
        "                          thickness=2)\n",
        "        \n",
        "    return img"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PZodQ9i7coq4"
      },
      "source": [
        "#### Verifying Model Inference\n",
        "* Obtaining predictions from the model loaded with tensorflow-hub\n",
        "* Visualizing results by drawing bounding boxes and labels with help of above defined utility function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LOBX9y3Dhw8D"
      },
      "outputs": [],
      "source": [
        "# loading image\n",
        "image = preprocess_image(path='../data/image/coco_bike.jpg')\n",
        "\n",
        "# getting predictions\n",
        "pred = model(image)\n",
        "\n",
        "# visualizing result\n",
        "image_bbox = visualize(path='../data/image/coco_bike.jpg',pred=pred,n_bbox=5)\n",
        "plt.figure(figsize=(6,6))\n",
        "plt.imshow(image_bbox)\n",
        "plt.axis(False)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kg9K3KQ6kejN"
      },
      "outputs": [],
      "source": [
        "# saving model for further processes\n",
        "MODEL_DIR_PATH = pathlib.Path(\"SavedModel\")\n",
        "MODEL_DIR_PATH.mkdir(exist_ok=True)\n",
        "\n",
        "tf.saved_model.save(model,str(MODEL_DIR_PATH))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PUaW4iYoXWpU"
      },
      "source": [
        "### Creating OpenVINO IR (Intermediate Representation) and compiling\n",
        "It is useful to convert your model to IR format to take advantage of OpenVINO optimization tools and features.\n",
        "* Convert TensorFlow model in SavedModel format to OpenVINO IR with the help of the openvino-dev (`mo`) python API.\n",
        "* The above step will create an XML (network topology) and a bin (network weights) file that will be compiled with the OpenVino runtime module."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NOzI1ffvQP2y"
      },
      "outputs": [],
      "source": [
        "IR_PATH = pathlib.Path('IR')\n",
        "IR_PATH.mkdir(exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eyq0rOYEie6D"
      },
      "outputs": [],
      "source": [
        "from openvino.tools import mo\n",
        "from openvino.runtime import serialize\n",
        "\n",
        "model_ir = mo.convert_model(saved_model_dir=str(MODEL_DIR_PATH))\n",
        "serialize(model_ir,'IR/efficientdet.xml')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iBI5_Zy6SVAY"
      },
      "outputs": [],
      "source": [
        "from openvino.runtime import Core\n",
        "core = Core()\n",
        "# read converted model\n",
        "model_ir = core.read_model(model='IR/efficientdet.xml',weights='IR/efficientdet.bin')\n",
        "# load model on CPU device\n",
        "compiled_model = core.compile_model(model_ir, 'CPU')\n",
        "# saving keys of required information\n",
        "output_keys = [compiled_model.output(4),  # CLASS KEY\n",
        "               compiled_model.output(3),  # BBOX KEY\n",
        "               compiled_model.output(6)]  # CONFIDENCE SCORE KEY"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UQZNXziTFl4a"
      },
      "source": [
        "#### Verifying OpenVINO model inference\n",
        "To test model inference, create an inference pipeline with the help of the above-defined utility functions\\\n",
        "The pipeline consists of :-\n",
        "* Preprocessing : You need to perform preprocessing over the image, as the model expects the image to be in RGB, with shape [1,height, width,3] and values in UINT8 format. [ `preprocess_image()` function ]\n",
        "* Inference of OpenVINO model.\n",
        "* Post-processing : Since the model returns a ton of information like `detection_scores` ,`raw_detection_scores` ,`raw_detection_classes` ,`num_detection` , etc. Therefore , you need to post-process results to gather only required information like score (confidence) , classes, and bounding boxes. [ `visualize()` function ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jiWJlHpw0ClT"
      },
      "outputs": [],
      "source": [
        "# loading image\n",
        "IMG_PATH = pathlib.Path('../data/image/coco_bike.jpg')\n",
        "img = preprocess_image(path=str(IMG_PATH))\n",
        "\n",
        "# producing result\n",
        "result = compiled_model([img])\n",
        "result_dict = {'detection_scores':result[output_keys[2]],\n",
        "               'detection_classes':result[output_keys[0]],\n",
        "               'detection_boxes':result[output_keys[1]]}\n",
        "\n",
        "# visualizing result\n",
        "image_bbox = visualize(path='../data/image/coco_bike.jpg',pred=result_dict,n_bbox=5)\n",
        "plt.figure(figsize=(6,6))\n",
        "plt.imshow(image_bbox)\n",
        "plt.axis(False)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jzzxqqpvo88Z"
      },
      "source": [
        "### Verify the Accuracy of the compiled model\n",
        "* Since EfficientDet models are trained with [COCO-2017](https://cocodataset.org/#download) dataset , you will use it to verify accuracy.\n",
        "* To evaluate performance, you will use mAP metric ie. mean Average Precision\n",
        "* To calculate mAP, you will use the COCO official API called [pycocotools](https://github.com/cocodataset/cocoapi/tree/master/PythonAPI/pycocotools)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qszfNIjGcTwB"
      },
      "outputs": [],
      "source": [
        "# Downloading Dataset and labels of COCO-VAL2017\n",
        "\n",
        "from zipfile import ZipFile\n",
        "\n",
        "DATA_URL = \"http://images.cocodataset.org/zips/val2017.zip\"\n",
        "LABELS_URL = \"https://github.com/ultralytics/yolov5/releases/download/v1.0/coco2017labels-segments.zip\"\n",
        "\n",
        "OUT_DIR = pathlib.Path.cwd()\n",
        "\n",
        "if not (OUT_DIR / \"coco/labels\").exists():\n",
        "    download_file(url=DATA_URL)\n",
        "    download_file(url=LABELS_URL)\n",
        "    with ZipFile('coco2017labels-segments.zip' , \"r\") as zip_ref:\n",
        "        zip_ref.extractall(OUT_DIR)\n",
        "    with ZipFile('val2017.zip' , \"r\") as zip_ref:\n",
        "        zip_ref.extractall(OUT_DIR / 'coco/images')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tpp9WfM6-5Qc"
      },
      "outputs": [],
      "source": [
        "from openvino.runtime import Model\n",
        "\n",
        "\n",
        "def write_result(model:Model,image_dir:pathlib.Path,res_file:str,n_images:int = 100):\n",
        "    \"\"\"\n",
        "    Create a JSON file with predictions in COCO format to evalute mAP\n",
        "\n",
        "    Parameters:\n",
        "        model(Model) : openvino \n",
        "        images_dir(Path) : Path of images directory\n",
        "        res_file(str) : result file name \n",
        "        n_images(int) : number of images for which predictions must be wrote (first n)\n",
        "    \n",
        "    Returns:\n",
        "        NONE\n",
        "    \"\"\"\n",
        "    \n",
        "    results = []\n",
        "    images = sorted(pathlib.os.listdir(image_dir))[:n_images]  # first n_images\n",
        "\n",
        "    # loop for finding result for each of n_images\n",
        "    for _,i in enumerate(images, start=1):\n",
        "\n",
        "        complete_path = pathlib.Path(image_dir) / i\n",
        "        img_tensor = preprocess_image(path=str(complete_path))\n",
        "\n",
        "        output_keys = [model.output(4),  # CLASS KEY\n",
        "                       model.output(3),  # BBOX KEY\n",
        "                       model.output(6)]  # CONFIDENCE SCORE KEY\n",
        "\n",
        "        result = model([img_tensor])\n",
        "\n",
        "        cat_ids ,scores, bboxs = result[output_keys[0]][0] , result[output_keys[2]][0] , result[output_keys[1]][0]\n",
        "\n",
        "        for k in range(len(cat_ids)):\n",
        "\n",
        "            __,h,w,c = img_tensor.shape\n",
        "            score , cat_id , bbox = scores[k] , cat_ids[k] , bboxs[k]\n",
        "            y_min ,x_min ,y_max ,x_max = bbox[0] * h ,bbox[1] * w ,bbox[2] * h ,bbox[3] * w\n",
        "\n",
        "            # storing result in COCO format\n",
        "            r = {'score':np.float64(score),\n",
        "                 'image_id':int(i[:len(i) - 4]),\n",
        "                 'category_id':int(cat_id),\n",
        "                 'bbox':list(np.array([x_min, y_min , x_max - x_min, y_max - y_min]).astype(np.float64))}\n",
        "\n",
        "            results.append(r)\n",
        "\n",
        "        if (_ % 10 == 0):\n",
        "            print(f'{_}/{n_images} predictions stored ')\n",
        "    \n",
        "    with open(res_file,'w') as result_file:\n",
        "        json.dump(results,result_file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5LrMRpNk9KjS"
      },
      "source": [
        "##### Evaluating Performance of OpenVINO model\n",
        "* First, you will write the results produced by the model in COCO format in a JSON file with `write_result()` function.\n",
        "* Then you will use COCO official API for model evaluation on the COCO dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "oNS7RLxrInR3",
        "outputId": "3fb0491e-b693-45f3-ca3e-74ff13fc0ac6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10/100 predictions stored \n",
            "20/100 predictions stored \n",
            "30/100 predictions stored \n",
            "40/100 predictions stored \n",
            "50/100 predictions stored \n",
            "60/100 predictions stored \n",
            "70/100 predictions stored \n",
            "80/100 predictions stored \n",
            "90/100 predictions stored \n",
            "100/100 predictions stored \n"
          ]
        }
      ],
      "source": [
        "# writing predictions\n",
        "images_folder = pathlib.Path('coco/images/val2017')\n",
        "result_file = 'result.json'\n",
        "write_result(model=compiled_model,image_dir=images_folder,res_file=result_file,n_images=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "id": "fUr0VKT6mjCD",
        "outputId": "15319af4-1649-4024-b270-e37d05beb575"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loading annotations into memory...\n",
            "Done (t=1.54s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=0.05s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=1.14s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.55s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.397\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.588\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.419\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.184\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.432\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.648\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.367\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.503\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.518\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.214\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.523\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.776\n"
          ]
        }
      ],
      "source": [
        "from pycocotools.coco import COCO\n",
        "from pycocotools.cocoeval import COCOeval\n",
        "\n",
        "annType = 'bbox'\n",
        "\n",
        "cocoGT = COCO('coco/annotations/instances_val2017.json')\n",
        "cocoDT = cocoGT.loadRes('result.json')\n",
        "\n",
        "imgIds = sorted(cocoGT.getImgIds())\n",
        "imgIds = imgIds[0:100]  # using first 100 ids as model is being evaluated on those images only\n",
        "\n",
        "cocoEval = COCOeval(cocoGT,cocoDT,annType)\n",
        "cocoEval.params.imgIds = imgIds\n",
        "cocoEval.evaluate()\n",
        "cocoEval.accumulate()\n",
        "cocoEval.summarize()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Ecj4k4F9cjk"
      },
      "source": [
        "### Optimize model using NNCF Post-training Quantization API [**WILL BE INCLUDED LATER**]\n",
        "<a href='https://github.com/openvinotoolkit/nncf'>NNCF</a> provides a suite of advanced algorithms for Neural Networks inference optimization in OpenVINO with minimal accuracy drop. We will use 8-bit quantization in post-training mode (without the fine-tuning pipeline) to optimize EfficientDet.\n",
        "\n",
        "The optimization process contains the following steps:\n",
        "1. Create Dataset for quantization\n",
        "2. Run `nncf.quantize` for getting optimized model\n",
        "3. Serialize OpenVINO IR model using openvino.runtime.serialize function\n",
        "\n",
        "```python\n",
        "import nncf\n",
        "def transform_fn(data_item):\n",
        "    \"\"\"\n",
        "    Create image tensor for quantization process\n",
        "\n",
        "    Parameters:\n",
        "        data_item : tensorflow dataset object\n",
        "    \n",
        "    Returns:\n",
        "        img(tf.tensor) : tensor of image in shape (1,512,512,3)\n",
        "    \"\"\"\n",
        "    data_item = pathlib.Path(data_item.numpy().decode('UTF8'))\n",
        "    img = preprocess_image(data_item) \n",
        "    return img\n",
        "```\n",
        "```python\n",
        "# creating dataset for accuracy testing\n",
        "dataloader = tf.data.Dataset.list_files('coco/images/val2017/*.jpg',shuffle=False)  # itterable Data Object\n",
        "quantization_dataset = nncf.Dataset(dataloader, transform_fn)\n",
        "\n",
        "# loading original openvino-model for quantization\n",
        "OpenVino_model = core.read_model(model='IR/efficientdet.xml',weights='IR/efficientdet.bin')\n",
        "```\n",
        "```python\n",
        "quantized_model = nncf.quantize(OpenVino_model, quantization_dataset)  \n",
        "# specify `preset` in nncf.quantize() for better result , Default optimizer will be used otherwise\n",
        "\n",
        "serialize(quantized_model,'int8_IR/efficientDet-D0_int8.xml')\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vsUJz3YtoSRN"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}