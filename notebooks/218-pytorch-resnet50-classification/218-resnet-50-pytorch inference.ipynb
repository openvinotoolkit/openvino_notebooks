{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3b94e7b0",
   "metadata": {},
   "source": [
    "# Resnet50 classification with OpenVINO\n",
    "\n",
    "This tutorial demonstrates the use of Resnet50 in OpenVino.The model information could be found [here](https://docs.openvino.ai/latest/omz_models_model_resnest_50_pytorch.html).\n",
    "\n",
    "![diagram](block_digram.jpeg)\n",
    "\n",
    "# What is Resnet?\n",
    "\n",
    "Residual Network (ResNet) is one of the famous deep learning models that was introduced by Shaoqing Ren, Kaiming He, Jian Sun, and Xiangyu Zhang in their paper. The paper was named “Deep Residual Learning for Image Recognition”  in 2015. The ResNet model is one of the popular and most successful deep learning models so far.\n",
    "\n",
    "ResNet50 is a variant of ResNet model which has 48 Convolution layers along with 1 MaxPool and 1 Average Pool layer. It has 3.8 x 10^9 Floating points operations. It is a widely used ResNet model in research.\n",
    "\n",
    "Resnet consist of a residual block architecture. These skip connection help us in solving the degradtion problem that occurs in other convolution based neural network. An example of skip connection is if you are training a neural network and if you pass the output from one of the hidden layer you have received to the other layer, you may notice that the output after passing to the next layer may be degarded compared to the previous output and this can cause the model to have inferior weights. Residual or skip connection helps us solving this problem by comapring the previous output with the current output and if the previous one is better than it will skip the current output and pass it onto the next layer.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99fee7d6",
   "metadata": {},
   "source": [
    "# Preparation\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfbfb7b2",
   "metadata": {},
   "source": [
    "Before working on the model inference, we will first download the resnet-50 model with the help of omz_downloader. If you dont have it installed in your machine, you can install it via this link [here](https://github.com/openvinotoolkit/open_model_zoo/blob/master/tools/model_tools/README.md)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "307c624e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################|| Downloading resnet-50-pytorch ||################\n",
      "\n",
      "========== Downloading /home/rahul/openvino_notebooks/notebooks/218 Pytorch Resnet-50 classification/public/resnet-50-pytorch/resnet50-19c8e357.pth\n",
      "... 100%, 100100 KB, 8108 KB/s, 12 seconds passed\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!omz_downloader --name resnet-50-pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "908e7774",
   "metadata": {},
   "source": [
    "Use the omz_converter to convert the pytorch fp32 model to OpenVino FP32 and FP16 IR format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c75c803",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Converting resnet-50-pytorch to ONNX\n",
      "Conversion to ONNX command: /home/rahul/openvino_env/bin/python -- /home/rahul/openvino_env/lib/python3.8/site-packages/openvino/model_zoo/internal_scripts/pytorch_to_onnx.py --model-name=resnet50 '--weights=/home/rahul/openvino_notebooks/notebooks/218 Pytorch Resnet-50 classification/public/resnet-50-pytorch/resnet50-19c8e357.pth' --import-module=torchvision.models --input-shape=1,3,224,224 '--output-file=/home/rahul/openvino_notebooks/notebooks/218 Pytorch Resnet-50 classification/public/resnet-50-pytorch/resnet-v1-50.onnx' --input-names=data --output-names=prob\n",
      "\n",
      "ONNX check passed successfully.\n",
      "\n",
      "========== Converting resnet-50-pytorch to IR (FP16)\n",
      "Conversion command: /home/rahul/openvino_env/bin/python -- /home/rahul/openvino_env/bin/mo --framework=onnx --data_type=FP16 '--output_dir=/home/rahul/openvino_notebooks/notebooks/218 Pytorch Resnet-50 classification/public/resnet-50-pytorch/FP16' --model_name=resnet-50-pytorch --input=data '--layout=data(NCHW)' '--mean_values=data[123.675,116.28,103.53]' '--scale_values=data[58.395,57.12,57.375]' --reverse_input_channels --output=prob '--input_model=/home/rahul/openvino_notebooks/notebooks/218 Pytorch Resnet-50 classification/public/resnet-50-pytorch/resnet-v1-50.onnx'\n",
      "\n",
      "Model Optimizer arguments:\n",
      "Common parameters:\n",
      "\t- Path to the Input Model: \t/home/rahul/openvino_notebooks/notebooks/218 Pytorch Resnet-50 classification/public/resnet-50-pytorch/resnet-v1-50.onnx\n",
      "\t- Path for generated IR: \t/home/rahul/openvino_notebooks/notebooks/218 Pytorch Resnet-50 classification/public/resnet-50-pytorch/FP16\n",
      "\t- IR output name: \tresnet-50-pytorch\n",
      "\t- Log level: \tERROR\n",
      "\t- Batch: \tNot specified, inherited from the model\n",
      "\t- Input layers: \tdata\n",
      "\t- Output layers: \tprob\n",
      "\t- Input shapes: \tNot specified, inherited from the model\n",
      "\t- Source layout: \tNot specified\n",
      "\t- Target layout: \tNot specified\n",
      "\t- Layout: \tdata(NCHW)\n",
      "\t- Mean values: \tdata[123.675,116.28,103.53]\n",
      "\t- Scale values: \tdata[58.395,57.12,57.375]\n",
      "\t- Scale factor: \tNot specified\n",
      "\t- Precision of IR: \tFP16\n",
      "\t- Enable fusing: \tTrue\n",
      "\t- User transformations: \tNot specified\n",
      "\t- Reverse input channels: \tTrue\n",
      "\t- Enable IR generation for fixed input shape: \tFalse\n",
      "\t- Use the transformations config file: \tNone\n",
      "Advanced parameters:\n",
      "\t- Force the usage of legacy Frontend of Model Optimizer for model conversion into IR: \tFalse\n",
      "\t- Force the usage of new Frontend of Model Optimizer for model conversion into IR: \tFalse\n",
      "OpenVINO runtime found in: \t/home/rahul/openvino_env/lib/python3.8/site-packages/openvino\n",
      "OpenVINO runtime version: \t2022.1.0-6935-7cd3c8e86e9\n",
      "Model Optimizer version: \t2022.1.0-6935-7cd3c8e86e9\n",
      "[ SUCCESS ] Generated IR version 11 model.\n",
      "[ SUCCESS ] XML file: /home/rahul/openvino_notebooks/notebooks/218 Pytorch Resnet-50 classification/public/resnet-50-pytorch/FP16/resnet-50-pytorch.xml\n",
      "[ SUCCESS ] BIN file: /home/rahul/openvino_notebooks/notebooks/218 Pytorch Resnet-50 classification/public/resnet-50-pytorch/FP16/resnet-50-pytorch.bin\n",
      "[ SUCCESS ] Total execution time: 1.08 seconds. \n",
      "[ SUCCESS ] Memory consumed: 280 MB. \n",
      "[ INFO ] The model was converted to IR v11, the latest model format that corresponds to the source DL framework input/output format. While IR v11 is backwards compatible with OpenVINO Inference Engine API v1.0, please use API v2.0 (as of 2022.1) to take advantage of the latest improvements in IR v11.\n",
      "Find more information about API v2.0 and IR v11 at https://docs.openvino.ai\n",
      "\n",
      "========== Converting resnet-50-pytorch to IR (FP32)\n",
      "Conversion command: /home/rahul/openvino_env/bin/python -- /home/rahul/openvino_env/bin/mo --framework=onnx --data_type=FP32 '--output_dir=/home/rahul/openvino_notebooks/notebooks/218 Pytorch Resnet-50 classification/public/resnet-50-pytorch/FP32' --model_name=resnet-50-pytorch --input=data '--layout=data(NCHW)' '--mean_values=data[123.675,116.28,103.53]' '--scale_values=data[58.395,57.12,57.375]' --reverse_input_channels --output=prob '--input_model=/home/rahul/openvino_notebooks/notebooks/218 Pytorch Resnet-50 classification/public/resnet-50-pytorch/resnet-v1-50.onnx'\n",
      "\n",
      "Model Optimizer arguments:\n",
      "Common parameters:\n",
      "\t- Path to the Input Model: \t/home/rahul/openvino_notebooks/notebooks/218 Pytorch Resnet-50 classification/public/resnet-50-pytorch/resnet-v1-50.onnx\n",
      "\t- Path for generated IR: \t/home/rahul/openvino_notebooks/notebooks/218 Pytorch Resnet-50 classification/public/resnet-50-pytorch/FP32\n",
      "\t- IR output name: \tresnet-50-pytorch\n",
      "\t- Log level: \tERROR\n",
      "\t- Batch: \tNot specified, inherited from the model\n",
      "\t- Input layers: \tdata\n",
      "\t- Output layers: \tprob\n",
      "\t- Input shapes: \tNot specified, inherited from the model\n",
      "\t- Source layout: \tNot specified\n",
      "\t- Target layout: \tNot specified\n",
      "\t- Layout: \tdata(NCHW)\n",
      "\t- Mean values: \tdata[123.675,116.28,103.53]\n",
      "\t- Scale values: \tdata[58.395,57.12,57.375]\n",
      "\t- Scale factor: \tNot specified\n",
      "\t- Precision of IR: \tFP32\n",
      "\t- Enable fusing: \tTrue\n",
      "\t- User transformations: \tNot specified\n",
      "\t- Reverse input channels: \tTrue\n",
      "\t- Enable IR generation for fixed input shape: \tFalse\n",
      "\t- Use the transformations config file: \tNone\n",
      "Advanced parameters:\n",
      "\t- Force the usage of legacy Frontend of Model Optimizer for model conversion into IR: \tFalse\n",
      "\t- Force the usage of new Frontend of Model Optimizer for model conversion into IR: \tFalse\n",
      "OpenVINO runtime found in: \t/home/rahul/openvino_env/lib/python3.8/site-packages/openvino\n",
      "OpenVINO runtime version: \t2022.1.0-6935-7cd3c8e86e9\n",
      "Model Optimizer version: \t2022.1.0-6935-7cd3c8e86e9\n",
      "[ SUCCESS ] Generated IR version 11 model.\n",
      "[ SUCCESS ] XML file: /home/rahul/openvino_notebooks/notebooks/218 Pytorch Resnet-50 classification/public/resnet-50-pytorch/FP32/resnet-50-pytorch.xml\n",
      "[ SUCCESS ] BIN file: /home/rahul/openvino_notebooks/notebooks/218 Pytorch Resnet-50 classification/public/resnet-50-pytorch/FP32/resnet-50-pytorch.bin\n",
      "[ SUCCESS ] Total execution time: 1.00 seconds. \n",
      "[ SUCCESS ] Memory consumed: 280 MB. \n",
      "[ INFO ] The model was converted to IR v11, the latest model format that corresponds to the source DL framework input/output format. While IR v11 is backwards compatible with OpenVINO Inference Engine API v1.0, please use API v2.0 (as of 2022.1) to take advantage of the latest improvements in IR v11.\n",
      "Find more information about API v2.0 and IR v11 at https://docs.openvino.ai\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!omz_converter --name resnet-50-pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c78b129",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f320141c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from openvino.runtime import Core\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ccc1443",
   "metadata": {},
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ffee2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = \"CPU\"\n",
    "#MODEL_FILE = \"model_resnet50/resnest-50-pytorch.xml\"\n",
    "MODEL_FILE = \"public/resnet-50-pytorch/FP16/resnet-50-pytorch.xml\"\n",
    "\n",
    "model_xml_path = Path(MODEL_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19c1ec1",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81406708",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_image(data):\n",
    "    image = cv2.cvtColor(cv2.imread(data), code=cv2.COLOR_BGR2RGB)\n",
    "    input_image = cv2.resize(src=image, dsize=(224, 224))\n",
    "    return input_image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec679ec9",
   "metadata": {},
   "source": [
    "# Load the model\n",
    "\n",
    "Load the model in Inference Engine with `ie.read_model` and compile it for the specified device with `ie.compile_model`. Get input and output keys and the expected input shape for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61b6bb80",
   "metadata": {},
   "outputs": [],
   "source": [
    "ie = Core()\n",
    "model = ie.read_model(model=model_xml_path, weights=model_xml_path.with_suffix(\".bin\"))\n",
    "compiled_model = ie.compile_model(model=model, device_name=DEVICE)\n",
    "\n",
    "# The input key contains information and shape of the model input\n",
    "input_key = next(iter(compiled_model.inputs))\n",
    "\n",
    "# The output key contains information and shape of the model output\n",
    "output_key = next(iter(compiled_model.outputs))\n",
    "\n",
    "network_input_shape = list(input_key.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a534b6d",
   "metadata": {},
   "source": [
    "# Load,Resize and reshape the Image\n",
    "The input image is read with OpenCV, resized to network input size, and reshaped to (N,C,H,W) (N=number of images,  C=number of channels, H=height, W=width). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55bccd75",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_NAME = 'data/hammer.jpg'\n",
    "\n",
    "# resize to input shape for network\n",
    "resized_image = resize_image(IMAGE_NAME)\n",
    "\n",
    "# reshape image to network input shape NCHW\n",
    "input_image = np.expand_dims(np.transpose(resized_image, (2, 0, 1)), 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e9ece67",
   "metadata": {},
   "source": [
    "### Do inference on image\n",
    "Pass the image for inference to the model, get the output and use np.argmax to extract the most probable class.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eafab9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_infer = compiled_model(inputs=[input_image])[output_key]\n",
    "result_index = np.argmax(result_infer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80264dbb",
   "metadata": {},
   "source": [
    "### Get output Label\n",
    "\n",
    "Pass on the output model label extacted from the output array to the imagenet class list to get the label file\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd3359be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the inference result to a class name.\n",
    "imagenet_classes = open(\"imagenet_1000.txt\").read().splitlines()\n",
    "\n",
    "\n",
    "output = imagenet_classes[result_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "862110f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the output class label is  =  hammerhead, hammerhead shark\n"
     ]
    }
   ],
   "source": [
    "print('the output class label is  = ',output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1ca30f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openvino_env",
   "language": "python",
   "name": "openvino_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
