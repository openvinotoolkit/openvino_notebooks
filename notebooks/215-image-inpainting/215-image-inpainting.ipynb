{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9c2cbeb-fe8b-4e09-9432-4f4f4bfddc9c",
   "metadata": {},
   "source": [
    "## Image In-painting with OpenVINOâ„¢\n",
    "This notebook demonstrates how to use an image in-painting model with OpenVINO, using [GMCNN model](https://github.com/shepnerd/inpainting_gmcnn) from [Open Model Zoo](https://github.com/openvinotoolkit/open_model_zoo/). This model, given a tampered image, is able to create something very similar to the original image. The Following pipeline will be used in this notebook.\n",
    "![pipeline](https://user-images.githubusercontent.com/4547501/165792473-ba784c0d-0a37-409f-a5f6-bb1849c1d140.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb231ad5-4fd9-4eb2-bf6b-6c1e511a4d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from openvino.runtime import Core\n",
    "\n",
    "sys.path.append(\"../utils\")\n",
    "import notebook_utils as utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6815624-1f04-4110-8f3e-1da9f1a02cf8",
   "metadata": {},
   "source": [
    "### Download the Model\n",
    "Models can be downloaded with `omz_downloader` - a command-line tool for downloading models from the Open Model Zoo. `gmcnn-places2-tf` is the omz name for the considered model. You can find the names of all available models [here](https://github.com/openvinotoolkit/open_model_zoo/blob/master/models/public/index.md) and [here](https://github.com/openvinotoolkit/open_model_zoo/blob/master/models/intel/index.md). The selected model comes from the public directory, which means it must be converted into Intermediate Representation (IR). This step is skipped if the model is already downloaded.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507f58c9-fd68-46b8-9476-127add5cbbc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A directory where the model will be downloaded.\n",
    "base_model_dir = \"model\"\n",
    "# The name of the model from Open Model Zoo.\n",
    "model_name = \"gmcnn-places2-tf\"\n",
    "\n",
    "model_path = Path(f\"{base_model_dir}/public/{model_name}/{model_name}/frozen_model.pb\")\n",
    "if not model_path.exists():\n",
    "    download_command = f\"omz_downloader \" \\\n",
    "                       f\"--name {model_name} \" \\\n",
    "                       f\"--output_dir {base_model_dir}\"\n",
    "    ! $download_command\n",
    "else:\n",
    "    print(\"Already downloaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e649526-4cd8-41fd-9b48-3590f02b5a63",
   "metadata": {},
   "source": [
    "### Convert Tensorflow model to OpenVINO IR format\n",
    "\n",
    "The pre-trained model is in TensorFlow format. To use it with OpenVINO, convert it to OpenVINO IR format. To do this, use Model Converter (`omz_converter`), which is another command-line tool. Then, specify the precision for `FP32` but it can be `FP16` as well. This step is also skipped if the model is already converted.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60b11d7-b3a4-4e2b-bf99-7de0c8eda6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = \"FP32\"\n",
    "ir_path = Path(f\"{base_model_dir}/public/{model_name}/{precision}/{model_name}.xml\")\n",
    "\n",
    "# Run Model Optimizer if the OpenVINO IR model file does not exist.\n",
    "if not ir_path.exists():\n",
    "    print(\"Exporting TensorFlow model to IR... This may take a few minutes.\")\n",
    "    convert_command = f\"omz_converter \" \\\n",
    "                      f\"--name {model_name} \" \\\n",
    "                      f\"--download_dir {base_model_dir} \" \\\n",
    "                      f\"--precisions {precision}\"\n",
    "    ! $convert_command\n",
    "else:\n",
    "    print(\"IR model already exists.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5020e38a-0537-4243-b716-b12e5e21e62b",
   "metadata": {},
   "source": [
    "### Load the model\n",
    "\n",
    "Now, load the OpenVINO IR model and perform as follows:\n",
    "\n",
    " 1. Initialize OpenVINO Runtime (Core).\n",
    " 2. Read the network from `*.bin` and `*.xml` files (weights and architecture)\n",
    " 3. Compile the model for the \"CPU\".\n",
    " 4. Get input and output nodes.\n",
    "\n",
    "Only a few lines of code are required to run the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc07099e-76a2-497b-97b4-2b83ba8e2950",
   "metadata": {},
   "outputs": [],
   "source": [
    "core = Core()\n",
    "\n",
    "# Read the model.xml and weights file\n",
    "model = core.read_model(model=ir_path)\n",
    "# Load the model on to the CPU\n",
    "compiled_model = core.compile_model(model=model, device_name=\"CPU\")\n",
    "# Store the input and output nodes\n",
    "input_layer = compiled_model.input(0)\n",
    "output_layer = compiled_model.output(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93076d61-68d9-4c44-b73d-9ac687560eb5",
   "metadata": {},
   "source": [
    "### Determine the input shapes of the model\n",
    "\n",
    "Note that both input shapes are the same. However, the second input has 1 channel (monotone)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2606632b-41a3-41e4-88ae-935029ec87df",
   "metadata": {},
   "outputs": [],
   "source": [
    "N, H, W, C = input_layer.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b641584-e018-49ce-a7df-f48d1eae1d52",
   "metadata": {},
   "source": [
    "### Create a square mask\n",
    "\n",
    "Next, create a single channeled mask that will be laid on top of the original image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885c49ff-34bc-476e-b47b-9dd37e4edc50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mask(image_width, image_height, size_x=30, size_y=30, number=1):\n",
    "    \"\"\"\n",
    "    Create a square mask of defined size on a random location.\n",
    "\n",
    "    :param: image_width: width of the image\n",
    "    :param: image_height: height of the image\n",
    "    :param: size: size in pixels of one side\n",
    "    :returns:\n",
    "            mask: grayscale float32 mask of size shaped [image_height, image_width, 1]\n",
    "    \"\"\"\n",
    "\n",
    "    mask = np.zeros((image_height, image_width, 1), dtype=np.float32)\n",
    "    for _ in range(number):\n",
    "        start_x = np.random.randint(image_width - size_x)\n",
    "        start_y = np.random.randint(image_height - size_y)\n",
    "        cv2.rectangle(img=mask,\n",
    "                      pt1=(start_x, start_y),\n",
    "                      pt2=(start_x + size_x, start_y + size_y),\n",
    "                      color=(1, 1, 1),\n",
    "                      thickness=cv2.FILLED)\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54d4d89-e7e4-46f7-b58f-858c2f8474c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a square mask of size WxH with number of \"holes\".\n",
    "mask = create_mask(image_width=W, image_height=H, size_x=50, size_y=50, number=15)\n",
    "# This mask will be laid over the input image as noise.\n",
    "plt.figure(figsize=(16, 12))\n",
    "plt.imshow(cv2.cvtColor(mask, cv2.COLOR_BGR2RGB));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2561cfd2-f1ac-4121-99ad-019c174a10a8",
   "metadata": {},
   "source": [
    "### Load and Resize the Image\n",
    "\n",
    "This image will be altered by using the mask. You can process any image you like. Just change the URL below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ce844f-35c0-4594-a4d4-c8fb1946c7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download an image.\n",
    "url = \"https://www.intel.com/content/dam/www/central-libraries/us/en/images/arc-home-hero-128.png.rendition.intel.web.480.360.png\"\n",
    "image_file = utils.download_file(\n",
    "    url, filename=\"laptop.png\", directory=\"data\", show_progress=False, silent=True, timeout=30\n",
    ")\n",
    "assert Path(image_file).exists()\n",
    "\n",
    "# Read the image.\n",
    "image = cv2.imread(\"data/laptop.png\")\n",
    "# Resize the image to meet network expected input sizes.\n",
    "resized_image = cv2.resize(src=image, dsize=(W, H), interpolation=cv2.INTER_AREA)\n",
    "plt.figure(figsize=(16, 12))\n",
    "plt.imshow(cv2.cvtColor(resized_image, cv2.COLOR_BGR2RGB));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af065568-7487-4cd8-9ca2-2343c9ccab3a",
   "metadata": {},
   "source": [
    "### Generating the Masked Image\n",
    "\n",
    "This multiplication of the image and the mask gives the result of the masked image layered on top of the original image. The `masked_image` will be the first input to the GMCNN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f93f1d1-a698-4583-989c-8c7b7bcdfafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating a masked image.\n",
    "masked_image = (resized_image * (1 - mask) + 255 * mask).astype(np.uint8)\n",
    "plt.figure(figsize=(16, 12))\n",
    "plt.imshow(cv2.cvtColor(masked_image, cv2.COLOR_BGR2RGB));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3807058c-dfbe-49cd-8dc1-7008c940b529",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "\n",
    "The model expects the input dimensions to be `NHWC`.\n",
    "\n",
    "- masked_image.shape = (512,680,3) -----> model expects = (1,512,680,3)\n",
    "- resized_mask.shape = (512,680,1) -----> model expects = (1,512,680,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45b4418",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "masked_image = masked_image[None, ...]\n",
    "mask = mask[None, ...]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006e5086",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Inference\n",
    "\n",
    "Do inference with the given masked image and the mask. Then, show the restored image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31410a7c-54d0-471c-9bf3-24d6cf9e4ec5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "result = compiled_model([masked_image, mask])[output_layer]\n",
    "result = result.squeeze().astype(np.uint8)\n",
    "plt.figure(figsize=(16, 12))\n",
    "plt.imshow(cv2.cvtColor(result, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "784da925",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Save the Restored Image\n",
    "\n",
    "Save the restored image to the data directory to download it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bdf9e7f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cv2.imwrite(\"data/laptop_restored.png\", result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
