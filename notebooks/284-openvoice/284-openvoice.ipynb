{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OpenVoice is a versatile instant voice tone transfering and generating speech in various languages with just a brief audio snippet from the source speaker. OpenVoice has three main features: (i) high quality tone color replication with multiple languages and accents; (ii) it provides fine-tuned control over voice styles, including emotions, accents, as well as other parameters such as rhythm, pauses, and intonation. (iii) OpenVoice achieves zero-shot cross-lingual voice cloning, eliminating the need for the generated speech and the reference speech to be part of a massive-speaker multilingual training dataset.\n",
    "\n",
    "![sdf](openvoice_scheme.png)\n",
    "\n",
    "More details about model can be found in [project web page](https://research.myshell.ai/open-voice), [paper](https://arxiv.org/abs/2312.01479), and official [repository](https://github.com/myshell-ai/OpenVoice)\n",
    "\n",
    "This notebooks provides example of converting original OpenVoice model (https://github.com/myshell-ai/OpenVoice) to OpenVINO IR format for faster inference.\n",
    "\n",
    "In this tutorial we will explore how to convert and run OpenVoice using OpenVINO.\n",
    "#### Table of contents:\n",
    "- [Clone repository and install requirements](#Clone-repository-and-install-requirements)\n",
    "- [Download checkpoints and load PyTorch model](#Download-checkpoints-and-load-PyTorch-model)\n",
    "- [Convert Models to OpenVINO IR](#Convert-Models-to-OpenVINO-IR)\n",
    "- [Inference](#Inference)\n",
    "    - [Select inference device](#Select-inference-device)\n",
    "    - [Select reference tone](#Select-reference-tone)\n",
    "    - [Run inference](#Run-inference)\n",
    "- [Run OpenVoice Gradio online app](#Run-OpenVoice-Gradio-online-app)\n",
    "- [Cleanup](#Cleanup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clone repository and install requirements\n",
    "[back to top ⬆️](#Table-of-contents:)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/epavel/devel/openvino_notebooks/notebooks/284-openvoice/OpenVoice\n",
      "Requirement already satisfied: openvino>=2023.3 in /home/epavel/opt/envs/py310-openvoice/lib/python3.10/site-packages (2023.3.0)\n",
      "Requirement already satisfied: librosa>=0.9.1 in /home/epavel/opt/envs/py310-openvoice/lib/python3.10/site-packages (0.9.1)\n",
      "Requirement already satisfied: wavmark>=0.0.3 in /home/epavel/opt/envs/py310-openvoice/lib/python3.10/site-packages (0.0.3)\n",
      "Requirement already satisfied: faster-whisper>=0.9.0 in /home/epavel/opt/envs/py310-openvoice/lib/python3.10/site-packages (0.9.0)\n",
      "Requirement already satisfied: pydub>=0.25.1 in /home/epavel/opt/envs/py310-openvoice/lib/python3.10/site-packages (0.25.1)\n",
      "Requirement already satisfied: whisper-timestamped>=1.14.2 in /home/epavel/opt/envs/py310-openvoice/lib/python3.10/site-packages (1.14.2)\n",
      "Requirement already satisfied: tqdm in /home/epavel/opt/envs/py310-openvoice/lib/python3.10/site-packages (4.66.1)\n",
      "Requirement already satisfied: inflect>=7.0.0 in /home/epavel/opt/envs/py310-openvoice/lib/python3.10/site-packages (7.0.0)\n",
      "Requirement already satisfied: unidecode>=1.3.7 in /home/epavel/opt/envs/py310-openvoice/lib/python3.10/site-packages (1.3.7)\n",
      "Requirement already satisfied: eng_to_ipa>=0.0.2 in /home/epavel/opt/envs/py310-openvoice/lib/python3.10/site-packages (0.0.2)\n",
      "Requirement already satisfied: pypinyin>=0.50.0 in /home/epavel/opt/envs/py310-openvoice/lib/python3.10/site-packages (0.50.0)\n",
      "Requirement already satisfied: cn2an>=0.5.22 in /home/epavel/opt/envs/py310-openvoice/lib/python3.10/site-packages (0.5.22)\n",
      "Requirement already satisfied: jieba>=0.42.1 in /home/epavel/opt/envs/py310-openvoice/lib/python3.10/site-packages (0.42.1)\n",
      "Requirement already satisfied: langid>=1.1.6 in /home/epavel/opt/envs/py310-openvoice/lib/python3.10/site-packages (1.1.6)\n",
      "Requirement already satisfied: gradio>=4.15 in /home/epavel/opt/envs/py310-openvoice/lib/python3.10/site-packages (4.15.0)\n",
      "Requirement already satisfied: ipywebrtc in /home/epavel/opt/envs/py310-openvoice/lib/python3.10/site-packages (0.6.0)\n",
      "Requirement already satisfied: numpy>=1.16.6 in /home/epavel/opt/envs/py310-openvoice/lib/python3.10/site-packages (from openvino>=2023.3) (1.23.4)\n",
      "Requirement already satisfied: openvino-telemetry>=2023.2.1 in /home/epavel/opt/envs/py310-openvoice/lib/python3.10/site-packages (from openvino>=2023.3) (2023.2.1)\n",
      "Requirement already satisfied: audioread>=2.1.5 in /home/epavel/opt/envs/py310-openvoice/lib/python3.10/site-packages (from librosa>=0.9.1) (3.0.1)\n",
      "Requirement already satisfied: scipy>=1.2.0 in /home/epavel/opt/envs/py310-openvoice/lib/python3.10/site-packages (from librosa>=0.9.1) (1.12.0)\n",
      "Requirement already satisfied: scikit-learn>=0.19.1 in /home/epavel/opt/envs/py310-openvoice/lib/python3.10/site-packages (from librosa>=0.9.1) (1.4.0)\n",
      "Requirement already satisfied: joblib>=0.14 in /home/epavel/opt/envs/py310-openvoice/lib/python3.10/site-packages (from librosa>=0.9.1) (1.3.2)\n",
      "Requirement already satisfied: decorator>=4.0.10 in /home/epavel/opt/envs/py310-openvoice/lib/python3.10/site-packages (from librosa>=0.9.1) (5.1.1)\n",
      "Requirement already satisfied: resampy>=0.2.2 in /home/epavel/opt/envs/py310-openvoice/lib/python3.10/site-packages (from librosa>=0.9.1) (0.4.2)\n",
      "Requirement already satisfied: numba>=0.45.1 in /home/epavel/opt/envs/py310-openvoice/lib/python3.10/site-packages (from librosa>=0.9.1) (0.58.1)\n",
      "Requirement already satisfied: soundfile>=0.10.2 in /home/epavel/opt/envs/py310-openvoice/lib/python3.10/site-packages (from librosa>=0.9.1) (0.12.1)\n",
      "Requirement already satisfied: pooch>=1.0 in /home/epavel/opt/envs/py310-openvoice/lib/python3.10/site-packages (from librosa>=0.9.1) (1.8.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/epavel/opt/envs/py310-openvoice/lib/python3.10/site-packages (from librosa>=0.9.1) (23.2)\n",
      "Requirement already satisfied: huggingface-hub in /home/epavel/opt/envs/py310-openvoice/lib/python3.10/site-packages (from wavmark>=0.0.3) (0.20.3)\n",
      "Requirement already satisfied: torch in /home/epavel/opt/envs/py310-openvoice/lib/python3.10/site-packages (from wavmark>=0.0.3) (2.1.0+cpu)\n",
      "Requirement already satisfied: torchaudio in /home/epavel/opt/envs/py310-openvoice/lib/python3.10/site-packages (from wavmark>=0.0.3) (2.1.0+cpu)\n",
      "Requirement already satisfied: av==10.* in /home/epavel/opt/envs/py310-openvoice/lib/python3.10/site-packages (from faster-whisper>=0.9.0) (10.0.0)\n",
      "Requirement already satisfied: ctranslate2<4,>=3.17 in /home/epavel/opt/envs/py310-openvoice/lib/python3.10/site-packages (from faster-whisper>=0.9.0) (3.24.0)\n",
      "Requirement already satisfied: tokenizers<0.15,>=0.13 in /home/epavel/opt/envs/py310-openvoice/lib/python3.10/site-packages (from faster-whisper>=0.9.0) (0.13.3)\n",
      "Requirement already satisfied: onnxruntime<2,>=1.14 in /home/epavel/opt/envs/py310-openvoice/lib/python3.10/site-packages (from faster-whisper>=0.9.0) (1.16.3)\n",
      "Requirement already satisfied: Cython in /home/epavel/opt/envs/py310-openvoice/lib/python3.10/site-packages (from whisper-timestamped>=1.14.2) (3.0.8)\n",
      "Requirement already satisfied: dtw-python in /home/epavel/opt/envs/py310-openvoice/lib/python3.10/site-packages (from whisper-timestamped>=1.14.2) (1.3.1)\n",
      "Requirement already satisfied: openai-whisper in /home/epavel/opt/envs/py310-openvoice/lib/python3.10/site-packages (from whisper-timestamped>=1.14.2) (20231117)\n",
      "Requirement already satisfied: pydantic>=1.9.1 in /home/epavel/opt/envs/py310-openvoice/lib/python3.10/site-packages (from inflect>=7.0.0) (2.5.3)\n",
      "Requirement already satisfied: typing-extensions in /home/epavel/opt/envs/py310-openvoice/lib/python3.10/site-packages (from inflect>=7.0.0) (4.9.0)\n",
      "Requirement already satisfied: setuptools>=47.3.1 in /home/epavel/opt/envs/py310-openvoice/lib/python3.10/site-packages (from cn2an>=0.5.22) (69.0.3)\n",
      "Requirement already satisfied: proces>=0.1.3 in /home/epavel/opt/envs/py310-openvoice/lib/python3.10/site-packages (from cn2an>=0.5.22) (0.1.7)\n",
      "Requirement already satisfied: aiofiles<24.0,>=22.0 in /home/epavel/opt/envs/py310-openvoice/lib/python3.10/site-packages (from gradio>=4.15) (23.2.1)\n",
      "Requirement already satisfied: altair<6.0,>=4.2.0 in /home/epavel/opt/envs/py310-openvoice/lib/python3.10/site-packages (from gradio>=4.15) (5.2.0)\n",
      "Requirement already satisfied: fastapi in /home/epavel/opt/envs/py310-openvoice/lib/python3.10/site-packages (from gradio>=4.15) (0.109.0)\n",
      "Requirement already satisfied: ffmpy in /home/epavel/opt/envs/py310-openvoice/lib/python3.10/site-packages (from gradio>=4.15) (0.3.1)\n",
      "Requirement already satisfied: gradio-client==0.8.1 in /home/epavel/opt/envs/py310-openvoice/lib/python3.10/site-packages (from gradio>=4.15) (0.8.1)\n",
      "Requirement already satisfied: httpx in /home/epavel/opt/envs/py310-openvoice/lib/python3.10/site-packages (from gradio>=4.15) (0.26.0)\n",
      "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /home/epavel/opt/envs/py310-openvoice/lib/python3.10/site-packages (from gradio>=4.15) (6.1.1)\n",
      "Requirement already satisfied: jinja2<4.0 in /home/epavel/opt/envs/py310-openvoice/lib/python3.10/site-packages (from gradio>=4.15) (3.1.3)\n",
      "Requirement already satisfied: markupsafe~=2.0 in /home/epavel/opt/envs/py310-openvoice/lib/python3.10/site-packages (from gradio>=4.15) (2.1.4)\n",
      "Requirement already satisfied: matplotlib~=3.0 in /home/epavel/opt/envs/py310-openvoice/lib/python3.10/site-packages (from gradio>=4.15) (3.8.2)\n",
      "Requirement already satisfied: orjson~=3.0 in /home/epavel/opt/envs/py310-openvoice/lib/python3.10/site-packages (from gradio>=4.15) (3.9.12)\n",
      "Requirement already satisfied: pandas<3.0,>=1.0 in /home/epavel/opt/envs/py310-openvoice/lib/python3.10/site-packages (from gradio>=4.15) (2.0.3)\n",
      "Requirement already satisfied: pillow<11.0,>=8.0 in /home/epavel/opt/envs/py310-openvoice/lib/python3.10/site-packages (from gradio>=4.15) (10.2.0)\n",
      "Requirement already satisfied: python-multipart in /home/epavel/opt/envs/py310-openvoice/lib/python3.10/site-packages (from gradio>=4.15) (0.0.6)\n",
      "Requirement already satisfied: pyyaml<7.0,>=5.0 in /home/epavel/opt/envs/py310-openvoice/lib/python3.10/site-packages (from gradio>=4.15) (6.0.1)\n",
      "Requirement already satisfied: ruff>=0.1.7 in /home/epavel/opt/envs/py310-openvoice/lib/python3.10/site-packages (from gradio>=4.15) (0.1.14)\n",
      "Requirement already satisfied: semantic-version~=2.0 in /home/epavel/opt/envs/py310-openvoice/lib/python3.10/site-packages (from gradio>=4.15) (2.10.0)\n",
      "Requirement already satisfied: tomlkit==0.12.0 in /home/epavel/opt/envs/py310-openvoice/lib/python3.10/site-packages (from gradio>=4.15) (0.12.0)\n",
      "Requirement already satisfied: typer<1.0,>=0.9 in /home/epavel/opt/envs/py310-openvoice/lib/python3.10/site-packages (from typer[all]<1.0,>=0.9->gradio>=4.15) (0.9.0)\n",
      "Requirement already satisfied: uvicorn>=0.14.0 in /home/epavel/opt/envs/py310-openvoice/lib/python3.10/site-packages (from gradio>=4.15) (0.27.0)\n",
      "Requirement already satisfied: fsspec in /home/epavel/opt/envs/py310-openvoice/lib/python3.10/site-packages (from gradio-client==0.8.1->gradio>=4.15) (2023.12.2)\n",
      "Requirement already satisfied: websockets<12.0,>=10.0 in /home/epavel/opt/envs/py310-openvoice/lib/python3.10/site-packages (from gradio-client==0.8.1->gradio>=4.15) (11.0.3)\n",
      "Requirement already satisfied: jsonschema>=3.0 in /home/epavel/opt/envs/py310-openvoice/lib/python3.10/site-packages (from altair<6.0,>=4.2.0->gradio>=4.15) (4.21.1)\n",
      "Requirement already satisfied: toolz in /home/epavel/opt/envs/py310-openvoice/lib/python3.10/site-packages (from altair<6.0,>=4.2.0->gradio>=4.15) (0.12.1)\n",
      "Requirement already satisfied: filelock in /home/epavel/opt/envs/py310-openvoice/lib/python3.10/site-packages (from huggingface-hub->wavmark>=0.0.3) (3.13.1)\n",
      "Requirement already satisfied: requests in /home/epavel/opt/envs/py310-openvoice/lib/python3.10/site-packages (from huggingface-hub->wavmark>=0.0.3) (2.31.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/epavel/opt/envs/py310-openvoice/lib/python3.10/site-packages (from matplotlib~=3.0->gradio>=4.15) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/epavel/opt/envs/py310-openvoice/lib/python3.10/site-packages (from matplotlib~=3.0->gradio>=4.15) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/epavel/opt/envs/py310-openvoice/lib/python3.10/site-packages (from matplotlib~=3.0->gradio>=4.15) (4.47.2)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/epavel/opt/envs/py310-openvoice/lib/python3.10/site-packages (from matplotlib~=3.0->gradio>=4.15) (1.4.5)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/epavel/opt/envs/py310-openvoice/lib/python3.10/site-packages (from matplotlib~=3.0->gradio>=4.15) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/epavel/opt/envs/py310-openvoice/lib/python3.10/site-packages (from matplotlib~=3.0->gradio>=4.15) (2.8.2)\n",
      "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /home/epavel/opt/envs/py310-openvoice/lib/python3.10/site-packages (from numba>=0.45.1->librosa>=0.9.1) (0.41.1)\n",
      "Requirement already satisfied: coloredlogs in /home/epavel/opt/envs/py310-openvoice/lib/python3.10/site-packages (from onnxruntime<2,>=1.14->faster-whisper>=0.9.0) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in /home/epavel/opt/envs/py310-openvoice/lib/python3.10/site-packages (from onnxruntime<2,>=1.14->faster-whisper>=0.9.0) (23.5.26)\n",
      "Requirement already satisfied: protobuf in /home/epavel/opt/envs/py310-openvoice/lib/python3.10/site-packages (from onnxruntime<2,>=1.14->faster-whisper>=0.9.0) (4.25.2)\n",
      "Requirement already satisfied: sympy in /home/epavel/opt/envs/py310-openvoice/lib/python3.10/site-packages (from onnxruntime<2,>=1.14->faster-whisper>=0.9.0) (1.12)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/epavel/opt/envs/py310-openvoice/lib/python3.10/site-packages (from pandas<3.0,>=1.0->gradio>=4.15) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/epavel/opt/envs/py310-openvoice/lib/python3.10/site-packages (from pandas<3.0,>=1.0->gradio>=4.15) (2023.4)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /home/epavel/opt/envs/py310-openvoice/lib/python3.10/site-packages (from pooch>=1.0->librosa>=0.9.1) (4.1.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/epavel/opt/envs/py310-openvoice/lib/python3.10/site-packages (from pydantic>=1.9.1->inflect>=7.0.0) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.6 in /home/epavel/opt/envs/py310-openvoice/lib/python3.10/site-packages (from pydantic>=1.9.1->inflect>=7.0.0) (2.14.6)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/epavel/opt/envs/py310-openvoice/lib/python3.10/site-packages (from scikit-learn>=0.19.1->librosa>=0.9.1) (3.2.0)\n",
      "Requirement already satisfied: cffi>=1.0 in /home/epavel/opt/envs/py310-openvoice/lib/python3.10/site-packages (from soundfile>=0.10.2->librosa>=0.9.1) (1.16.0)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /home/epavel/opt/envs/py310-openvoice/lib/python3.10/site-packages (from typer<1.0,>=0.9->typer[all]<1.0,>=0.9->gradio>=4.15) (8.1.7)\n",
      "Requirement already satisfied: colorama<0.5.0,>=0.4.3 in /home/epavel/opt/envs/py310-openvoice/lib/python3.10/site-packages (from typer[all]<1.0,>=0.9->gradio>=4.15) (0.4.6)\n",
      "Requirement already satisfied: shellingham<2.0.0,>=1.3.0 in /home/epavel/opt/envs/py310-openvoice/lib/python3.10/site-packages (from typer[all]<1.0,>=0.9->gradio>=4.15) (1.5.4)\n",
      "Requirement already satisfied: rich<14.0.0,>=10.11.0 in /home/epavel/opt/envs/py310-openvoice/lib/python3.10/site-packages (from typer[all]<1.0,>=0.9->gradio>=4.15) (13.7.0)\n",
      "Requirement already satisfied: h11>=0.8 in /home/epavel/opt/envs/py310-openvoice/lib/python3.10/site-packages (from uvicorn>=0.14.0->gradio>=4.15) (0.14.0)\n",
      "Requirement already satisfied: starlette<0.36.0,>=0.35.0 in /home/epavel/opt/envs/py310-openvoice/lib/python3.10/site-packages (from fastapi->gradio>=4.15) (0.35.1)\n",
      "Requirement already satisfied: anyio in /home/epavel/opt/envs/py310-openvoice/lib/python3.10/site-packages (from httpx->gradio>=4.15) (4.2.0)\n",
      "Requirement already satisfied: certifi in /home/epavel/opt/envs/py310-openvoice/lib/python3.10/site-packages (from httpx->gradio>=4.15) (2023.11.17)\n",
      "Requirement already satisfied: httpcore==1.* in /home/epavel/opt/envs/py310-openvoice/lib/python3.10/site-packages (from httpx->gradio>=4.15) (1.0.2)\n",
      "Requirement already satisfied: idna in /home/epavel/opt/envs/py310-openvoice/lib/python3.10/site-packages (from httpx->gradio>=4.15) (3.6)\n",
      "Requirement already satisfied: sniffio in /home/epavel/opt/envs/py310-openvoice/lib/python3.10/site-packages (from httpx->gradio>=4.15) (1.3.0)\n",
      "Requirement already satisfied: triton<3,>=2.0.0 in /home/epavel/opt/envs/py310-openvoice/lib/python3.10/site-packages (from openai-whisper->whisper-timestamped>=1.14.2) (2.2.0)\n",
      "Requirement already satisfied: more-itertools in /home/epavel/opt/envs/py310-openvoice/lib/python3.10/site-packages (from openai-whisper->whisper-timestamped>=1.14.2) (10.2.0)\n",
      "Requirement already satisfied: tiktoken in /home/epavel/opt/envs/py310-openvoice/lib/python3.10/site-packages (from openai-whisper->whisper-timestamped>=1.14.2) (0.5.2)\n",
      "Requirement already satisfied: networkx in /home/epavel/opt/envs/py310-openvoice/lib/python3.10/site-packages (from torch->wavmark>=0.0.3) (2.8.2)\n",
      "Requirement already satisfied: pycparser in /home/epavel/opt/envs/py310-openvoice/lib/python3.10/site-packages (from cffi>=1.0->soundfile>=0.10.2->librosa>=0.9.1) (2.21)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /home/epavel/opt/envs/py310-openvoice/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio>=4.15) (23.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /home/epavel/opt/envs/py310-openvoice/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio>=4.15) (2023.12.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /home/epavel/opt/envs/py310-openvoice/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio>=4.15) (0.32.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /home/epavel/opt/envs/py310-openvoice/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio>=4.15) (0.17.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/epavel/opt/envs/py310-openvoice/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio>=4.15) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/epavel/opt/envs/py310-openvoice/lib/python3.10/site-packages (from requests->huggingface-hub->wavmark>=0.0.3) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/epavel/opt/envs/py310-openvoice/lib/python3.10/site-packages (from requests->huggingface-hub->wavmark>=0.0.3) (2.1.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/epavel/opt/envs/py310-openvoice/lib/python3.10/site-packages (from rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio>=4.15) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/epavel/opt/envs/py310-openvoice/lib/python3.10/site-packages (from rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio>=4.15) (2.17.2)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/epavel/opt/envs/py310-openvoice/lib/python3.10/site-packages (from anyio->httpx->gradio>=4.15) (1.2.0)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /home/epavel/opt/envs/py310-openvoice/lib/python3.10/site-packages (from coloredlogs->onnxruntime<2,>=1.14->faster-whisper>=0.9.0) (10.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/epavel/opt/envs/py310-openvoice/lib/python3.10/site-packages (from sympy->onnxruntime<2,>=1.14->faster-whisper>=0.9.0) (1.3.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /home/epavel/opt/envs/py310-openvoice/lib/python3.10/site-packages (from tiktoken->openai-whisper->whisper-timestamped>=1.14.2) (2023.12.25)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/epavel/opt/envs/py310-openvoice/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio>=4.15) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "repo_dir = Path(\"OpenVoice\")\n",
    "\n",
    "if not repo_dir.exists():\n",
    "    !git clone https://github.com/myshell-ai/OpenVoice\n",
    "\n",
    "# cd to the original repo to save original data paths and imports\n",
    "%cd $repo_dir\n",
    "\n",
    "%pip install \"openvino>=2023.3\" \\\n",
    "\"librosa>=0.9.1\" \\\n",
    "\"wavmark>=0.0.3\" \\\n",
    "\"faster-whisper>=0.9.0\" \\\n",
    "\"pydub>=0.25.1\" \\\n",
    "\"whisper-timestamped>=1.14.2\" \\\n",
    "\"tqdm\" \\\n",
    "\"inflect>=7.0.0\" \\\n",
    "\"unidecode>=1.3.7\" \\\n",
    "\"eng_to_ipa>=0.0.2\" \\\n",
    "\"pypinyin>=0.50.0\" \\\n",
    "\"cn2an>=0.5.22\" \\\n",
    "\"jieba>=0.42.1\" \\\n",
    "\"langid>=1.1.6\" \\\n",
    "\"gradio>=4.15\" \\\n",
    "\"ipywebrtc\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download checkpoints and load PyTorch model\n",
    "[back to top ⬆️](#Table-of-contents:)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing the dtw module. When using in academic works please cite:\n",
      "  T. Giorgino. Computing and Visualizing Dynamic Time Warping Alignments in R: The dtw Package.\n",
      "  J. Stat. Soft., doi:10.18637/jss.v031.i07.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import openvino as ov\n",
    "core = ov.Core()\n",
    "\n",
    "from api import BaseSpeakerTTS, ToneColorConverter, OpenVoiceBaseClass\n",
    "import se_extractor\n",
    "\n",
    "# Fetch `notebook_utils` module\n",
    "import urllib.request\n",
    "urllib.request.urlretrieve(\n",
    "    url='https://raw.githubusercontent.com/openvinotoolkit/openvino_notebooks/main/notebooks/utils/notebook_utils.py',\n",
    "    filename='notebook_utils.py'\n",
    ")\n",
    "from notebook_utils import download_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = 'https://huggingface.co/myshell-ai/OpenVoice/resolve/main/checkpoints/'\n",
    "\n",
    "CKPT_BASE_PATH = '../checkpoints/'\n",
    "\n",
    "en_suffix = 'base_speakers/EN'\n",
    "zh_suffix = 'base_speakers/ZH'\n",
    "converter_suffix = 'converter'\n",
    "en_ckpt_path = f'{CKPT_BASE_PATH}/{en_suffix}'\n",
    "zh_ckpt_path = f'{CKPT_BASE_PATH}/{zh_suffix}'\n",
    "converter_path = f'{CKPT_BASE_PATH}/{converter_suffix}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make notebook lightweight by default model for Chineese speech is not activated, in order turn on please set flag enable_chineese_lang to True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "enable_chineese_lang = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'../checkpoints/converter/checkpoint.pth' already exists.\n"
     ]
    }
   ],
   "source": [
    "download_file(base_url + f'{converter_suffix}/checkpoint.pth', directory=converter_path)\n",
    "download_file(base_url + f'{converter_suffix}/config.json', directory=converter_path)\n",
    "download_file(base_url + f'{en_suffix}/checkpoint.pth', directory=en_ckpt_path)\n",
    "download_file(base_url + f'{en_suffix}/config.json', directory=en_ckpt_path)\n",
    "\n",
    "download_file(base_url + f'{en_suffix}/en_default_se.pth', directory=en_ckpt_path)\n",
    "download_file(base_url + f'{en_suffix}/en_style_se.pth', directory=en_ckpt_path)\n",
    "\n",
    "if enable_chineese_lang:\n",
    "    download_file(base_url + f'{zh_suffix}/checkpoint.pth', directory=zh_ckpt_path)\n",
    "    download_file(base_url + f'{zh_suffix}/ZH/config.json', directory=zh_ckpt_path)\n",
    "    download_file(base_url + f'{zh_suffix}/ZH/zh_default_se.pth', directory=zh_ckpt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_device = \"cpu\"  # todo: check if torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") is indeed needed\n",
    "\n",
    "en_base_speaker_tts = BaseSpeakerTTS(f'{en_ckpt_path}/config.json', device=pt_device)\n",
    "en_base_speaker_tts.load_ckpt(f'{en_ckpt_path}/checkpoint.pth')\n",
    "\n",
    "tone_color_converter = ToneColorConverter(f'{converter_path}/config.json', device=pt_device)\n",
    "tone_color_converter.load_ckpt(f'{converter_path}/checkpoint.pth')\n",
    "\n",
    "if enable_chineese_lang:\n",
    "    zh_base_speaker_tts = BaseSpeakerTTS(f'{zh_ckpt_path}/config.json', device=pt_device)\n",
    "    zh_base_speaker_tts.load_ckpt(f'{zh_ckpt_path}/checkpoint.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert models to OpenVINO IR\n",
    "[back to top ⬆️](#Table-of-contents:)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To convert to OpenVino IR format first we need to get acceptable `torch.nn.Module` object. Both ToneColorConverter, BaseSpeakerTTS instead of using `self.forward` as the main entry point use custom `infer` and `convert_voice` methods respectively, therefore need to wrap them with a custom class that is inherited from torch.nn.Module. \n",
    "\n",
    "<!---\n",
    "# One more reason to make a wrapper is also that these functions use float arguments while only torch.Tensor and tuple of torch.Tensors are acceptable \n",
    "# todo: check if it works when kwargs are moved to example inputs.\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tts_kwargs = dict(noise_scale = 0.667, noise_scale_w = 0.6, speed = 1.0, sdp_ratio = 0.2)\n",
    "\n",
    "voice_convert_kwargs = dict(tau=0.3)\n",
    "tts_kwargs = dict(noise_scale = 0.667, noise_scale_w = 0.6, length_scale = 1.0)  # length_scale = 1.0 / speed - here we set speed = 1 as default\n",
    "\n",
    "class OVOpenVoiceBase(torch.nn.Module):\n",
    "    def __init__(self, voice_model: OpenVoiceBaseClass, kwargs):\n",
    "        super().__init__()\n",
    "        self.voice_model = voice_model\n",
    "        self.default_kwargs = kwargs\n",
    "        for par in voice_model.model.parameters():\n",
    "            par.requires_grad = False\n",
    "    \n",
    "class OVOpenVoiceTTS(OVOpenVoiceBase):\n",
    "    def get_example_input(self):\n",
    "        stn_tst = self.voice_model.get_text('this is original text', self.voice_model.hps, False)\n",
    "        x_tst = stn_tst.unsqueeze(0)\n",
    "        x_tst_lengths = torch.LongTensor([stn_tst.size(0)])\n",
    "        speaker_id = torch.LongTensor([1])\n",
    "        return (x_tst, x_tst_lengths, speaker_id)\n",
    "\n",
    "    def forward(self, x, x_lengths, sid):\n",
    "        return self.voice_model.model.infer(x, x_lengths, sid, **self.default_kwargs)\n",
    "    \n",
    "class OVOpenVoiceConverter(OVOpenVoiceBase):\n",
    "    def get_example_input(self):\n",
    "        y = torch.randn([1, 513, 238], dtype=torch.float32)\n",
    "        y_lengths = torch.LongTensor([y.size(-1)])\n",
    "        target_se = torch.randn(*(1, 256, 1))\n",
    "        source_se = torch.randn(*(1, 256, 1))\n",
    "        return (y, y_lengths, source_se, target_se)\n",
    "    \n",
    "    def forward(self, y, y_lengths, sid_src, sid_tgt):\n",
    "        return self.voice_model.model.voice_conversion(y, y_lengths, sid_src, sid_tgt, **self.default_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert to OpenVino IR and save to IRs_path folder for the future use. If IRs already exist skip conversion and read them directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IRS_PATH = '../openvino_irs/'\n",
    "EN_TTS_IR = f'{IRS_PATH}/openvoice_en_tts.xml'\n",
    "ZH_TTS_IR = f'{IRS_PATH}/openvoice_zh_tts.xml'\n",
    "VOICE_CONVERTER_IR = f'{IRS_PATH}/openvoice_tone_conversion.xml'\n",
    "\n",
    "paths = [EN_TTS_IR, VOICE_CONVERTER_IR]\n",
    "models = [OVOpenVoiceTTS(en_base_speaker_tts, tts_kwargs), OVOpenVoiceConverter(tone_color_converter, voice_convert_kwargs)]\n",
    "if enable_chineese_lang:\n",
    "    models.append(OVOpenVoiceTTS(zh_base_speaker_tts, tts_kwargs))\n",
    "ov_models = []\n",
    "\n",
    "for model, path in zip(models, paths):\n",
    "    if not os.path.exists(path):\n",
    "        ov_model = ov.convert_model(model, example_input=model.get_example_input())\n",
    "        ov.save_model(ov_model, path)\n",
    "    else:\n",
    "        ov_model = core.read_model(path)\n",
    "    ov_models.append(ov_model)\n",
    "\n",
    "ov_en_tts, ov_voice_conversion = ov_models[:2]\n",
    "if enable_chineese_lang:\n",
    "    ov_zh_tts = ov_models[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select inference device\n",
    "[back to top ⬆️](#Table-of-contents:)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "\n",
    "core = ov.Core()\n",
    "device = widgets.Dropdown(\n",
    "    options=core.available_devices + [\"AUTO\"],\n",
    "    value='AUTO',\n",
    "    description='Device:',\n",
    "    disabled=False,\n",
    ")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select reference tone\n",
    "[back to top ⬆️](#Table-of-contents:)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, select the reference tone of voice to which the generated text will be converted: your can select from existing ones or record your own by seleceing `record_manually`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_speakers = [\n",
    "    'resources/example_reference.mp3',\n",
    "    'resources/demo_speaker0.mp3',\n",
    "    'resources/demo_speaker1.mp3',\n",
    "    'resources/demo_speaker2.mp3',\n",
    "    'record_manually',\n",
    "]\n",
    "\n",
    "ref_speaker = widgets.Dropdown(\n",
    "    options=reference_speakers,\n",
    "    value=reference_speakers[0],\n",
    "    description=\"reference voice from which tone color will be copied\",\n",
    "    disabled=False,\n",
    ")\n",
    "\n",
    "display(ref_speaker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_DIR = '../outputs/'\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_speaker_path = ref_speaker.value\n",
    "\n",
    "if ref_speaker.value == 'record_manually':\n",
    "    ref_speaker_path = f'{OUTPUT_DIR}/custom_example_sample.webm'\n",
    "    from ipywebrtc import AudioRecorder, CameraStream\n",
    "    camera = CameraStream(constraints={'audio': True,'video':False})\n",
    "    recorder = AudioRecorder(stream=camera, filename=ref_speaker_path, autosave=True)\n",
    "    display(recorder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Play the reference voice sample before cloning it's tone to another speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio\n",
    "Audio(ref_speaker_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load speaker embeddings\n",
    "en_source_default_se = torch.load(f'{en_ckpt_path}/en_default_se.pth')\n",
    "en_source_style_se = torch.load(f'{en_ckpt_path}/en_style_se.pth')\n",
    "zh_source_se = torch.load(f'{zh_ckpt_path}/zh_default_se.pth') if enable_chineese_lang else None\n",
    "\n",
    "target_se, audio_name = se_extractor.get_se(ref_speaker_path, tone_color_converter, target_dir='processed', vad=True)  # ffmpeg must be installed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace original infer methods of OpenVoiceBaseClass with optimized OpenVINO inference.\n",
    "\n",
    "There are pre and post processings that are not traceable and could not be offloaded to OpenVINO, instead of writing such processing ourselves we will rely on the already existing ones. We just replace infer and voice conversion functions of OpenVoiceBaseClass so that the the most computationally expensive part is done in OpenVINO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assert_kwargs_are_same(kwargs: dict, orig_kwargs: dict):\n",
    "    for k, v in kwargs.items():\n",
    "        assert v == orig_kwargs[k], f\"Model was converted to IR with {k}: '{orig_kwargs[k]}', \" \\\n",
    "        f\"but you are trying to infer with {k} = '{v}'. \" \\\n",
    "        f\"Please use original value or rerun ov.convert_model with the desirable value of '{k}'\"\n",
    "\n",
    "def get_pathched_infer(ov_model: ov.Model, device: str, orig_kwargs: dict = None) -> callable:\n",
    "    compiled_model = core.compile_model(ov_model, device)\n",
    "    \n",
    "    def infer_impl(x, x_lengths, sid=None, **kwargs):\n",
    "        assert_kwargs_are_same(kwargs, orig_kwargs)\n",
    "        ov_output = compiled_model((x, x_lengths, sid))\n",
    "        return (torch.tensor(ov_output[0]), )\n",
    "    return infer_impl\n",
    "\n",
    "def get_patched_voice_conversion(ov_model: ov.Model, device: str, orig_kwargs: dict = None) -> callable:\n",
    "    compiled_model = core.compile_model(ov_model, device)\n",
    "\n",
    "    def voice_conversion_impl(y, y_lengths, sid_src, sid_tgt, **kwargs):\n",
    "        assert_kwargs_are_same(kwargs, orig_kwargs)\n",
    "        ov_output = compiled_model((y, y_lengths, sid_src, sid_tgt))\n",
    "        return (torch.tensor(ov_output[0]), )\n",
    "    return voice_conversion_impl\n",
    "\n",
    "\n",
    "en_base_speaker_tts.model.infer = get_pathched_infer(ov_en_tts, device.value, orig_kwargs=tts_kwargs)\n",
    "tone_color_converter.model.voice_conversion = get_patched_voice_conversion(ov_voice_conversion, device.value, orig_kwargs=voice_convert_kwargs)\n",
    "if enable_chineese_lang:\n",
    "    tone_color_converter.model.voice_conversion = get_pathched_infer(ov_zh_tts, device.value, orig_kwargs=tts_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run inference\n",
    "[back to top ⬆️](#Table-of-contents:)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = f'{OUTPUT_DIR}/output_en_default.wav'\n",
    "\n",
    "text = \"\"\"\n",
    "OpenVINO toolkit is a comprehensive toolkit for quickly developing applications and solutions that solve \n",
    "a variety of tasks including emulation of human vision, automatic speech recognition, natural language processing, \n",
    "recommendation systems, and many others.\n",
    "\"\"\"\n",
    "\n",
    "src_path = f'{OUTPUT_DIR}/tmp.wav'\n",
    "en_base_speaker_tts.tts(text, src_path, speaker='default', language='English', speed=1.0)\n",
    "# src_path = '/home/epavel/my_base_voice.m4a'\n",
    "\n",
    "tone_color_converter.convert(\n",
    "    audio_src_path=src_path, \n",
    "    src_se=en_source_default_se, \n",
    "    tgt_se=target_se, \n",
    "    output_path=save_path, \n",
    "    message=\"@MyShell\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# play the original voice\n",
    "Audio(src_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# play the speech with tone voice copied from the reference\n",
    "Audio(save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run OpenVoice Gradio online app\n",
    "[back to top ⬆️](#Table-of-contents:)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use [Gradio](https://www.gradio.app/) app to run TTS and voice tone conversion online."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openvoice_gradio import get_demo\n",
    "\n",
    "demo = get_demo(OUTPUT_DIR, color_convert_model, en_tts_model, zh_tts_model, en_source_default_se, en_source_style_se, zh_source_se)\n",
    "demo.queue(max_size=2)\n",
    "demo.launch(server_name=\"0.0.0.0\", server_port=7860)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup\n",
    "[back to top ⬆️](#Table-of-contents:)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# please run this cell for stopping gradio interface\n",
    "demo.close()\n",
    "\n",
    "# clean up \n",
    "# import shutil\n",
    "# shutil.rmtree(CKPT_BASE_PATH)\n",
    "# shutil.rmtree(IRS_PATH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
