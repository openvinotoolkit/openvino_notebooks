{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d44ad85",
   "metadata": {},
   "source": [
    "# Convert photo to cartoon ONNX Model to OpenVINO™ IR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29def0ea",
   "metadata": {},
   "source": [
    "The aim of portrait cartoon stylization is to transform real photos into cartoon images with portrait's ID information and texture details. We use Generative Adversarial Network method to realize the mapping of picture to cartoon. Considering the difficulty in obtaining paired data and the non-corresponding shape of input and output, we adopt unpaired image translation fashion.\n",
    "\n",
    "The results of CycleGAN, a classic unpaired image translation method, often have obvious artifacts and are unstable. Recently, Kim et al. propose a novel normalization function (AdaLIN) and an attention module in paper \"U-GAT-IT\" and achieve exquisite selfie2anime results.\n",
    "\n",
    "Different from the exaggerated anime style, our cartoon style is more realistic and contains unequivocal ID information. To this end, we add a Face ID Loss (cosine distance of ID features between input image and cartoon image) to reach identity invariance.\n",
    "\n",
    "We propose a Soft Adaptive Layer-Instance Normalization (Soft-AdaLIN) method which fuses the statistics of encoding features and decoding features in de-standardization.\n",
    "\n",
    "Based on U-GAT-IT, two hourglass modules are introduced before encoder and after decoder to improve the performance in a progressively way.\n",
    "\n",
    "We also pre-process the data to a fixed pattern to help reduce the difficulty of optimization. For details, see below.\n",
    "\n",
    "This tutorial demonstrates the running results of photo2cartoon and converts it from ONNX model to the IR model used by OpenVION.\n",
    "\n",
    "Requirements\n",
    "\n",
    "    ·python 3.6\n",
    "    ·pytorch 1.4\n",
    "    ·tensorflow-gpu 1.14\n",
    "    ·face-alignment\n",
    "    ·dlib\n",
    "    ·onnxruntime\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a6337d8",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca78da0",
   "metadata": {},
   "source": [
    "The default environment of  openvino does not contain all the packages required for the current model to run, so you need to run the following command first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0f6a00",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "!pip install face-alignment dlib onnxruntime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f1859c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "sys.path.append(\"../utils\")\n",
    "from notebook_utils import download_file\n",
    "\n",
    "import numpy as np\n",
    "import onnxruntime\n",
    "import argparse\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e96ff29e",
   "metadata": {},
   "source": [
    "## Prerequisittes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd5c30c",
   "metadata": {},
   "source": [
    "This Model is not in Gihub, so you should pre-dowload it in: [Google Drive](https://drive.google.com/file/d/1PhwKDUhiq8p-UqrfHCqj257QnqBWD523/view?usp=sharing) or [Baidu Cloud](https://pan.baidu.com/share/init?surl=MsT3-He3UGipKhUi4OcCJw) acess code: y2ch. And place the downloaded model in the models folder, place seg_model_384.pb to utils file folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eedf6c2c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Clone photo2cartoon project\n",
    "\n",
    "if not Path('photo2cartoon').exists():\n",
    "    !git clone https://github.com/minivision-ai/photo2cartoon.git\n",
    "        \n",
    "%cd photo2cartoon\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285f447f",
   "metadata": {},
   "source": [
    "## Check model inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c39c87",
   "metadata": {},
   "source": [
    "`test_onnx.py` script run ONNXmodel to test photo to cartoon.\n",
    "\n",
    "Please use a young Asian woman photo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b1a574",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!python test_onnx.py --photo_path ./images/photo_test.jpg --save_path ./images/cartoon_result.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397cc371",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "original_img = Image.open('./images/photo_test.jpg')\n",
    "generate_img = Image.open('./images/cartoon_result.png')\n",
    "fig, ax =plt.subplots(1,2)\n",
    "ax[0].imshow(original_img)\n",
    "ax[0].set_title('original')\n",
    "\n",
    "ax[1].imshow(generate_img)\n",
    "ax[1].set_title('generate')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee70e45c",
   "metadata": {},
   "source": [
    "This part show how to use the ONNX Model to generate cartoon image.\n",
    "\n",
    "This open source model is based on the trainning of yong women in Asia.For other groups with insufficient coverage, you can collect the data of corresponding groups according to the use scenario for training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24af352b",
   "metadata": {},
   "source": [
    "## Conver ONNX Model to OpenVINO Intermediate Representation (IR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442ec572",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from openvino.tools import mo\n",
    "from openvino.runtime import serialize\n",
    "\n",
    "\n",
    "model = mo.convert_model('./models/photo2cartoon_weights.onnx')\n",
    "\n",
    "serialize(model, './models/photo2cartoon.xml')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4aab180",
   "metadata": {},
   "source": [
    "## Verify model inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252c86d9",
   "metadata": {},
   "source": [
    "To infer the model, you first need to call the `ExecutableNetwork` method `create_infer_Request()` to create an inference request, we use `compile_Model()` loaded `exec_ net`.  Then we must call `infer()` as `_InferRequest_`  The method requires a parameter: `inputs`. This is a dictionary that maps input layer names to input data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e096e9dc",
   "metadata": {},
   "source": [
    "- Step 1: Import the model. We passed `ie.read_Model` to read the model, `ie.confile_Model` to compile the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b22b3eb",
   "metadata": {},
   "source": [
    "- Step 2: Load the image and convert it to the input shape. To propagate an image through the network, you need to load it into an array, adjust it to the shape expected by the network, and convert it to the input layout format of the network. We get the reference of the desired height and width of the network, and adjust the image to this size. Finally, we change the image size to N, C, H, W format (where N=1), first call `np.transpose()` to change to C, H, W."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4650a27a",
   "metadata": {},
   "source": [
    "- Step 3: Model reasoning. We can use `compiled_Model([input_data])[output_layer]` directly obtains the result of reasoning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b7ed71",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "from openvino.runtime import Core\n",
    "\n",
    "\n",
    "ie = Core()\n",
    "\n",
    "\n",
    "# load network\n",
    "print(\"Load network\")\n",
    "photo2cartoon_model_xml = \"./models/photo2cartoon.xml\"\n",
    "\n",
    "model = ie.read_model(model=photo2cartoon_model_xml)\n",
    "compiled_model = ie.compile_model(model = model, device_name=\"CPU\")\n",
    "input_layer = compiled_model.input(0)\n",
    "output_layer = compiled_model.output(0)\n",
    "print('Model Input and Output Info')\n",
    "\n",
    "print(f\"- input shape: {input_layer.shape}\")\n",
    "print(f\"- input precision: {input_layer.element_type}\")\n",
    "\n",
    "print(f\"- output shape: {output_layer.shape}\")\n",
    "print(f\"- output precision: {output_layer.element_type}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10870056",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# load image\n",
    "print(\"Load input image\")\n",
    "image_filename = './images/photo_test.jpg'\n",
    "image = cv2.imread(image_filename)\n",
    "print(\"- input image shape: {}\".format(image.shape))\n",
    "\n",
    "N, C, H, W = input_layer.shape\n",
    "\n",
    "resized_image = cv2.resize(src=image, dsize=(W, H))\n",
    "print(\"- resize image into shape: {}\".format(resized_image.shape))\n",
    "input_data = np.expand_dims(np.transpose(resized_image, (2,0,1)), 0).astype(np.float32)\n",
    "print(\"- align image shape same as network input: {}\".format(input_data.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055a1d40",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Infrence\n",
    "\n",
    "print(\"Infrence\")\n",
    "\n",
    "result = compiled_model([input_data])[output_layer]\n",
    "print(\"- generate image[0] shape: {}\".format(result[0].shape))\n",
    "print(\"- generate image precision: {}\".format(result.dtype))\n",
    "result_path = './images/openvino_result.jpg'\n",
    "\n",
    "generate_image = result[0].transpose((1,2,0))\n",
    "\n",
    "cv2.imwrite(result_path, generate_image)\n",
    "plt.imshow(generate_image)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
